[["index.html", "Introduction to spatial-temporal data anlysis using R 本稿の目的", " Introduction to spatial-temporal data anlysis using R Tsubasa Yamaguchi 2023-09-27 本稿の目的 本稿は、時空間相関を考慮したGLM/GLMMをRで実装する方法を解説する。 生態学のデータでは、データに非独立性が存在することが多くある(第1章)。多くの統計分析はデータが互いに独立であることを仮定しているので、こうした非独立性を考慮せずにを行ってしまうと誤った結論を導いてしまうことになりかねない。本稿では、特に時間的・空間的な相関があることでデータに非独立性がある場合に、どのようにそれに対処するべきかを解説する。本稿では、特にGLMやGLMM(Zuur et al. 2013)による分析を扱う。 本稿は主に Alain Zuurによる”Zuur, A. F. (2017). Beginner’s Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-Inla: Using Glm and Glmm Volume I”(Zuur 2017)を基に執筆している。本書はなるべく数学的な説明を省きつつ、実際の生態学のデータを用いて時空間を考慮したGLM/GLMMについて間接している本である。 その他には、以下の本も参考にした。 Mixed effects models and extensions in ecology with R (Zuur 2009) Rで始める地理空間データの統計解析入門 (村上 2022) Rとstanではじめるベイズ統計モデリングによるデータ分析入門 (馬場 2019) 時系列分析と状態空間モデルの基礎 : RとStanで学ぶ理論と実装 (馬場 2018) References "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham and Grolemund 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al. 2021) 出版社サイト 使用するパッケージは以下のとおりである。 ## データハンドリング library(knitr) library(MASS) library(tidyverse) library(scales) library(easystats) library(data.table) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) ## 地理データ library(sp) library(sf) library(fields) library(NipponMap) library(ggmap) library(rgdal) ## モデリング library(INLA) library(mgcv) library(gamm4) library(nlme) library(gstat) library(brms) library(rstan) library(cmdstanr) library(ggeffects) ## グラフや表関連 library(plotly) library(bayesplot) library(viridis) library(gt) library(geoR) library(ggnewscale) library(GGally) library(ggrepel) library(patchwork) library(DT) library(kableExtra) library(ggsci) library(lemon) References "],["Chapter2.html", "1 Recognizing statistical dependency 1.1 Pseudoreplication 1.2 Linear regression applied to spatial data 1.3 GAM applied to temporal data", " 1 Recognizing statistical dependency 1.1 Pseudoreplication 1.1.1 疑似反復とは 疑似反復(pseudoreplication)とは、応答変数のデータが独立ではないにもかかわらず、統計解析にそのことが考慮されていないことを指す。多くの統計解析は全てのデータが独立であることを仮定しているので、もし疑似反復が生じている状態で分析を行うと正しい結果が得られないことが多い。 疑似反復の典型的な例としては、同じ個体から複数のデータが得られている場合が挙げられる。例えば、ある治療薬の効果を調べる場合、各患者について治療前のデータと治療薬を飲んだ後のデータを収集する。もし100人分データを収集するとすれば200個のデータが集まるが、これらのデータが独立であると考えることはできない。なぜなら、同じ患者のデータはその患者特有の属性など(年齢、性別、あるいは観測できない要因など)によって他の患者のデータよりも類似している可能性が高くなるからである。もし独立であると仮定して分析を行うと、実際よりもデータの標準誤差が小さく推定されてしまい、第一種の過誤を犯しやすくなってしまう。 他にも、例えば10個の植木鉢にそれぞれ5個ずつ種子を植えて、その成長度合いを調べる場合を考えてみよう。このとき、合計50個のデータが得られるが、同じ植木鉢に植えられた種子のデータを独立であると考えることはできない。なぜなら、同じ植木鉢の種子はその植木鉢特有の属性(土中の栄養分、日照度合い、あるいは観測できない要因など)によって、他の植木鉢の種子のデータよりも類似している可能性が高くなるからである。 こうした疑似反復に対処するためのアプローチは、混合モデルと呼ばれるものを適用することである(Zuur et al. 2013)。 1.1.2 時空間的な疑似反復 上記のような疑似反復の他にも、時間的あるいは空間的な疑似反復が生じることがある。例えば、あるニホンザルの群れで発情しているメスの数を毎日記録するとしよう。このとき、時間的に近い日のデータ同士はそうでないデータ同士よりも類似する確率が高い。なぜなら、ある日発情していたメスは、その次の日も発情している可能性が高いからである。 図1.1は実際に宮城県金華山島で収集された発情メス数のデータである。実際に、近い日は類似した値をとることが多いことが分かる。このように、時系列データは互いに独立していないことが多い。こうした時間的な疑似相関を考慮せずに分析を行ってしまう(e.g., 毎日の発情メス数が気温によって変わるかを調べるなど)と、誤った結論を導いてしまいかねない。 daily_data &lt;- read_csv(&quot;data/daily_data_2021.csv&quot;) daily_data %&gt;% filter(duration &gt;= 300) %&gt;% ggplot(aes(x = date))+ geom_line(aes(y = no_est))+ scale_x_date(date_breaks = &quot;1 week&quot;)+ scale_y_continuous(breaks = seq(0,16,2))+ theme_bw(base_size=15)+ theme(axis.text.x = element_text(angle=30, hjust=1), axis.title.y = element_text(angle = 0, vjust = 0.5), aspect.ratio=0.5, legend.position = c(0.2,0.9), legend.text = element_text(size=10.5, family = &quot;Yu Mincho&quot;), axis.text = element_text(family = &quot;Times New Roman&quot;))+ labs(x = &quot;&quot;, y = &quot;発\\n情\\nメ\\nス\\n数&quot;)+ guides(linetype = guide_legend(title=NULL)) 図1.1: 2021年の金華山島B1群における各観察日の発情メス数 地理空間データについても同様のことがいえる。例えば、日本の各都道府県における納豆の消費量について分析するとする(データはこちらから)。このとき、各都道府県のデータを独立と考えることはできない。なぜなら、地理的に近い都道府県は食文化や気候などが類似しており、納豆の消費量も類似している可能性が高くなるからである。 実際、地図上に納豆消費量を図示すると(図1.2)、地理的に近い県は納豆の消費量も類似していることが分かる。このように、空間的データについてもデータ同士に非独立性が生じやすい。 natto &lt;- read_csv(&quot;data/natto.csv&quot;) gyuniku &lt;- read_csv(&quot;data/gyuniku.csv&quot;) shp &lt;- system.file(&quot;shapes/jpn.shp&quot;, package = &quot;NipponMap&quot;)[1] pref &lt;- read_sf(shp) %&gt;% rename(prefecture = name) pref %&gt;% left_join(gyuniku) %&gt;% left_join(natto) -&gt; japan_data st_crs(japan_data) &lt;- 4326 japan_data %&gt;% filter(prefecture != &quot;Okinawa&quot;) %&gt;% ggplot()+ geom_sf(aes(fill = natto))+ theme_bw()+ theme(aspect.ratio = 1)+ scale_fill_gradient2(high = muted(&quot;blue&quot;), low = muted(&quot;red&quot;), mid = &quot;white&quot;, midpoint = 3700)+ labs(fill = &quot;納豆消費量(円)&quot;) 図1.2: 各都道府県の納豆消費量(円) こうした空間的な疑似反復を考慮せずに分析を行ってしまうと、誤った結論を導いてしまうことになる。例えば、各都道府県の納豆消費量と牛肉消費量が関連しているかを分析するとしよう。図1.3は両者の関連をプロットしたものであるが、プロットだけを見ると両社は強い負の相関を持つように見える(実際、相関係数は-0.737。しかし、先ほど見たように各都道府県のデータは独立ではないので、空間的な非独立性を考慮した分析を行わなければいけない。空間的相関を考慮した分析を行うと、両者の関連はなくなる(こちらを参照)。 japan_data %&gt;% ggplot(aes(x = gyuniku, y = natto))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;納豆消費量(円)&quot;, x = &quot;牛肉消費量(g)&quot;) 図1.3: 各都道府県の納豆消費量と牛肉消費量 1.2 Linear regression applied to spatial data 本節では、Cruikshanks et al. (2006) のデータを用いる。この研究では、アイルランドの257の川において、川のpHがSDI(Sodium Dominance Index; 陽イオン中のナトリウムイオン)と関連しているかを、緯度(Altitude)やその場所が森林化されているか(Forested)も考慮したうえで調べている。 1.2.1 Visualization データは以下の通り。 iph &lt;- read_delim(&quot;data/Irishph.txt&quot;) %&gt;% mutate(fForested = ifelse(Forested == &quot;1&quot;, &quot;yes&quot;, &quot;no&quot;)) %&gt;% data.frame() datatable(iph, options = list(scrollX = 20), filter = &quot;top&quot;) 各説明変数との関連は以下の通り。 iph %&gt;% dplyr::select(Altitude, pH, fForested, SDI) %&gt;% pivot_longer(cols = c(Altitude, SDI)) %&gt;% ggplot(aes(x = value, y = pH))+ geom_point(aes(color = fForested))+ geom_smooth(aes(color = fForested), method = &quot;lm&quot;)+ facet_rep_wrap(~ name, scales = &quot;free_x&quot;, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Covariates&quot;) 1.2.2 Dependency 以下の線形モデルを適用するとする。 \\[ \\begin{aligned} pH_i &amp;\\sim N(0,\\sigma^2)\\\\ \\mu_i &amp;= \\beta_1 + \\beta_2 \\times SDI_i\\\\ \\end{aligned} \\] 結果を図示すると以下のようになる。 m2_1 &lt;- lm(pH ~ SDI, data = iph) 濃く塗りつぶした部分が95%信頼区間、薄く塗りつぶした部分が95%予測区間である。 ggpredict(m2_1, terms = &quot;SDI[7:72,by=0.1]&quot;, interval = &quot;prediction&quot;) %&gt;% data.frame() %&gt;% mutate(type = &quot;prediction&quot;) %&gt;% bind_rows(ggpredict(m2_1, terms = &quot;SDI[7:72,by=0.1]&quot;, interval = &quot;confidence&quot;) %&gt;% data.frame() %&gt;% mutate(type = &quot;confidence&quot;)) %&gt;% rename(SDI = x) %&gt;% ggplot(aes(x = SDI, y = predicted))+ geom_ribbon(aes(ymin = conf.high, ymax = conf.low, fill = type), alpha = 0.5)+ scale_fill_grey()+ geom_line()+ geom_point(data = iph, aes(y = pH), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1) 1.2.3 Fit the model 次に、全部の交互作用を含むモデルを考える。 iph %&gt;% mutate(logAltitude = log(Altitude,10)) -&gt; iph m2_2 &lt;- lm(pH ~ SDI*fForested*logAltitude, data = iph) 結果は以下の通り。 summary(m2_2) ## ## Call: ## lm(formula = pH ~ SDI * fForested * logAltitude, data = iph) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.94554 -0.18644 -0.01226 0.21667 1.13820 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.250624 0.765918 10.772 &lt;2e-16 *** ## SDI -0.028011 0.017190 -1.630 0.105 ## fForestedyes 1.794536 2.070682 0.867 0.387 ## logAltitude 0.106199 0.390728 0.272 0.786 ## SDI:fForestedyes -0.008168 0.037112 -0.220 0.826 ## SDI:logAltitude 0.001764 0.008614 0.205 0.838 ## fForestedyes:logAltitude -0.885493 1.012152 -0.875 0.383 ## SDI:fForestedyes:logAltitude 0.003573 0.017939 0.199 0.842 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3756 on 202 degrees of freedom ## Multiple R-squared: 0.5675, Adjusted R-squared: 0.5525 ## F-statistic: 37.86 on 7 and 202 DF, p-value: &lt; 2.2e-16 あまりに煩雑なのでAICによるモデル選択を行う。 stepAIC(m2_2) ## Start: AIC=-403.47 ## pH ~ SDI * fForested * logAltitude ## ## Df Sum of Sq RSS AIC ## - SDI:fForested:logAltitude 1 0.0055954 28.498 -405.43 ## &lt;none&gt; 28.492 -403.47 ## ## Step: AIC=-405.43 ## pH ~ SDI + fForested + logAltitude + SDI:fForested + SDI:logAltitude + ## fForested:logAltitude ## ## Df Sum of Sq RSS AIC ## - SDI:fForested 1 0.00454 28.503 -407.39 ## - SDI:logAltitude 1 0.01654 28.515 -407.31 ## &lt;none&gt; 28.498 -405.43 ## - fForested:logAltitude 1 1.01027 29.508 -400.11 ## ## Step: AIC=-407.39 ## pH ~ SDI + fForested + logAltitude + SDI:logAltitude + fForested:logAltitude ## ## Df Sum of Sq RSS AIC ## - SDI:logAltitude 1 0.01443 28.517 -409.29 ## &lt;none&gt; 28.503 -407.39 ## - fForested:logAltitude 1 1.08368 29.586 -401.56 ## ## Step: AIC=-409.29 ## pH ~ SDI + fForested + logAltitude + fForested:logAltitude ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 28.517 -409.29 ## - fForested:logAltitude 1 1.2837 29.801 -402.04 ## - SDI 1 29.3674 57.884 -262.62 ## ## Call: ## lm(formula = pH ~ SDI + fForested + logAltitude + fForested:logAltitude, ## data = iph) ## ## Coefficients: ## (Intercept) SDI fForestedyes ## 8.10382 -0.02461 1.29402 ## logAltitude fForestedyes:logAltitude ## 0.18292 -0.65962 AICが最小のモデルは以下の通り。 m2_3 &lt;- lm(pH ~ SDI + logAltitude*fForested, data = iph) 1.2.4 Model validation 1.2.4.1 Check homogeinity and model misfit モデル診断を行う。標準化残差と予測値、各共変量の関係は特にパターンが見られず、問題ないよう。 resid &lt;- rstandard(m2_3) data.frame(resid = resid, fitted = predict(m2_3)) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) iph %&gt;% mutate(resid = resid) %&gt;% select(resid, SDI, logAltitude) %&gt;% pivot_longer(cols = c(SDI, logAltitude)) %&gt;% ggplot(aes(x = value, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ labs(x = &quot;&quot;) iph %&gt;% mutate(resid = resid) %&gt;% select(resid, fForested) %&gt;% ggplot(aes(x = fForested, y = resid))+ geom_boxplot()+ theme_bw()+ theme(aspect.ratio = 1) 1.2.5 Check spatial dependence 地理的空間上に残差を図示してもパターンがあるかはわかりにくい。 iph %&gt;% mutate(resid = resid) %&gt;% ggplot(aes(x = Easting, y = Northing))+ geom_point(shape = 21, aes(fill = resid &gt;= 0, size = abs(resid)))+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ theme_bw()+ theme(aspect.ratio = 1) 図1.4: Residuals plotted versus spatial position. The width of a point is proportional to the (absolute) value of a residual. Filled circles are positive residuals and open circles are negative residuals. It would be useful to add the contour lines of the Irish borders. そこで、バリオグラムを作成する。 バリオグラムではまず、データ間の距離がある特定の範囲内にあるデータのペアを抽出する。例えば、図1.5は10kmずつに区切った範囲内にある2つのデータをつないだものである。そのうえで、ある距離範囲カテゴリ(e.g., 10km &lt; dist &lt; 20km)において各データペアの残差の差の二乗を平均したものを算出する。これを全距離範囲カテゴリについて行い、それを図示したものをバリオグラムという。なお、各範囲カテゴリには、少なくとも100ペアくらいはあった方がよい。 crossing(ID1 = iph$ID, ID2 = iph$ID) %&gt;% left_join(iph %&gt;% select(ID,Easting, Northing), by = c(&quot;ID1&quot; = &quot;ID&quot;)) %&gt;% rename(Easting1 = Easting, Northing1 = Northing) %&gt;% left_join(iph %&gt;% select(ID,Easting, Northing), by = c(&quot;ID2&quot; = &quot;ID&quot;)) %&gt;% rename(Easting2 = Easting, Northing2 = Northing) %&gt;% filter(ID1 != ID2) %&gt;% mutate(dist = sqrt((Easting1 - Easting2)^2 + (Northing1 - Northing2)^2)/1000) %&gt;% mutate(cat = ifelse(dist &lt; 10, &quot;Distances &lt; 10 km&quot;, ifelse(dist &lt; 20, &quot;10 km &lt; Distances &lt; 20 km&quot;, ifelse(dist &lt; 30, &quot;20 km &lt; Distances &lt; 30 km&quot;, ifelse(dist &lt; 40, &quot;30 km &lt; Distances &lt; 40 km&quot;, &quot;NA&quot;))))) %&gt;% mutate(cat2 = ifelse(dist &lt; 40, 1, ifelse(dist &lt; 30, 2, ifelse(dist &lt; 20, 3, ifelse(dist &lt; 10, 4, &quot;NA&quot;))))) %&gt;% filter(cat != &quot;NA&quot;) %&gt;% mutate(cat = fct_relevel(cat, &quot;Distances &lt; 10 km&quot;)) %&gt;% ggplot()+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;1&quot;))+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;2&quot;))+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;3&quot;))+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;4&quot;))+ facet_rep_wrap(~cat, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Easting&quot;, y = &quot;Northing&quot;) 図1.5: Each panel shows c ombinations of any two sampling locations with distances of certain threshold values. もしデータに空間的な相関がないのであれば、距離の範囲カテゴリに関わらずデータペアの残差の差の平均は一定になるはずである(= バリオグラムはx軸と平行になる)。一方で、例えば空間的に近いデータほど似た残差をとるのであれば、近い距離範囲カテゴリではデータペアの残差の差の平均が小さくなる。 Rでは以下のように実行できる。cressie = TRUEとすることで推定がより頑強になり、外れ値の影響を小さくすることができる。npは各距離範囲カテゴリのデータ数を、distはそれぞれの距離カテゴリーにおけるデータ間の平均距離、gammaは計算されたバリオグラムの値を表す。明らかにプロットは一定の値をとっておらず、強い空間相関があることが予想される(図1.6)。 vario_2_3 &lt;- data.frame(resid = rstandard(m2_3), Easting.km = iph$Easting/1000, Northing.km = iph$Northing/1000) sp::coordinates(vario_2_3) &lt;- c(&quot;Easting.km&quot;, &quot;Northing.km&quot;) vario_2_3 %&gt;% variogram(resid ~ 1, data = ., cressie = TRUE, ## 距離が150km以下のデータのみ使用 cutoff = 150, ## 各距離範囲カテゴリの範囲 width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;semivariogram&quot;) 図1.6: m2_3のバリオグラム 南北方向と東西方向の距離を分けて調べることもできる。特に東西方向では明確にバリオグラムが水平ではなく、空間的な独立性がないことが分かる。 vario_2_3 %&gt;% variogram(resid ~ Easting.km + Northing.km, data = ., ## 0が南北方向、90が東西方向 alpha = c(0, 90), cressie = TRUE, cutoff = 150, width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ dir.hor, labeller = as_labeller(c(&quot;0&quot; = &quot;North-South&quot;, &quot;90&quot; = &quot;East-West&quot;)))+ labs(y = &quot;semivariogram&quot;) 1.3 GAM applied to temporal data 1.3.1 Subnivium temperature data 本節では、 Petty et al. (2015) のデータを用いる。この論文では雪下と地面の間の環境(subnivium)の温度を調べている。積雪量が温度に与える影響を、米ウィスコンシン州の3か所の3つの異なる環境(tall grass prailies, deciduous, coniferous)で検討している。 2013年12月から2014年3月における、日ごとの平均温度が記録されている。各環境に4つずつデータロガーが置かれている。そのため、\\(3 \\times 4 = 12\\)個の時系列データがある。 sn &lt;- read_csv(&quot;data/Snow.csv&quot;) %&gt;% mutate(date = as_datetime(str_c(Year,Month, Day, sep = &quot;-&quot;))) %&gt;% mutate(date_num = as.numeric((date - min(date))/(3600*24)) + 1) datatable(sn, options = list(scrollX = 20), filter = &quot;top&quot;) 論文に倣い、2013年12月5日から2014年3月3日までのデータを用いる(4 &lt;= date_num &lt;= 92)。 sn2 &lt;- sn %&gt;% filter(date_num &gt;= 4 &amp; date_num &lt;= 92) 各環境における温度の変化は以下の通り。 sn2 %&gt;% ggplot(aes(x = date_num, y = Temp))+ geom_line(aes(linetype = Logger))+ facet_rep_wrap(~Type)+ theme_bw()+ theme(aspect.ratio = 1.2) 1.3.2 Sources of dependency 同じ環境のロガーはそれぞれ10mしか離れていないので、同じ日におけるこれらのロガーのデータは独立ではない。また、同じロガーのデータについても、時間的な相関があると考えられる(t-1日目の温度とt日目の温度が独立とは考えにくい)。各環境間は距離が離れているので、独立性があると仮定してよさそう。 以下では、こうした非独立性を考慮せずに分析をした場合にどのような問題がが生じるかを見ていく。 1.3.3 The model 以下のGAMMを適用する(回帰係数は省略している)。ロガーIDをランダム切片として入れている。環境ごとにsmootherを推定する。\\(t\\)は経過日数(date_num)、\\(i\\)はロガーのidを表す。 \\[ \\begin{aligned} T_{it} &amp;\\sim N(\\mu_t, \\sigma^2)\\\\ \\mu_{it} &amp;= \\alpha + f_j(date\\_num_t) + Type_i + a_i\\\\ a_i &amp;\\sim N(0, \\sigma_{Logger}^2) \\end{aligned} (\\#eq:m2.4) \\] Rでは以下のように実行する。 m2_4 &lt;- gamm(Temp ~ s(date_num, by = Type) + Type, random = list(Logger =~ 1), data = sn2 %&gt;% mutate(Type = as.factor(Type))) 結果は以下の通り。 summary(m2_4$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Temp ~ s(date_num, by = Type) + Type ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.7363 0.1796 -9.670 &lt;2e-16 *** ## TypeDeciduous -0.1378 0.2574 -0.535 0.5927 ## TypePrairie 0.5000 0.2551 1.960 0.0503 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(date_num):TypeConiferous 8.658 8.658 36.21 &lt;2e-16 *** ## s(date_num):TypeDeciduous 8.205 8.205 62.67 &lt;2e-16 *** ## s(date_num):TypePrairie 8.229 8.229 37.69 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.548 ## Scale est. = 1.0144 n = 921 summary(m2_4$lme) ## Linear mixed-effects model fit by maximum likelihood ## Data: strip.offset(mf) ## AIC BIC logLik ## 2787.212 2840.292 -1382.606 ## ## Random effects: ## Formula: ~Xr - 1 | g ## Structure: pdIdnot ## Xr1 Xr2 Xr3 Xr4 Xr5 Xr6 Xr7 Xr8 ## StdDev: 20.28316 20.28316 20.28316 20.28316 20.28316 20.28316 20.28316 20.28316 ## ## Formula: ~Xr.0 - 1 | g.0 %in% g ## Structure: pdIdnot ## Xr.01 Xr.02 Xr.03 Xr.04 Xr.05 Xr.06 Xr.07 Xr.08 ## StdDev: 16.03337 16.03337 16.03337 16.03337 16.03337 16.03337 16.03337 16.03337 ## ## Formula: ~Xr.1 - 1 | g.1 %in% g.0 %in% g ## Structure: pdIdnot ## Xr.11 Xr.12 Xr.13 Xr.14 Xr.15 Xr.16 Xr.17 Xr.18 ## StdDev: 14.19846 14.19846 14.19846 14.19846 14.19846 14.19846 14.19846 14.19846 ## ## Formula: ~1 | Logger %in% g.1 %in% g.0 %in% g ## (Intercept) Residual ## StdDev: 0.3414393 1.007198 ## ## Fixed effects: y ~ X - 1 ## Value Std.Error DF t-value p-value ## X(Intercept) -1.736302 0.1798447 906 -9.654451 0.0000 ## XTypeDeciduous -0.137767 0.2578500 9 -0.534292 0.6061 ## XTypePrairie 0.499994 0.2555270 9 1.956717 0.0821 ## Xs(date_num):TypeConiferousFx1 -1.238174 1.0476349 906 -1.181875 0.2376 ## Xs(date_num):TypeDeciduousFx1 3.652453 1.4161295 906 2.579180 0.0101 ## Xs(date_num):TypePrairieFx1 0.042635 1.1659387 906 0.036567 0.9708 ## Correlation: ## X(Int) XTypDc XTypPr X(_):TC X(_):TD ## XTypeDeciduous -0.697 ## XTypePrairie -0.704 0.491 ## Xs(date_num):TypeConiferousFx1 -0.001 0.001 0.001 ## Xs(date_num):TypeDeciduousFx1 0.000 0.004 0.000 0.000 ## Xs(date_num):TypePrairieFx1 0.000 0.000 0.001 0.000 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.0136973 -0.4288093 0.0765251 0.5515962 3.2003331 ## ## Number of Observations: 921 ## Number of Groups: ## g g.0 %in% g ## 1 1 ## g.1 %in% g.0 %in% g Logger %in% g.1 %in% g.0 %in% g ## 1 12 1.3.4 Model validation ロガーごとの標準化残差を時系列的に図示したのが下図である。ここからパターンを読み取るのは難しい。 sn2 %&gt;% mutate(resid = resid(m2_4$lme, type = &quot;n&quot;)) %&gt;% ggplot(aes(x = date_num, y = resid))+ geom_point()+ geom_smooth(color = &quot;grey23&quot;)+ facet_rep_wrap(~Logger, scales = &quot;free_y&quot;) 時系列相関があるかを調べるためには、自己相関関数(acf)を描くことが有効である。自己相関関数は、k時点前のデータとの相関をkの関数としてあらわしたものである。 以下で、ロガーごとに時系列相関を算出する。 sn2 %&gt;% mutate(resid = resid(m2_4$lme, type = &quot;n&quot;)) %&gt;% group_by(Logger) %&gt;% arrange(date_num, .by_group = TRUE) -&gt; sn3 Loggerid &lt;- unique(sn3$Logger) all.out &lt;- NULL for(i in seq_along(Loggerid)){ data &lt;- sn3 %&gt;% filter(Logger == Loggerid[i]) ## 各ロガーについて時系列相関を算出 out.acf &lt;- acf(data$resid, lag.max = 15, plot = FALSE) ## 出力をデータフレームに out.df &lt;- data.frame(Timelag = out.acf$lag, Acf = out.acf$acf, SE = qnorm(0.975)/sqrt(out.acf$n.used), ID = Loggerid[i]) ## 全て結合 all.out &lt;- bind_rows(all.out, out.df) } 図示したのが下図である。グレーの塗りつぶしは95%信頼区間を表している。図から、全てのロガーにおいて1時点前のデータとの相関が高いことが示唆される。これは、残差に時系列相関があることを示しており、これを考慮したモデルを作成する必要性を示唆している。 all.out %&gt;% ggplot(aes(x = Timelag, y = 0))+ geom_segment(aes(xend = Timelag, yend = Acf))+ geom_ribbon(aes(ymax = SE, ymin = -SE), alpha = 0.3)+ theme_bw()+ theme(aspect.ratio = 0.8)+ facet_rep_wrap(~ID, repeat.tick.labels = TRUE)+ labs(y = &quot;Auto-correlation&quot;) acfの代わりにバリオグラムを用いることもできる。これは、時間間隔が一定でない場合などに有効である。これについては後でもう一度触れる。 References "],["Chapter3.html", "2 Time series and GLS 2.1 Ospreys 2.2 Covariance and correlation coefficients 2.3 Linear regression models 2.4 Focusing on the residual covariance matrix 2.5 Dependency and the covariance matrix 2.6 Dealing with temporal dependency 2.7 Multiple time series", " 2 Time series and GLS 本章では、時系列データに対して用いることができる回帰モデルについて解説する。 2.1 Ospreys Steidl et al. (1991) は、ミサゴの卵の厚さが殺虫剤の崩壊産物(DDD)によって変わるかを調べ、有意な関連を見つけた。本節ではこのデータを用いる。 osp &lt;- read_csv(&quot;data/Ospreys.csv&quot;) datatable(osp, options = list(scrollX = 20), filter = &quot;top&quot;) 2.2 Covariance and correlation coefficients DDDと卵の殻の厚さの関連は以下の通り。 osp %&gt;% ggplot(aes(x = DDD, y = THICK))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio=1) 相関係数は-0.42である。 cor(osp$THICK, osp$DDD) ## [1] -0.4195692 2.3 Linear regression models 以下のモデルを考える。 \\[ \\begin{aligned} Thichness_i &amp;= \\beta_1 + \\beta_2 \\times DDD_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] Rでは以下のように実行する。 m3_1 &lt;- lm(THICK ~ DDD, data = osp) 2.4 Focusing on the residual covariance matrix 残差\\(\\epsilon_i\\)は行列式で以下のように書ける。なお、\\(\\bf{I}\\)は単位行列である。 \\[ \\bf{\\epsilon} \\sim N(0, \\bf{\\sigma^2} \\times \\mathbf{I}) \\] より一般的に、残差\\(\\epsilon_i\\)は以下のように書ける。\\(\\bf{\\Sigma}\\)は分散共分散行列と呼ばれる。 \\[ \\bf{\\epsilon} \\sim N(0, \\bf{\\Sigma}) \\] 通常の線形回帰モデルでは、\\(\\bf{\\Sigma}\\)は以下のようになる。ここで、\\(sigma^2\\)に単位行列を書けるということは、残差間が独立であることを仮定していることになる。例えば、1行2列目は\\(\\epsilon_1\\)と\\(\\epsilon_2\\)の共分散を表すが、単位行列ではこれが0になる。同様に、単位行列は対角成分以外が全て0になるので、異なる残差同士の共分散が全て0になると仮定していることになる。 \\[ \\bf{\\Sigma} = \\sigma^2 \\times \\mathbf{I} \\] より一般的には、分散共分散行列\\(\\bf{\\Sigma}\\)は以下のように書ける。これは対称行列である。\\(\\phi_{i,j}\\)は\\(\\epsilon_i\\)と\\(\\epsilon_j\\)の共分散である。通常の回帰分析ではこれらが全て0と仮定された。共分散が０以外の値をとる場合、異なる残差は独立ではなくなる。 \\[ \\bf{\\Sigma} = \\begin{pmatrix} \\sigma^2 &amp; \\phi_{1,2} &amp; \\phi_{1,3} &amp; \\phi_{1,4} &amp; \\cdots &amp;\\phi_{1,25} \\\\ &amp; \\sigma^2 &amp; \\phi_{2,3} &amp; \\phi_{2,4} &amp; \\cdots&amp; \\phi_{2,25}\\\\ &amp; &amp; \\sigma^2 &amp; \\phi_{3,4} &amp; \\cdots &amp; \\phi_{3,25} \\\\ &amp; &amp; &amp; \\sigma^2 &amp; \\ddots &amp; \\vdots \\\\ &amp; &amp; &amp; &amp; \\sigma^2 &amp; \\phi_{24,25}\\\\ &amp; &amp; &amp; &amp; &amp; \\sigma^2 \\end{pmatrix} \\tag{2.1} \\] 2.5 Dependency and the covariance matrix ここで、回帰モデルにおける分散共分散行列の役割について理解するためにシミュレーションを行う。変数\\(z_1\\)と\\(z_2\\)が以下に従って1000個ずつ得られるとする。 \\[ \\begin{aligned} z_1 &amp;\\sim N(10,1)\\\\ z_2 &amp;\\sim N(15,1) \\end{aligned} \\] Rでは以下のように得る。 set.seed(1234) z1 &lt;- rnorm(1000, 10, 1) z2 &lt;- rnorm(1000, 15, 1) MASSパッケージのmvrnorm関数を用い、多変量正規分布から同様に値を行列として得ることもできる。 sigma &lt;- diag(2) Z &lt;- mvrnorm(1000, mu = c(10, 15), Sigma = sigma) %&gt;% data.frame() %&gt;% rename(z1 = 1, z2 = 2) datatable(Z) このとき、\\(z_1\\)と\\(z_2\\)は行列を用いると以下のように多変量正規分布から得られていると書くことができる。これは、平均がそれぞれ10と15で、分散共分散行列\\(\\bf{\\Sigma}\\)が単位行列の多変量正規分布から値が得られたことを示す。 \\[ \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = N \\Bigl( \\begin{pmatrix} 10 \\\\ 15 \\end{pmatrix}, \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ \\end{pmatrix} \\Bigl) \\] 得られたデータをプロットして分かるように、分散共分散行列が単位行列であり、\\(z_1\\)と\\(z_2\\)の間の共分散はゼロとなっているため、これらに相関が全くないことが分かる。 Z %&gt;% ggplot(aes(x = z1, y = z2))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1) 今度は、\\(z_1\\)と\\(z_2\\)が正の相関を持つような場合を考える。このようなときは、以下のように\\(\\bf{\\Sigma}\\)の\\(\\phi\\)成分を0でなく正の値にしてやればよい(ここでは0.9)。分散を1にしているので、この値はそのまま相関係数になる。 sigma &lt;- diag(2) sigma[1,2] &lt;- 0.9 sigma[2,1] &lt;- 0.9 sigma ## [,1] [,2] ## [1,] 1.0 0.9 ## [2,] 0.9 1.0 実際に得られた値をプロットしても、\\(z_1\\)と\\(z_2\\)が強い相関を持つことが分かる。このように、\\(\\bf{Sigma}\\)の非対角成分に0以外の値を割り当てることで、多変量正規分布から得られる値が非独立であることを表現できる。 Z &lt;- mvrnorm(1000, mu = c(10, 15), Sigma = sigma) %&gt;% data.frame() %&gt;% rename(z1 = 1, z2 = 2) Z %&gt;% ggplot(aes(x = z1, y = z2))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1) 2.6 Dealing with temporal dependency 同様に、時系列データに対しても、残差の分散共分散行列の非対角成分\\(\\phi_{i,j}\\)を0以外の値にすることで、データの非独立性に対処することができる。そのような方法の一つがGLS(Generalized least square)と呼ばれる方法である。 2.6.1 Adelie penguins ここでは、 Barbraud and Weimerskirch (2006) が南極の海鳥が到着する日と産卵日について調査したデータを用いる。ここでは、特に産卵日について着目する。 データは以下の通り。各年について1つのデータがある。 bird &lt;- read_csv(&quot;data/Phenology_Data_Antarcticbirds_AFZ1.csv&quot;) datatable(bird, options = list(scrollX = 20), filter = &quot;top&quot;) 分析では、海氷面積によって産卵日に違いが出るかを調べる。海氷面積の直接的なデータはないので、その近似として海中のメタルスルホン酸(MSA: 海氷が多いと多くなる)を用いる。 産卵日の年変動と、MSAと産卵日の関係は以下のようになる。 bird %&gt;% ggplot(aes(x = Year, y = LayingAP))+ geom_line()+ geom_point()+ theme_bw()+ theme(aspect.ratio = 0.7)+ labs(y = &quot;Laying date&quot;) -&gt; p1 bird %&gt;% ggplot(aes(x = MSA, y = LayingAP))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Laying date&quot;) -&gt; p2 p1 + p2 2.6.2 Do we have dependency? 産卵日に影響する様々な要因(成熟したメスの数、病気の流行、ホルモンレベル)などは年ごとに独立ではなく、t年のデータがt+1年のデータに影響を及ぼしていると考えられる。よって、各年の産卵日は独立ではないと考えられる。 2.6.3 Formulation of the linear regression model まずは時系列を考慮しない通常の線形回帰モデルを適用する。モデル式は以下の通り。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 2.6.4 Application of the linear regression model Rでは以下のように実行する。ここでは、nlmeパッケージのgls関数を用いる(もちろん、lm関数でも実行できる)。 m3_2a &lt;- gls(LayingAP ~ MSA, data = bird, na.action = na.omit) 結果は以下の通り。MSAの効果は弱いことが分かる。 summary(m3_2a) ## Generalized least squares fit by REML ## Model: LayingAP ~ MSA ## Data: bird ## AIC BIC logLik ## 139.7118 144.0137 -66.85588 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 247.91825 1.25111 198.15867 0.0000 ## MSA -33.01513 16.42976 -2.00947 0.0533 ## ## Correlation: ## (Intr) ## MSA -0.956 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -1.5831272 -0.5845941 -0.1200808 0.5813974 1.9238887 ## ## Residual standard error: 2.111689 ## Degrees of freedom: 33 total; 31 residual モデルの標準化残差と予測値、MSAとの関連をプロットしたのが以下の図である。数字は観察年の下２桁を表す。明確なパターンは見当たらない。しかし、よく見てみると観察年が近いと似た残差をとる傾向があるように思える。例えば、60年代のデータは全て残差が負の値になっている。 data.frame(resid = resid(m3_2a, type = &quot;n&quot;), Year = bird %&gt;% drop_na(LayingAP, MSA) %&gt;% .$Year, fitted = predict(m3_2a), MSA = bird %&gt;% drop_na(LayingAP, MSA) %&gt;% .$Year) %&gt;% mutate(Year2 = str_sub(Year, 3,4)) -&gt; fitted_m3_2a fitted_m3_2a %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1, size = 2)+ geom_text_repel(aes(label = Year2))+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw(base_size = 14)+ theme(aspect.ratio = 1) -&gt; p1 fitted_m3_2a %&gt;% ggplot(aes(x = MSA, y = resid))+ geom_point(shape = 1, size = 2)+ geom_text_repel(aes(label = Year2))+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw(base_size = 14)+ theme(aspect.ratio = 1) -&gt; p2 p1 + p2 自己相関関数をプロットしてみると、あまり明確にはわからないが有意に自己相関が高いところがあることが分かる。 resid &lt;- rep(NA, nrow(bird)) i &lt;- !is.na(bird$LayingAP) &amp; !is.na(bird$MSA) resid[i] &lt;- resid(m3_2a, type = &quot;n&quot;) acf &lt;- acf(resid, lag.max = 20, na.action = na.pass, plot = FALSE) data.frame(lag = 0:20, acf = acf$acf, SE = qnorm(0.975)/sqrt(acf$n.used)) %&gt;% ggplot(aes(x = lag, y = 0))+ geom_segment(aes(xend = lag, yend = acf))+ geom_hline(aes(yintercept = -SE), linetype = &quot;dashed&quot;, color = &quot;navy&quot;)+ geom_hline(aes(yintercept = SE), linetype = &quot;dashed&quot;, color = &quot;navy&quot;)+ theme_bw()+ labs(y = &quot;acf&quot;)+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(0,20,1)) 欠損値が多いので、バリオグラムで見た方が適切かもしれない。バリオグラムは以下のようになる。バリオグラムは水平にならず、やはり残差に時間的な相関があることが示唆される。 vario_3_2a &lt;- data.frame(resid = resid, Year = bird$Year, zero = 0) %&gt;% drop_na() sp::coordinates(vario_3_2a) &lt;- c(&quot;Year&quot;, &quot;zero&quot;) vario_3_2a %&gt;% variogram(resid ~ 1, data = ., cutoff = 9, width = 1) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_line()+ geom_point(size = 3, shape = 21, fill = &quot;black&quot;, color = &quot;white&quot;, stroke = 2)+ theme_bw(base_size = 14)+ theme(aspect.ratio = 1)+ labs(y = &quot;semivariogram&quot;, x = &quot;Time lag&quot;)+ coord_cartesian(ylim = c(0,1.4))+ scale_x_continuous(breaks = seq(1,9,1))+ scale_y_continuous(breaks = seq(0,1.4,0.2)) こうした時系列相関が問題になりうるかを判断するためには、時系列相関を考慮したモデルを作成し、それを考慮しないモデルと比較する必要がある。 2.6.5 Formulation of the GLS model 通常の回帰モデルでは異なる残差同士が独立(相関が0)なので、以下のように書くことができる。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2)\\\\ cor(\\epsilon_t, \\epsilon_s) &amp;= \\begin{cases} 0 \\; \\bf{if} \\;t \\neq s \\\\ 1 \\; \\bf{if} \\;t = s \\end{cases} \\end{aligned} \\] これまでに見てきたように、時系列相関を考慮するためには異なる残差同士の相関が0でないと仮定すればよい。これは、以下のように書ける。なお、\\(h()\\)は残差同士の相関を決める関数で\\(\\phi\\)はその関数におけるパラメータである。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2)\\\\ cor(\\epsilon_t, \\epsilon_s) &amp;= h(\\phi, \\epsilon_t, \\epsilon_s) \\end{aligned} \\] 時系列相関を考慮したモデルでは、この\\(h()\\)に様々な関数を想定することで、データの非独立性に対応する。最も一般的なものは、AR1過程と呼ばれるもので、以下のように書ける。なお、\\(\\phi\\)は0から1の値をとる。 \\[ \\begin{aligned} \\epsilon_t &amp;= \\phi \\times \\epsilon_{t-1} + \\nu_t \\\\ \\nu_t &amp;\\sim N(0, \\sigma_\\nu^2) \\end{aligned} \\] 関数\\(h()\\)は以下のように書ける。このとき、残差は定常性を持つといわれる。これは、残差の共分散は時間差のみに依存しているということである。 \\[ h(\\phi, \\epsilon_t, \\epsilon_s) = \\phi^{|t-s|} \\] AR1で残差の分散共分散行列\\(\\bf{\\Sigma}\\)は以下のように書ける。行列中のパラメータは$$1つなので、これさえ推定できれば良い。 \\[ \\bf{\\Sigma} = cov(\\bf{\\epsilon}) = \\frac{\\sigma_{\\nu}^2}{1-\\phi^2} \\times \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi^2 &amp; \\phi^3 &amp; \\cdots &amp; \\phi^{54} \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi^2 &amp; \\ddots &amp; \\vdots\\\\ \\phi^2 &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^3 \\\\ \\phi^3 &amp; \\phi^2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^2 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi^{54} &amp; \\cdots &amp; \\phi^2 &amp; \\phi^2 &amp; \\phi &amp; 1 \\end{pmatrix} \\] 相関行列は以下のように書ける。 \\[ cor(\\bf{\\epsilon}) = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi^2 &amp; \\phi^3 &amp; \\cdots &amp; \\phi^{54} \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi^2 &amp; \\ddots &amp; \\vdots\\\\ \\phi^2 &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^3 \\\\ \\phi^3 &amp; \\phi^2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^2 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi^{54} &amp; \\cdots &amp; \\phi^3 &amp; \\phi^2 &amp; \\phi &amp; 1 \\end{pmatrix} \\] AR1では、回帰係数の推定値とその分散共分散行列は以下のようになる。 \\[ \\begin{aligned} \\bf{\\hat{\\beta}} &amp;= (\\bf{X^t} \\times \\bf{\\Sigma^{-1}} \\times \\bf{X})^{-1} \\times \\bf{X^t} \\times \\bf{\\Sigma^{-1}} \\times \\bf{y}\\\\ cov(\\hat{\\beta}) &amp;= (\\bf{X^t} \\times \\bf{\\Sigma^{-1}} \\times \\bf{X})^{-1} \\end{aligned} \\] AR1過程モデルの代わりに、残差が他の相関構造をもつものを仮定することもできる。例えば、交換可能(exchangable)な相関を持つ場合、相関行列は以下のように書ける。これは、時間差に依らず全ての異なる残差が同じ相関\\(\\phi\\)を持つことを仮定している。これは、短い時系列を持つデータに対しては有効である場合がある。 \\[ cor(\\bf{\\epsilon}) = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\cdots &amp; \\phi \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi &amp; \\ddots &amp; \\vdots\\\\ \\phi &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi\\\\ \\phi &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi\\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi &amp; \\cdots &amp; \\phi &amp; \\phi &amp; \\phi &amp; 1 \\\\ \\end{pmatrix} \\] 2.6.6 Implementation using the gls function AR1モデルのGLSのモデル式を書くと以下のようになる。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2)\\\\ cor(\\epsilon_t, \\epsilon_s) &amp;= \\phi^{|t-s|} \\end{aligned} \\] Rでは以下のように実行できる。gls関数では、correlation =オプションで様々な残差の相関構造をモデリングできる。例えば、交換可能な相関の場合は、correlation = corCompSymm()とする。 m3_2b &lt;- gls(LayingAP ~ MSA, correlation = corAR1(form = ~Year), data = bird, na.action = na.omit) 結果は以下の通り。推定された\\(phi\\)は0.523である。驚くべきことに、時系列相関を考慮しない場合にはMSAの係数が負の値だったのに対して、今回は正の値になっている。 summary(m3_2b) ## Generalized least squares fit by REML ## Model: LayingAP ~ MSA ## Data: bird ## AIC BIC logLik ## 138.8594 144.5953 -65.42968 ## ## Correlation Structure: ARMA(1,0) ## Formula: ~Year ## Parameter estimate(s): ## Phi1 ## 0.5236874 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 244.57591 1.443356 169.44949 0.000 ## MSA 10.33068 17.311974 0.59674 0.555 ## ## Correlation: ## (Intr) ## MSA -0.896 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -1.5300255 -0.6243847 -0.0438220 0.7957452 2.0484887 ## ## Residual standard error: 2.345265 ## Degrees of freedom: 33 total; 31 residual モデルの予測値を図示したのが下図である。AR1モデルでは傾きが正になり、MSAと産卵日の関連はより小さなものと推定されている。 nd &lt;- data.frame(MSA =seq(0.03,0.14,length = 100)) data.frame(m3_2a = predict(m3_2a, newdata = nd), m3_2b = predict(m3_2b, newdata = nd), MSA = nd$MSA) %&gt;% pivot_longer(cols = 1:2, names_to = &quot;model&quot;, values_to = &quot;fitted&quot;) %&gt;% ggplot(aes(x = MSA, y = fitted))+ geom_line(aes(color = model), linewidth = 1)+ geom_text(aes(label = str_sub(bird$Year, 3,4), y = LayingAP), data = bird)+ theme_bw()+ theme(aspect.ratio = 0.9)+ scale_color_nejm()+ labs(y = &quot;Laying date&quot;) AICを比較しても、AR1モデルの方がわずかに予測がよいことが分かる。 AIC(m3_2a, m3_2b) 2.7 Multiple time series 第1.3節でみた積雪量と雪下温度の関連を調べた Petty et al. (2015) のデータについてもう一度考える。式@ref(eq:m2.4)のモデルでは、各時系列の残差が自己相関を持っていた。そこで、以下のモデルを考える(回帰係数は省略)。 \\[ \\begin{aligned} &amp;T_{it} = \\alpha + f_j(date\\_num_t) + Type_i + a_i + \\epsilon_{it}\\\\ &amp;a_i \\sim N(0, \\sigma_{Logger}^2)\\\\ &amp;\\epsilon_{it} \\sim N(0, \\sigma^2)\\\\ &amp;cor(\\epsilon_{it}, \\epsilon_{is}) = \\phi^{|t-s|} \\end{aligned} (\\#eq:m3.3) \\] Rでは、以下のように実行できる。ランダム切片を含む場合、自己相関は自動的にそれぞれのロガーに対して適用されるため、correlation = corAR1(form =~date_num)としても同じ結果が得られる。Rのgamm関数では全てのロガーについて同じ\\(\\phi\\)しか推定できない。 m3_3 &lt;- gamm(Temp ~ s(date_num, by = Type) + Type, random = list(Logger =~ 1), correlation = corAR1(form = ~date_num|Logger), data = sn2 %&gt;% mutate(Type = as.factor(Type))) 例えば、ロガー1の残差の相関行列は以下のように書ける。 \\[ \\bf{\\Sigma_1} = cor \\begin{pmatrix} \\epsilon_{1,1}\\\\ \\epsilon_{1,2}\\\\ \\vdots\\\\ \\epsilon_{1,88}\\\\ \\epsilon_{1,89} \\end{pmatrix} = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi^2 &amp; \\phi^3 &amp; \\cdots &amp; \\phi^{89} \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi^2 &amp; \\ddots &amp; \\vdots\\\\ \\phi^2 &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^3 \\\\ \\phi^3 &amp; \\phi^2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^2 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi^{89} &amp; \\cdots &amp; \\phi^3 &amp; \\phi^2 &amp; \\phi &amp; 1 \\end{pmatrix} \\] gamm関数で推定した場合、全てのロガーで同じ\\(\\phi\\)が推定されるので、どのロガーの残差の相関行列も\\(\\bf{\\Sigma_1}\\)となる。よって、すべてのロガーの残差の相関行列は以下のように書ける。対角成分以外が0なのは、異なるロガーの残差の相関は0である(= 独立である)ことを表している。 \\[ \\begin{aligned} cor \\begin{pmatrix} \\begin{pmatrix} \\epsilon_{1,1}\\\\ \\vdots\\\\ \\epsilon_{1,89} \\end{pmatrix}\\\\ \\begin{pmatrix} \\epsilon_{2,1}\\\\ \\vdots\\\\ \\epsilon_{2,89} \\end{pmatrix}\\\\ \\vdots \\\\ \\begin{pmatrix} \\epsilon_{12,1}\\\\ \\vdots\\\\ \\epsilon_{12,89} \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} \\bf{\\Sigma_1} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\bf{\\Sigma_2} &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\bf{\\Sigma_{12}} \\\\ \\end{pmatrix} = \\begin{pmatrix} \\bf{\\Sigma_1} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\bf{\\Sigma_1} &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\bf{\\Sigma_{1}} \\\\ \\end{pmatrix} \\end{aligned} \\] 結果は以下の通り。\\(\\phi\\)は0.504と推定されている。 summary(m3_3$lme) ## Linear mixed-effects model fit by maximum likelihood ## Data: strip.offset(mf) ## AIC BIC logLik ## 2587.526 2645.432 -1281.763 ## ## Random effects: ## Formula: ~Xr - 1 | g ## Structure: pdIdnot ## Xr1 Xr2 Xr3 Xr4 Xr5 Xr6 Xr7 Xr8 ## StdDev: 16.80172 16.80172 16.80172 16.80172 16.80172 16.80172 16.80172 16.80172 ## ## Formula: ~Xr.0 - 1 | g.0 %in% g ## Structure: pdIdnot ## Xr.01 Xr.02 Xr.03 Xr.04 Xr.05 Xr.06 Xr.07 Xr.08 ## StdDev: 12.99064 12.99064 12.99064 12.99064 12.99064 12.99064 12.99064 12.99064 ## ## Formula: ~Xr.1 - 1 | g.1 %in% g.0 %in% g ## Structure: pdIdnot ## Xr.11 Xr.12 Xr.13 Xr.14 Xr.15 Xr.16 Xr.17 Xr.18 ## StdDev: 10.23867 10.23867 10.23867 10.23867 10.23867 10.23867 10.23867 10.23867 ## ## Formula: ~1 | Logger %in% g.1 %in% g.0 %in% g ## (Intercept) Residual ## StdDev: 0.2900993 1.070964 ## ## Correlation Structure: ARMA(1,0) ## Formula: ~date_num | g/g.0/g.1/Logger ## Parameter estimate(s): ## Phi1 ## 0.5039287 ## Fixed effects: y ~ X - 1 ## Value Std.Error DF t-value p-value ## X(Intercept) -1.7091286 0.1769862 906 -9.656845 0.0000 ## XTypeDeciduous -0.1055758 0.2601888 9 -0.405766 0.6944 ## XTypePrairie 0.5034402 0.2537067 9 1.984339 0.0785 ## Xs(date_num):TypeConiferousFx1 -1.2565046 1.4583432 906 -0.861597 0.3891 ## Xs(date_num):TypeDeciduousFx1 3.0138336 1.7648757 906 1.707675 0.0880 ## Xs(date_num):TypePrairieFx1 0.4391241 1.4170564 906 0.309885 0.7567 ## Correlation: ## X(Int) XTypDc XTypPr X(_):TC X(_):TD ## XTypeDeciduous -0.680 ## XTypePrairie -0.698 0.475 ## Xs(date_num):TypeConiferousFx1 0.006 -0.004 -0.004 ## Xs(date_num):TypeDeciduousFx1 0.000 -0.004 0.000 0.000 ## Xs(date_num):TypePrairieFx1 0.000 0.000 0.001 0.000 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.4057668 -0.4121370 0.1026576 0.5351727 2.4662264 ## ## Number of Observations: 921 ## Number of Groups: ## g g.0 %in% g ## 1 1 ## g.1 %in% g.0 %in% g Logger %in% g.1 %in% g.0 %in% g ## 1 12 最後に、モデルの残差の自己相関関数(acf)を図示する。 sn2 %&gt;% mutate(resid = resid(m3_3$lme, type = &quot;n&quot;)) %&gt;% group_by(Logger) %&gt;% arrange(date_num, .by_group = TRUE) -&gt; sn3 Loggerid &lt;- unique(sn3$Logger) all.out &lt;- NULL for(i in seq_along(Loggerid)){ data &lt;- sn3 %&gt;% filter(Logger == Loggerid[i]) ## 各ロガーについて時系列相関を算出 out.acf &lt;- acf(data$resid, lag.max = 15, plot = FALSE) ## 出力をデータフレームに out.df &lt;- data.frame(Timelag = out.acf$lag, Acf = out.acf$acf, SE = qnorm(0.975)/sqrt(out.acf$n.used), ID = Loggerid[i]) ## 全て結合 all.out &lt;- bind_rows(all.out, out.df) } 図示したのが下図である。図からは、依然として多くのロガーでは時系列相関があることが分かる。よって、単にAR1モデルを適用するだけでは問題は解決できていない。 all.out %&gt;% ggplot(aes(x = Timelag, y = 0))+ geom_segment(aes(xend = Timelag, yend = Acf))+ geom_ribbon(aes(ymax = SE, ymin = -SE), alpha = 0.3)+ theme_bw()+ theme(aspect.ratio = 0.8)+ facet_rep_wrap(~ID, repeat.tick.labels = TRUE)+ labs(y = &quot;Auto-correlation&quot;) また、他の問題としてGAMMに時間のsmootherとAR1過程の両方が含まれている場合、これらが競合してしまう場合があることもある。この場合、どちらかのみを適用した方がよい。 References "],["Chapter4.html", "3 Spatial data and GLS 3.1 Variogram models for spatial dependency 3.2 Application on the Irish pH data 3.3 Matern correlation function", " 3 Spatial data and GLS 本章では、今度は空間的相関を持つデータにGLSを適用する。 3.1 Variogram models for spatial dependency 時系列データに対しては、異なる残差間の相関を以下のような関数\\(h()\\)で定義した。 \\[ h(\\phi, \\epsilon_t, \\epsilon_s) = \\phi^{|t-s|} \\] しかし、空間データに対して全く同じことをすることはできない。その代わり、残差のバリオグラムの形に応じて数学的モデルを選択し、それを用いて残差の分散共分散行列\\(\\bf{\\Sigma}\\)を計算することになる。nlmeパッケージには、corExp、corSpher、corLin、corGaus、corRatioなど、残差の空間的なパターンをモデリングするための様々なモデルがある(これらは、カーネルとも呼ばれる)。それぞれのモデルは2つのパラメータを持つ。詳細な数学的表現については、?corClassesでヘルプを参照するか、 Dale and Fortin (2014) や 村上 (2022) を参照。 例えば、指数バリオグラム(corExp)は以下のように定義される。なお、\\(s\\)は2地点間の距離、\\(\\phi\\)はレンジ(range)と呼ばれるパラメータであり、自己相関がなくなるまでの距離を表す。 \\[ h(s, \\phi) = 1 - e^{-\\frac{s}{\\phi}} \\] 同様に、球形(corSpher)は以下のように定義される。 \\[ \\begin{aligned} h(s, \\phi) = \\begin{cases} 1 - \\frac{3}{2}\\frac{s}{\\phi} + \\frac{3}{2}(\\frac{s}{\\phi})^3 \\;\\; &amp;if \\; 0 \\le s &lt; \\phi \\\\ 0 \\;\\; &amp;if \\; \\phi &lt; s \\end{cases} \\end{aligned} \\] また、ガウス型(corGaus)は以下のように定義される。 \\[ h(s, \\phi) = exp \\Bigl( -\\bigl( \\frac{s}{\\phi} \\bigl)^2 \\Bigl) \\] これらのモデルは距離が0のときバリオグラムの値も0になってしまうため、距離が0のときのバリオグラムの値を指定することができる(= ナゲット効果)。 様々なモデルのバリオグラムを図示したのが以下である。 #corExp mydata &lt;- data.frame(D = seq(0,1,by = 0.1)) cprExp &lt;- NULL phi_exp = c(0.2, 0.3, 0.5) nugget = 0.2 for(i in seq_along(phi_exp)){ corExp(c(phi_exp[i],nugget), form = ~ mydata$D, ## ナゲット効果 nugget = T,) %&gt;% Initialize(,data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_exp[i], type = &quot;Exponential&quot;) -&gt; vario.out cprExp &lt;- bind_rows(cprExp, vario.out) } #CorSpher cprSph &lt;- NULL phi_sph = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_sph)){ corSpher(c(phi_sph[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_sph[i], type = &quot;Spherical&quot;) -&gt; vario.out cprSph &lt;- bind_rows(cprSph, vario.out) } #CorGaus cprGaus &lt;- NULL phi_gaus = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_gaus)){ corGaus(c(phi_gaus[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_gaus[i], type = &quot;Gaussian&quot;) -&gt; vario.out cprGaus &lt;- bind_rows(cprGaus, vario.out) } #CorRatio cprRatio &lt;- NULL phi_ratio = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_ratio)){ corGaus(c(phi_ratio[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_ratio[i], type = &quot;Ratio&quot;) -&gt; vario.out cprRatio &lt;- bind_rows(cprRatio, vario.out) } #CorLin cprLin &lt;- NULL phi_lin = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_lin)){ corGaus(c(phi_lin[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_lin[i], type = &quot;Lin&quot;) -&gt; vario.out cprLin &lt;- bind_rows(cprLin, vario.out) } ## 図示 bind_rows(cprExp, cprGaus, cprSph, cprRatio, cprLin) %&gt;% mutate(phi = as.factor(phi)) %&gt;% ggplot(aes(x = dist, y = variog))+ geom_line(aes(group = phi))+ facet_rep_wrap(~type, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1) 分析は以下の5ステップで行う。 空間的相関を考慮せずにモデリングを行う。 1のモデルの残差のバリオグラムを書く。 バリオグラムの形を基に、どのバリオグラムモデルを適用するか決める。 バリオグラムモデルを含み、空間的相関を考慮したモデリングを行う。 4のモデルが問題ないかをチェックする。 3.2 Application on the Irish pH data 本節では、第1.2節で分析したアイルランドの河川のpHを調べたデータを再び用いる。空間的相関を考慮しない通常の線形回帰については第1.2節ですでに実行しているため、これに関する説明は省略する(step1とstep2)。図1.6からどのバリオグラムモデルが適切かを判断することが難しいため、可能なバリオグラムモデルを全て当てはめる。 iph %&gt;% mutate(Xkm = Easting/1000, Ykm = Northing/1000) -&gt; iph m4_1 &lt;- gls(pH ~ SDI + logAltitude*fForested, data = iph, method = &quot;REML&quot;) ## 指数モデル m4_1_exp &lt;- update(m4_1, correlation =corExp(form = ~ Xkm + Ykm, nugget = TRUE)) ## Linモデル m4_1_lin &lt;- update(m4_1, correlation =corLin(form = ~ Xkm + Ykm, nugget = TRUE)) ## Gausモデル m4_1_gau &lt;- update(m4_1, correlation =corGaus(form = ~ Xkm + Ykm, nugget = TRUE)) ## 球形モデル m4_1_sph &lt;- update(m4_1, correlation =corSpher(form = ~ Xkm + Ykm, nugget = TRUE)) ## Ratioモデル m4_1_rat &lt;- update(m4_1, correlation =corRatio(form = ~ Xkm + Ykm, nugget = TRUE)) 各モデルのAICを比較すると指数モデル(m4_1_exp)と比率モデル(m4_1_rat)が最もAICが低い。しかし、その他の空間的相関を考慮したモデルはむしろAICが高くなっていることが分かる。このことは、これらのモデルで推定されたレンジ(\\(\\phi\\))の値が0に近いことを示している。 AIC(m4_1, m4_1_exp, m4_1_gau, m4_1_lin, m4_1_rat, m4_1_sph) 実際、時数モデルと比率モデル以外はレンジの推定値がほとんど0になっていることが分かる。 bind_rows(coef(m4_1_exp$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_lin$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_gau$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_sph$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_rat$modelStruct$corStruct, unconstrained = FALSE)) %&gt;% mutate(model = c(&quot;Exp&quot;,&quot;Lin&quot;,&quot;Gaussian&quot;,&quot;Spherical&quot;,&quot;Ratio&quot;)) %&gt;% select(model, everything()) これは、gls関数ではレンジphiを推定する際に、指定しなければ最短の距離の90%の値をアルゴリズムの初期値として使用するために生じている。この問題を回避するためには、以下のようにvalue =で初期値を指定する必要がある。ここでは、レンジに50、ナゲットに0.1を割り当てている(Linモデルだけ収束しなかったので、レンジの初期値に25を割り当てている)。 ## 指数モデル m4_1_exp2 &lt;- update(m4_1, correlation =corExp(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) ## Linモデル m4_1_lin2 &lt;- update(m4_1, correlation =corLin(form = ~ Xkm + Ykm, nugget = TRUE, value = c(25, 0.1))) ## Gausモデル m4_1_gau2 &lt;- update(m4_1, correlation =corGaus(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) ## 球形モデル m4_1_sph2 &lt;- update(m4_1, correlation =corSpher(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) ## Ratioモデル m4_1_rat2 &lt;- update(m4_1, correlation =corRatio(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) 新しいモデルでは、レンジの推定値が0に近くなくなっている。 bind_rows(coef(m4_1_exp2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_lin2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_gau2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_sph2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_rat2$modelStruct$corStruct, unconstrained = FALSE)) %&gt;% mutate(model = c(&quot;Exp&quot;,&quot;Lin&quot;,&quot;Gaussian&quot;,&quot;Spherical&quot;,&quot;Ratio&quot;)) %&gt;% select(model, everything()) これらのモデルのAICを比較すると、相関構造としてcorLinを持つモデルが最もAICが低いことが分かった。 AIC(m4_1, m4_1_exp2, m4_1_gau2, m4_1_lin2, m4_1_rat2, m4_1_sph2) このモデルの結果は以下の通り。 summary(m4_1_lin2) ## Generalized least squares fit by REML ## Model: pH ~ SDI + logAltitude * fForested ## Data: iph ## AIC BIC logLik ## 169.5945 196.1786 -76.79724 ## ## Correlation Structure: Linear spatial correlation ## Formula: ~Xkm + Ykm ## Parameter estimate(s): ## range nugget ## 67.2152946 0.5228704 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 8.175531 0.2766976 29.546811 0.0000 ## SDI -0.023739 0.0019874 -11.944746 0.0000 ## logAltitude 0.154131 0.1397899 1.102593 0.2715 ## fForestedyes 1.036179 0.3841835 2.697093 0.0076 ## logAltitude:fForestedyes -0.539765 0.1816375 -2.971661 0.0033 ## ## Correlation: ## (Intr) SDI lgAltt fFrstd ## SDI -0.061 ## logAltitude -0.931 -0.213 ## fForestedyes -0.380 -0.020 0.380 ## logAltitude:fForestedyes 0.411 -0.016 -0.406 -0.989 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -5.1573493 -0.5666860 -0.1527922 0.4324576 2.7694846 ## ## Residual standard error: 0.392704 ## Degrees of freedom: 210 total; 205 residual 空間相関を考慮しないモデル(m4_1)と比較すると、推定値が少し変化しているようだ。95%信頼区間は一般的に空間的相関を考慮すれば大きくなるが、今回はあまり変わっていないように見える。 compare_parameters(m4_1, m4_1_lin2) バリオグラムを描画すると、まだ空間的相関が少しありそう? vario_4_1 &lt;- data.frame(resid = resid(m4_1_lin2, type = &quot;n&quot;), Xkm = iph$Xkm, Ykm = iph$Ykm) sp::coordinates(vario_4_1) &lt;- c(&quot;Xkm&quot;, &quot;Ykm&quot;) vario_4_1 %&gt;% variogram(resid ~ Xkm + Ykm, data = ., ## 0が南北方向、90が東西方向 alpha = c(0, 90), cressie = TRUE, cutoff = 150, width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ dir.hor, labeller = as_labeller(c(&quot;0&quot; = &quot;North-South&quot;, &quot;90&quot; = &quot;East-West&quot;)))+ labs(y = &quot;semivariogram&quot;) 3.3 Matern correlation function Matern相関関数は指数モデルとガウスモデルを包含するもので、以下のように書ける。なお、\\(s_i\\)と\\(s_j\\)はデータ\\(i\\)と\\(j\\)の空間的な場所を、\\(K_\\nu\\)は第2種ベッセル関数を、\\(||s_i - s_j||\\)はデータ\\(i\\)と\\(j\\)のユークリッド距離を表す(ベッセル関数については高度な数学が必要のため、理解しなくていい)。\\(\\kappa\\)はAR1過程モデルの\\(\\phi\\)やバリオグラムモデルのレンジに相当するものである。\\(\\Gamma()\\)はガンマ関数である。Matern関数は\\(\\nu\\)が0.5のとき指数モデルに、\\(\\nu = \\infty\\)のときはガウスモデルと一致する(村上 2022)。 \\[ cor_{Matern}(s_i, s_j) = \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\times (\\kappa \\times ||s_i - s_j||)^\\nu \\times K_\\nu(\\kappa \\times ||s_i - s_j||) \\] Matern相関関数を図示したのが図3.1である。AR1過程やバリオグラムモデルのように、空間的に近いデータ同士の相関は高く、空間的に離れるほど相関が低くなっていくことが分かる。Matern関数はglsには実装されていないが、のちに学ぶINLAパッケージには実装されている。 library(fields) crossing(kappa = c(0.02,0.07,0.2), distance = seq(0,100,length =100)) %&gt;% mutate(correlation = ifelse(distance != 0, (kappa * distance) * besselK(kappa * distance, 1), 1)) %&gt;% mutate(kappa = as.factor(kappa)) %&gt;% ggplot(aes(x = distance, y = correlation))+ geom_line(aes(linetype = kappa))+ theme_bw()+ theme(aspect.ratio = 1) 図3.1: Matern関数 References "],["Chapter5.html", "4 Linear mixed-effects models and dependency 4.1 White Storks 4.2 Considering the data (wrongly) as one-way nested 4.3 Fitting the one-way nested model using lmer 4.4 Model validation 4.5 Sketching the fitted value 4.6 Considering the data (correctly) as two-way nested 4.7 Differences with the AR1 process approach", " 4 Linear mixed-effects models and dependency 本節では、混合モデルがどのようにデータの非独立性に対処しているのかを見ていく。 4.1 White Storks ここでは、シュバシコウの成長に影響を与える要因を調べた Bouriach et al. (2015) の研究データを用いる。あるコロニー内の多くの巣から、各巣内の複数の雛のデータが複数回ずつにわたって最大生後54日まで収集されている。 ws &lt;- read_csv(&quot;data/whitestork.csv&quot;) datatable(ws, options = list(scrollX = 20), filter = &quot;top&quot;) 雛の成長度合いは、くちばし長で評価されている。図4.1は年齢とくちばし長の関連を図示したものである。 ws %&gt;% ggplot(aes(x = age, y = beak))+ geom_point(shape =1, size = 1.5)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Beak length&quot;, x = &quot;Age&quot;) 図4.1: Scatterplot of beak length (mm) of White Stork chicks versus age (in days). 4.2 Considering the data (wrongly) as one-way nested まず、以下のモデルを考える(回帰係数は省略している)。BLはくちばし長、Ageは日齢、Chickは雛のID、Nestはそのデータが得られた巣のIDを表す。 \\[ \\begin{aligned} BL_i &amp;= Intercept + Age_i + Nest_i + Chick_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] このモデルには2つの大きな問題がある。 巣IDと雛IDは多いので、モデルで膨大なパラメータを推定することになる。 同じ雛/巣から複数のデータが収集されており、疑似反復が生じている。 この問題を解決する方法として、巣ごとの平均をとることができるがサンプルサイズが著しく減少する。また、巣ごとの平均くちばし長というのは生物学的に見て意味のあるものだとは思えない。混合mドエルはこれらの問題を解決する。 4.2.1 model formulation まずは、以下の混合モデルを考える。このモデルは、雛IDについてはひとまず無視し、巣IDをランダム切片として含めている。なお、\\(i\\)は巣IDを表し、\\(j = 1,2,3,\\dots,n_i\\)は巣ごとのデータ数を表す。ここでは、\\(a_i\\)と\\(\\epsilon_{ij}\\)は独立であると仮定されている。 \\[ \\begin{aligned} BL_{ij} &amp;= Intercept + Age_{ij} + a_i + \\epsilon_{ij} \\\\ a_i &amp;\\sim N(0, \\sigma_{nest}^2)\\\\ \\epsilon_{ij} &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] このモデルは、以下のようにも書ける。 \\[ \\begin{aligned} BL_{ij} &amp;= N(\\mu_{ij}, \\sigma^2)\\\\ E(BL_{ij}) &amp;= \\mu_{ij} \\;\\; and \\;\\; var(BL_{ij}) = \\sigma^2 \\\\ \\mu_{ij} &amp;= Intercept + Age_{ij} + a_i \\\\ a_i &amp;\\sim N(0, \\sigma_{nest}^2)\\\\ \\end{aligned} \\tag{4.1} \\] 生態学では、一元配置入れ子モデル(one-way nested model)の線形混合効果モデルと呼ばれる。それでは、混合モデルはどのようにデータの非独立性に対応しているのだろうか。 同じ巣の雛同士は、同じ親に育てられ、生息環境が同じであり、遺伝的にも類似している。よって、同じ巣の雛のくちばし長は独立ではなく、他の巣の雛のくちばし長よりも類似していると考えられる。 同じ巣の雛のくちばし長同士の相関は、この混合モデルでは以下のように書ける。これは級内相関係数(inter class correlation: ICC)とも呼ばれる。なお、このモデルでは異なる巣の雛のくちばし長同士の相関は0であると仮定される。混合モデルでは、このように巣内のデータの非独立性が考慮される。 \\[ cor(BL_{ij}, BL_{ik}) = \\phi = \\frac{\\sigma_{nest}^2}{\\sigma_{nest}^2 + \\sigma^2} \\tag{4.2} \\] 巣1(データ数が6)のデータの相関行列は以下のように書ける。 \\[ \\bf{\\Sigma_1} = cor \\begin{pmatrix} BL_{1,1}\\\\ BL_{1,2}\\\\ BL_{1,3}\\\\ BL_{1,4}\\\\ BL_{1,5}\\\\ BL_{1,6}\\\\ \\end{pmatrix} = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi \\\\ \\phi &amp; \\phi &amp; 1 &amp; \\phi &amp; \\phi &amp; \\phi \\\\ \\phi &amp; \\phi &amp; \\phi &amp; 1 &amp; \\phi &amp; \\phi \\\\ \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; 1 \\\\ \\end{pmatrix} \\] 他の巣についても同じように書ける(データ数に応じて行列数が変わるだけである)。よって、全ての巣のデータの相関係数は以下のように書ける。なお、\\(n_1, n_2, \\dots, n_{73}\\)は各巣のデータ数である。以上で見たように、同じ巣のデータ同士の相関は\\(\\phi\\)、異なる巣のデータ同士の相関は0であると仮定される。 \\[ \\begin{aligned} cor \\begin{pmatrix} \\begin{pmatrix} BL_{1,1}\\\\ \\vdots\\\\ BL_{1,n_1} \\end{pmatrix}\\\\ \\begin{pmatrix} BL_{2,1}\\\\ \\vdots\\\\ BL_{2,n_2} \\end{pmatrix}\\\\ \\vdots \\\\ \\begin{pmatrix} BL_{73,1}\\\\ \\vdots\\\\ BL_{73,n_{73}} \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} \\bf{\\Sigma_1} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\bf{\\Sigma_2} &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\bf{\\Sigma_{73}} \\\\ \\end{pmatrix} \\end{aligned} \\] なお、式(4.2)は一つのランダム切片を持つ線形混合モデルについてのみ当てはまる。一般化線形混合モデル(GLMM)や2つ以上のランダム切片/ランダム傾きをもつ線形混合モデルについては異なる表現が用いられる。 混合モデルはGLSと同様にデータ間の相関をモデルに組み込むことによって、データの非独立性に対処している。なお、ランダム切片の分散\\(\\sigma_{nest}^2\\)について正確な推定を行うためには、少なくとも5以上のクラスター(今回の場合は巣ID)がなくてはならない。 4.3 Fitting the one-way nested model using lmer それでは、モデル(4.1)をRで実行する。ここでは、lme4パッケージのlmer関数を用いる。分析には2012年のデータのみを用いる。 ws2 &lt;- drop_na(ws, beak, age, nest, chick) %&gt;% mutate(fnest = as.factor(nest), fchick = as.factor(chick)) %&gt;% filter(year == &quot;2012&quot;) %&gt;% data.frame() m5_1 &lt;- lmer(beak ~ age + (1|fnest), data = ws2) 結果は以下の通り。 summary(m5_1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: beak ~ age + (1 | fnest) ## Data: ws2 ## ## REML criterion at convergence: 10234.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.9103 -0.5406 -0.0259 0.5768 6.3796 ## ## Random effects: ## Groups Name Variance Std.Dev. ## fnest (Intercept) 57.23 7.565 ## Residual 62.50 7.905 ## Number of obs: 1438, groups: fnest, 73 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 44.4417 0.9651 46.05 ## age 2.9925 0.0169 177.08 ## ## Correlation of Fixed Effects: ## (Intr) ## age -0.301 モデルの結果から、モデル式は以下のように推定されたことが分かる。2行目から\\(a_i\\)を除いた\\(\\mu_{ij} = 44.44 + 2.99\\times Age_{ij}\\)の部分はモデルのfixed partと呼ばれ、平均的な巣におけるくちばし長の期待値を表す(ランダム切片を含まないので)。 \\[ \\begin{aligned} BL_{ij} &amp;= N(\\mu_{ij}, 7.90^2)\\\\ \\mu_{ij} &amp;= 44.44 + 2.99\\times Age_{ij} + a_i \\\\ a_i &amp;\\sim N(0, 7.56^2)\\\\ \\end{aligned} \\] 級内相関\\(\\phi\\)は以下のように求められる。 \\[ \\phi = \\frac{7.56^2}{7.56^2 + 7.90^2} = 0.49 \\] Rでは以下のように求める。よって、同じ巣内のデータ同士の相関は0.47と推定されたことが分かる。 sigma_ranef &lt;- VarCorr(m5_1) %&gt;% as.data.frame() %&gt;% .[1,5] sigma_ranef^2/(sigma_ranef^2 + sigma(m5_1)^2) ## [1] 0.4780135 fixed partの予測値と95%信頼区間を表したのが図4.2である。 nd5_1 &lt;- data.frame(age = seq(min(ws2$age), max(ws2$age), by = 1)) ## 説明変数を含む行列 X &lt;- model.matrix(~age, data = nd5_1) ## 予測値と95％信頼区間の算出 fitted5_1 &lt;- nd5_1 %&gt;% ## 予測値はbeta × Xで求まる mutate(fitted = X %*% fixef(m5_1) %&gt;% .[,1]) %&gt;% ## 予測値のseは以下の通り mutate(se = sqrt(diag(X %*% vcov(m5_1) %*% t(X)))) %&gt;% mutate(ci.low = fitted - 1.96*se, ci.high = fitted + 1.96*se) fitted5_1 %&gt;% ggplot(aes(x = age, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = ci.low, ymax = ci.high), alpha = 0.2)+ geom_point(data = ws2, aes(y = beak), shape =1, size = 1.5)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Beak length&quot;, x = &quot;Age&quot;) 図4.2: Fixed part of the linear mixed-effects model. The shaded area is a 95% confidence interval for the mean. 4.4 Model validation このモデルはまだ性別の効果を考慮していない他、雛IDの非独立性についても考慮していない。よって、ここではモデル診断は行わない。 4.5 Sketching the fitted value それぞれの巣について推定された\\(a_i\\)は以下の通り。これは、モデルのrandom partと呼ばれる。 ranef(m5_1) %&gt;% data.frame() %&gt;% rename(estimated = condval, sd = condsd) %&gt;% mutate_if(is.numeric, ~round(., 2)) %&gt;% datatable() fixed partとrandom partを足した各巣の予測値を示したのが図4.3である。なお、赤い線は図4.2で示したfixed partのみの直線を示している。それぞれの直線は、ここランダム効果の分だけ上/下にシフトしている。 predict(m5_1) %&gt;% data.frame() %&gt;% rename(predicted = 1) %&gt;% bind_cols(ws2) %&gt;% ggplot(aes(x = age))+ geom_line(aes(y = predicted, group = fnest))+ geom_point(aes(y = beak), shape = 1,size =1.5)+ geom_line(data= fitted5_1, aes(y = fitted), color = &quot;red3&quot;, linewidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Beak length&quot;, x = &quot;Age&quot;) 図4.3: Fixed part plus the random effects for the linear mixed-effects model. 4.6 Considering the data (correctly) as two-way nested さて、それでは次に雛IDも考慮したモデルを考える。データでは同じ雛から複数のデータが収集されており、ここでも疑似反復が生じているからである。同じ雛から得られたデータは、同じ巣の他の雛のデータよりも類似していると考えられる。 以下のようなモデルを考える。このようなモデルは、two-way nested linear mixed-effects modelと呼ばれる。なお、\\(i\\)は巣IDを、\\(j\\)は巣ごとの雛IDを、\\(k\\)は巣\\(i\\)における\\(j\\)番目の雛の\\(k\\)個目のデータであることを表す。 \\[ \\begin{aligned} BL_{ijk} &amp;= N(\\mu_{ijk}, \\sigma^2)\\\\ E(BL_{ijk}) &amp;= \\mu_{ijk} \\;\\; and \\;\\; var(BL_{ijk}) = \\sigma^2 \\\\ \\mu_{ijk} &amp;= Intercept + Age_{ijk} + a_i + b_{ij} \\\\ a_i &amp;\\sim N(0, \\sigma_{nest}^2)\\\\ b_{ij} &amp;\\sim N(0, \\sigma_{chick}^2)\\\\ \\end{aligned} \\tag{4.3} \\] このモデルでは、同じ巣内の異なるデータ間に相関があり、かつ同じ雛の異なるデータ間にも相関があることを仮定している。なお、異なる巣のデータ間は独立だと仮定されている。 同じ巣内の同じ雛のデータ間の相関は以下の式で与えられる。 \\[ \\phi_{chick} = \\frac{\\sigma_{nest}^2 + \\sigma_{chick}^2}{\\sigma_{nest}^2 + \\sigma_{chick}^2 + \\sigma^2} \\] また、同じ巣内の異なる雛間のデータの相関は以下の式で表せられる。 \\[ \\phi_{nest} = \\frac{\\sigma_{nest}^2}{\\sigma_{nest}^2 + \\sigma_{chick}^2 + \\sigma^2} \\] このモデルは、Rで以下のように実行できる。 m5_2 &lt;- lmer(beak ~ age + (1|fnest/fchick), data = ws2) 結果は以下の通り。 summary(m5_2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: beak ~ age + (1 | fnest/fchick) ## Data: ws2 ## ## REML criterion at convergence: 9932.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.3657 -0.5617 -0.0678 0.5513 6.9810 ## ## Random effects: ## Groups Name Variance Std.Dev. ## fchick:fnest (Intercept) 29.70 5.449 ## fnest (Intercept) 47.81 6.915 ## Residual 40.81 6.388 ## Number of obs: 1438, groups: fchick:fnest, 262; fnest, 73 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 44.41110 0.93656 47.42 ## age 2.97532 0.01406 211.63 ## ## Correlation of Fixed Effects: ## (Intr) ## age -0.245 iccはそれぞれ\\(phi_{chick} = 0.66\\)、\\(phi_{nest} = 0.40\\)と推定された。 sigma_chick &lt;- VarCorr(m5_2) %&gt;% as.data.frame() %&gt;% .[1,5] sigma_nest &lt;- VarCorr(m5_2) %&gt;% as.data.frame() %&gt;% .[2,5] sigma &lt;- sigma(m5_2) ## phi_nest sigma_nest^2/(sigma^2 + sigma_chick^2 + sigma_nest^2) ## [1] 0.4040858 ## phi_chick (sigma_nest^2+sigma_chick^2)/(sigma^2 + sigma_chick^2 + sigma_nest^2) ## [1] 0.6550681 モデルの結果を図示したのが図4.4である。黒い線はモデルの fixed partの予測値を、赤い点線は巣6(Ap2)の予測値(\\(\\mu_{ijk} + a_i\\))を示している。また、2本の赤い直線は巣6の雛2頭の予測値(\\(\\mu_{ijk} + a_i + b_{ij}\\))を、赤い点はその2頭のデータを示している。これを見ると、2頭の雛の予測値は巣の予測値から近いことが分かる。これは、雛IDのランダム切片よりも巣IDのランダム切片の方が予測値への影響が大きいことを示している。\\(\\phi_{chick}\\)と\\(\\phi_{nest}\\)の値が近いほどこのことがいえる。 re_Ap2 &lt;- ranef(m5_2)$fnest[6,1] fitted5_2_fixed &lt;- ggpredict(m5_2, terms = &quot;age[1:54,by=0.1]&quot;, type = &quot;fixed&quot;) %&gt;% rename(age = x) %&gt;% mutate(fitted_Ap2 = predicted + re_Ap2) fitted5_2 &lt;- predict(m5_2) %&gt;% data.frame() %&gt;% bind_cols(ws2) %&gt;% rename(fitted = 1) fitted5_2_fixed %&gt;% ggplot(aes(x = age, y = predicted))+ geom_line(linewidth = 1)+ geom_line(aes(y = fitted_Ap2), data = . %&gt;% filter(age &gt;= 6 &amp; age &lt;= 29), linewidth = 0.8, color = &quot;red3&quot;, linetype = &quot;dashed&quot;)+ geom_line(data = fitted5_2 %&gt;% filter(fnest== &quot;Ap2&quot;), aes(y = fitted, group = fchick), color = &quot;red3&quot;, linewidth = 1)+ geom_point(data = ws2, aes(y = beak), shape = 1, size = 1) + geom_point(data = ws2 %&gt;% filter(fnest == &quot;Ap2&quot;), aes(y = beak, shape = fchick), size = 4, color = &quot;red3&quot;)+ scale_shape_manual(values = c(16,18))+ theme_bw()+ theme(aspect.ratio = 1) 図4.4: Fitted values due to the fixed part, fixed part + the random intercept Nest, and fixed part + the random intercept Nest + the random intercept Chick. one-way nested model とtwo-way nested model を比較するとパラメータの推定値と標準偏差がわずかに違う。AICを用いてどちらが良いかを調べることもできるが、疑似反復が解消されているtwo-way nested modelを選ぶべきである。 compare_parameters(m5_1, m5_2, select = &quot;{estimate}&lt;br&gt;({se})|{p}&quot;) %&gt;% data.frame() %&gt;% mutate_if(is.numeric, ~round(.,2)) %&gt;% select(1,4,5,12,13) 4.7 Differences with the AR1 process approach 第2章で見たような残差AR1過程モデルは残差に時間的な相関があると仮定して疑似反復に対処したが、必ずしも応答変数に時間的相関を仮定したわけではなかった。一方で、混合モデルは応答変数に従属構造があることを考慮して疑似反復に対処している。 References "],["Chapter6.html", "5 Modelling space explicitly 5.1 Model formulation 5.2 Covariance matrix of the spatial random effect 5.3 Spatial-temporal correlation", " 5 Modelling space explicitly 本章では、混合モデルのように残差ではなく応答変数に直接従属構造を仮定して空間的相関に対処する方法を見ていく。ただし、通常の混合モデルのランダム切片が正規分布からそれぞれ独立に得られると仮定する一方で、今回はランダム切片が空間的相関を持つことを仮定してモデリングを行う。こうしたモデルの実装を頻度論的な手法で行うことは難しいため、実際のモデリングは次章でベイズ統計について学んでから行う。 5.1 Model formulation ここでは、前章と同じくシュバシコウのデータ(Bouriach et al. 2015)を用いて話を進める。 まず通常の線形回帰モデルから始めよう。巣IDや雛IDの効果について無視したとき、以下のように書ける。\\(i\\)はデータの番号を表し、全部で1438ある。 \\[ \\begin{aligned} BL_i &amp;= \\alpha + Age_i \\times \\beta + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルは以下のようにも書ける。なお、\\(z_i = (1, Age_i)\\)である。1列目の1は切片を表している。\\(\\bf{\\beta} = \\begin{pmatrix} \\alpha\\\\ \\beta \\end{pmatrix}\\)である。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{5.1} \\] 式(5.1)は単純な線形回帰モデルであり、残差はそれぞれ正規分布から独立に得られると仮定されている。\\(\\bf{\\epsilon} = (\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_{1438})\\)とするとき、\\(\\bf{\\epsilon} \\sim N(0,\\bf{\\Sigma})\\)と書ける。なお、\\(\\bf{\\Sigma}\\)は\\(\\bf{I}\\)を単位行列とするとき\\(\\sigma^2 \\times \\bf{I}\\)と書ける。第2で見たように、このとき\\(\\bf{\\Sigma}\\)は対角成分以外が0の行列なので、残差同士の相関は0であると仮定されている。 そこで、空間的な相関に対処するために式(5.1)に空間的相関を表す要素を付け足す。本書では、これを\\(u_i\\)と表す。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + u_i + \\epsilon_i\\\\ epsilon_i &amp;\\sim N(0,\\sigma^2)\\\\\\ \\end{aligned} \\tag{5.2} \\] ここで、\\(u_i\\)は平均が0で、分散共分散行列が\\(\\bf{\\Omega}\\)に従う正規分布から得られると考える。ただし、\\(\\bf{\\Omega}\\)は通常のランダム切片のように対角行列(対角成分以外が0の行列)ではなく、空間相関を考慮している。 よって、このモデルは以下のように書ける。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + u_i + \\epsilon_i\\\\ \\bf{\\epsilon} &amp;\\sim N(0,\\sigma^2 \\times \\bf{I})\\\\ \\bf{u} &amp;\\sim N(0, \\bf{\\Omega}) \\end{aligned} \\tag{5.3} \\] 5.2 Covariance matrix of the spatial random effect \\(\\bf{\\Omega}\\)の成分全てを推定するのは非常に難しい。今回のように1438個のデータがあるのであれば、\\(1438 \\times 1437 \\times 1/2 = 1033203\\)このパラメータを推定してければいけなくなる。そこで、第2章(AR1過程)や第3章(バリオグラムモデル)でやったように、推定するパラメータを減らすために何らかの数理モデルを用いる。 ここでは、第3.3節で導入したMatern相関関数を用いる。この関数では、2つのパラメータさえ推定すればよい。 5.2.1 Simulation study 以下では、Matern関数がどのように\\(\\bf{\\Omega}\\)を決定するかをシミュレーションを用いて説明する。 以下のように、5つの場所をランダムに定める(図5.1)。 set.seed(123) Xloc &lt;- runif(5, 0, 1) Yloc &lt;- runif(5, 0, 1) Loc &lt;- cbind(Xloc, Yloc) Loc %&gt;% data.frame() %&gt;% mutate(n = 1:n()) %&gt;% ggplot(aes(x = Xloc, y = Yloc))+ geom_text(aes(label = n))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;X coordinates&quot;, y = &quot;Y coordinates&quot;)+ scale_x_continuous(breaks = seq(0.3,1,0.1))+ scale_y_continuous(breaks = seq(0,1,0.2)) 図5.1: Position of five sampling locations in our simulation study. ここで、それぞれの場所で雛のくちばし長のデータを収集したとする。式(5.2)より、5つのランダム切片\\(u_1, u_2, \\dots, u_5\\)を推定する必要がある。\\(u_i\\)は平均が0、分散共分散行列が\\(\\bf{\\Omega}\\)の正規分布から得られるとする。\\(\\bf{\\Omega}\\)は以下で与えられるとする。 \\[ \\bf{\\Omega} = \\sigma_u^2 \\times \\begin{pmatrix} 1 &amp; \\omega_{12} &amp; \\omega_{13} &amp; \\omega_{14} &amp; \\omega_{15} \\\\ &amp; 1 &amp; \\omega_{23} &amp; \\omega_{24} &amp; \\omega_{25} \\\\ &amp; &amp; 1 &amp; \\omega_{34} &amp; \\omega_{35} \\\\ &amp; &amp; &amp; 1 &amp; \\omega_{45} \\\\ &amp; &amp; &amp; &amp; 1 \\end{pmatrix} \\] ここで、行列の各要素はMatern関数によって定まるとする。第3.3節で見たように、Matern関数は距離と2つの未知のパラメータで定まる関数である。よって、この2つのパラメータが定まれば全ての\\(\\omega\\)が定まる。 \\[ \\omega_{ij} = cov(u_i,u_j) = \\sigma_u^2 \\times \\rm{Matern \\; correlation \\; sites \\; i \\; and\\;j} \\tag{5.4} \\] それでは、以下で実際にパラメータを定めて\\(\\omega_{ij}\\)を計算してみよう。まず、データ間の距離を算出する。 Dist &lt;- dist(Loc) %&gt;% as.matrix() Dist ## 1 2 3 4 5 ## 1 0.0000000 0.69540037 0.8555197 0.78132050 0.7715140 ## 2 0.6954004 0.00000000 0.5259413 0.09754322 0.1681197 ## 3 0.8555197 0.52594131 0.0000000 0.58393877 0.6873190 ## 4 0.7813205 0.09754322 0.5839388 0.00000000 0.1108665 ## 5 0.7715140 0.16811974 0.6873190 0.11086647 0.0000000 次にMatern関数のパラメータを定める。ここでは、\\(\\kappa = 4, \\nu = 1\\)とする。また、\\(\\sigma_u\\)も1とする。 kappa &lt;- 5 nu &lt;- 1 sigma_u &lt;- 1 式(5.4)より、\\(\\omega_{ij}\\)は以下のように求まる。 d.vec &lt;- as.vector(Dist) cor.M &lt;- sigma_u * (2^(1-nu))/gamma(nu) * (kappa * d.vec)^nu * besselK(kappa*d.vec, nu) \\(\\omega_{ij}\\)と距離の関係を図示すると以下のようになる。ここからわかるように、距離が近いほど共分散\\(\\omega_{ij}\\)が大きくなっている。 data.frame(dist = d.vec, omega = cor.M) %&gt;% drop_na() %&gt;% ggplot(aes(x = dist, y = omega))+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Distance&quot;, y = &quot;Covariance&quot;) 行列\\(\\bf{\\Omega}\\)は以下の通り。図5.1と見比べると、実際に距離が近いデータほど値が高くなっていることが分かる(e.g., 2と4、4と5)。 omega &lt;- matrix(cor.M, ncol = 5, nrow = 5) diag(omega) &lt;- 1 colnames(omega) &lt;- 1:5 rownames(omega) &lt;- 1:5 omega %&gt;% kable(digits = 3, align = &quot;c&quot;, caption = &quot;Ω&quot;) %&gt;% kable_styling(font_size = 15, full_width = FALSE) 表5.1: Ω 1 2 3 4 5 1.000 0.079 0.039 0.054 0.057 0.079 1.000 0.166 0.834 0.671 0.039 0.166 1.000 0.129 0.082 0.054 0.834 0.129 1.000 0.803 0.057 0.671 0.082 0.803 1.000 以上をまとめると、以下のようになる。 データ間の空間的相関を決める分散共分散行列\\(\\bf{\\Omega}\\)をMatern関数を用いて定義する。 Matern関数では、距離が近いほど\\(\\bf{\\Omega}\\)の行列成分\\(\\omega\\)の値が大きくなり、ひいては\\(u_i\\)の値が近くなっていく。 第8章以降では、INLAというパッケージを用いて式(5.2)をモデリングしていく。 5.3 Spatial-temporal correlation ここまで時系列相関と空間相関について別々に扱ってきたが、現実のデータではどちらもが同時に存在することが多々ある。例えば、シュバシコウのデータ(Bouriach et al. 2015)では様々な巣において4年間にわたるデータが収集された。 以下では、再びシュバシコウのデータを用いて空間モデルを時空間モデル(spatial-temporal model)に拡張していく。\\(BL_{it}\\)を場所\\(i\\)、時間\\(t\\)におけるくちばし長、\\(Z_i = (1, Age_{it})\\)とするとき、以下のようにモデルを拡張する。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + w_{it} + \\epsilon_i\\\\ epsilon_i &amp;\\sim N(0,\\sigma^2)\\\\\\ \\end{aligned} \\tag{5.5} \\] なお、\\(w_{it}\\)は時系列相関を考慮するため以下のように定式化する。\\(\\phi\\)は-1から1までの値をとるパラメータである。\\(w_{it}\\)は\\(\\phi\\)が大きいほど1時点前の\\(w_{i,t-1}\\)と類似する。 \\[ w_{it} = \\phi \\times w_{i, t-1} + u_{it} \\] 5.3.1 Simulation study (continued) \\(u_{it}\\)は空間相関を表す項で、第5.2と同様に平均0, 分散共分散行列が\\(\\bf{\\Omega}\\)の正規分布から得られるとする。 \\[ \\begin{pmatrix} u_{1t}\\\\ \\vdots\\\\ u_{5t} \\end{pmatrix} \\sim N(0, \\bf{\\Omega}) \\] 式(5.4)と同様に、\\(\\bf{\\Omega}\\)は以下のように書ける。なお、\\(u_{it}\\)には時間的な相関はない。 \\[ \\bf{Omega} = \\sigma_u^2 \\times \\rm{Matern \\; correlation \\; sites \\; i \\; and\\;j} \\] それでは、\\(w_{it}\\)がどのように決まるか実際にシミュレーションを行ってみよう。 まず、時間的当館が強く、\\(\\phi = 0.9\\)であるとする。 phi &lt;- 0.9 100時点(\\(t = 1,2,3,\\dots,100\\))のデータが5地点(\\(i = 1,2,\\dots,5\\))について収集されたとする。このとき、時点1のデータ\\(w_{i,1}\\)は以下のように得られる(数学的な詳細はここでは省略)。 \\[ \\begin{pmatrix} w_{1,1}\\\\ \\vdots\\\\ w_{5,1} \\end{pmatrix} \\sim N(0, \\frac{\\sigma_u^2}{1-\\phi^2} \\times \\bf{\\Omega}) \\] なお、\\(\\sigma_u^2 = 1\\)であるとし、\\(\\bf{\\Omega}\\)は前節と同じものを使用する。以下で\\(w_{i,1}\\)が得られた。 sigma_u &lt;- 1 cov.w1 &lt;- (sigma_u^2/(1-phi^2))+omega w1 &lt;- mvrnorm(1, mu = rep(0,5), Sigma = cov.w1) よって、\\(t = 2,3,\\dots,100\\)のときの\\(w_{it}\\)っは以下のように得られる。 w &lt;- matrix(nrow = 5, ncol = 100) w[,1] &lt;- w1 colnames(w) &lt;- str_c(&quot;t&quot;, 1:100) for(t in 2:100){ u &lt;- mvrnorm(1, mu = rep(0,5), Sigma = omega) w[, t] &lt;- phi*w[t-1] + u } 以下のように5地点における100時点の\\(w_{it}\\)が得られた。 w %&gt;% data.frame() %&gt;% rownames_to_column(var = &quot;place&quot;) %&gt;% mutate_if(is.numeric, ~round(.,3)) %&gt;% datatable(options = list(scrollX = 20), filter = &quot;top&quot;) これを図示すると以下のようになる。場所が近い地点のデータ(2,4,5)はそれ以外のデータよりもより類似している傾向があることが分かる。 w %&gt;% data.frame() %&gt;% rownames_to_column(var = &quot;place&quot;) %&gt;% pivot_longer(2:101, names_to = &quot;time&quot;, values_to = &quot;w&quot;) %&gt;% mutate(time = as.numeric(str_replace(time, &quot;t&quot;,&quot;&quot;))) %&gt;% ggplot(aes(x = time, y = w))+ geom_line(aes(linetype = place, linewidth = place %in% c(&quot;2&quot;,&quot;4&quot;,&quot;5&quot;)))+ scale_linewidth_manual(values = c(0.6,1.2))+ theme_bw()+ theme(aspect.ratio = 0.8)+ labs(linewidth = &quot;if place is 2, 4, or 5&quot;) 実際の分析では、\\(w_{it}\\)を得るためのパラメータ(\\(\\phi, \\sigma_u, \\kappa, \\nu\\)は与えられるものではなく、データから推定することになる。データの推定は非常に複雑なので、ベイズ推定が必要になってくる。次章ではベイズ統計について学ぶ。 References "],["Chapter7.html", "6 Introduction to Bayesian statistics 6.1 Why go Bayesian? 6.2 General probability rules 6.3 The mean of a distribution 6.4 Bayes theorem again 6.5 Conjugate priors 6.6 Markov chain Monte Carlo simulation 6.7 Integrated nested Laplace approximation 6.8 Examples using R-INLA 6.9 追記", " 6 Introduction to Bayesian statistics 本章では、ベイズ統計とマルコフ連鎖モンテカルロ法(MCMC)、integrated nested Laplace approximations(INLA)について解説を行う。 6.1 Why go Bayesian? ベイズ統計を使うモチベーションとしてはいくつかある。 事前に持っている知識を分析に取り入れるため。 後に見るように、ベイズ統計では事前分布という形であらかじめ持っている知識を分析に組み込むことができる。 頻度論的な統計学に対する批判から 頻度論的な統計学とは、いわゆる帰無仮説検定(p値)に基づく統計学を指すが、p値や信頼区間などをめぐってはその解釈のしにくさや論理的な問題点に対してたびたび批判的な意見も投げかけられている(e.g., 岡田 and 大久保 2012; 松浦 2016)。 複雑なモデルを使用するため 時空間相関を考慮したGLMやGLMMなどの複雑なモデルは、通常の頻度論的な枠組みでは扱えないことが多い。ベイズ統計はこうした複雑なモデルを柔軟にモデリングすることを可能にする。 頻度論ではパラメータはある1つの真値を持つと考えられる一方で、ベイズ統計ではパラメータはある確率的な分布に従っているとされる(Kruschke 2014; 松浦 2016, ; 馬場 2019; McElreath 2020)。ベイズ統計を用いた分析では、データが得られた時のパラメータの分布(= 事後分布)を最終的に得る(\\(P(\\beta|D)\\))。一方で、頻度論的な統計学ではパラ、エータがある値のときにデータが得られる確率(\\(P(D|\\beta)\\))を計算する(= 尤度)。 6.2 General probability rules まず確立の基本から確認していく。\\(P(A)\\)と\\(P(B)\\)をそれぞれ事象Aが生じる確率、事象Bが生じる確率とする。また、\\(P(A \\cap B)\\)をAかつBである確率、\\(P(A \\cup B)\\)をAまたはBである確率とする。このとき、 \\[ P(A \\cap B) = P(B \\cap A) \\] である。また、AとBが独立であるときは以下のように書ける。 \\[ P(A \\cap B) = P(A) \\times P(B) \\] 一方、AとBが独立でないとき以下のように書ける。なお、\\(P(A|B)\\)は条件付き確率を表し、事象Bが生じたときに事象Aが生じる確率を表す。 \\[ \\begin{aligned} P(A \\cap B) &amp;= P(A|B) \\times P(B)\\\\ P(A \\cap B) &amp;= P(B|A) \\times P(A) \\end{aligned} \\tag{6.1} \\] よって、以下の式が導かれる。これを、ベイズの定理という。 \\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\tag{6.2} \\] 6.3 The mean of a distribution ある変数\\(Y\\)がパラメータ\\(\\mu\\)のポワソン分布から得られるとき、\\(Y\\)の期待値は\\(\\mu\\)である。このことは以下のように書ける。 \\[ \\begin{aligned} &amp;Y \\sim Poisson(\\mu)\\\\ &amp;E(Y) = \\mu \\end{aligned} \\] \\(Y\\)が離散的な値のとき、その期待値は以下のように書ける。なお、\\(y\\)は\\(Y\\)がとりうる全ての値を表す。よって、離散的な変数に関する確率分布(ポワソン分布、ベルヌーイ分布、二項分布、負の二項分布など)の期待値は以下の式で求められる。 \\[ E(Y) = \\sum_y y \\times p(y) \\tag{6.3} \\] ポワソン分布は\\(p(y) = \\frac{e^{-\\mu} \\times \\mu^y}{y!}\\)なので、式(6.3)は以下のように書ける。この式を計算すると右辺は\\(\\mu\\)になる。 \\[ E(Y) = \\sum_{y =0} ^\\infty y \\times \\frac{e^{-\\mu} \\times \\mu^y}{y!} \\tag{6.4} \\] もし変数\\(Y\\)が連続的な値の場合、その期待値は\\(\\int\\)を用いて以下のように書ける。よって、連続的な変数に関する確率分布(正規分布、ガンマ分布、β分布など)の期待値は以下の式で求められる。 \\[ E(Y) = \\int _{-\\infty} ^{\\infty} y \\times p(y) dy \\tag{6.5} \\] 6.4 Bayes theorem again ベイズの定理(式(6.2))を用いて、データ(D)が得られたときにパラメータ\\(\\beta\\)がとりうる確率の分布\\(P(\\beta|D)\\)は以下のように書ける。 \\[ P(\\beta|D) = \\frac{P(D|\\beta) \\times P(\\beta)}{P(D)} \\] \\(P(\\beta|D)\\)は、データが得られた時のパラメータ\\(\\beta\\)の事後分布(posterior distribution)という。事後分布こそが、私たちがデータからパラメータを推定するときに求めたいものである。 \\(P(D|\\beta)\\)はあるパラメータ\\(\\beta\\)が与えられたときにデータが得られる確率であり、いわゆる尤度(likelihood)である。\\(P(\\beta)\\)はデータが与えられていない状態でのパラメータ\\(\\beta\\)が得られる確率分布で事前分布(prior distribution)と呼ばれる。 最後に、\\(P(D)\\)はデータが得られる確率で、事後分布の合計を1にするための役割を果たす。これは周辺尤度と言われ、通常計算することが難しいので省略されることが多い。このとき、式(6.2)は以下のように書ける。なお、\\(\\propto\\)は左辺が右辺に比例することを表す。 \\[ P(\\beta|D) \\propto P(D|\\beta) \\times P(\\beta) \\tag{6.6} \\] この式は、事後分布は尤度と事前分布の積に比例していることを示している。また、事後分布の期待値は式(6.5)から以下のように書ける。 \\[ E(\\beta|D) = \\int_{-\\infty} ^\\infty \\beta \\times P(\\beta|D) d\\beta \\] 次節以降では、事後分布とその期待値をどのように推定するかをみていく。 6.5 Conjugate priors 第2章で調べたように、ミサゴの卵の厚さが殺虫剤の崩壊産物(DDD)によって変わるかを検討するとする(Steidl et al. 1991)。第2と同様に以下のモデルを考える。 \\[ \\begin{aligned} &amp;\\mu_i = \\beta_1 + DDD_i \\times \\beta_2 \\\\ &amp;Thickness_i \\sim N(\\mu_i,\\sigma^2) \\end{aligned} \\tag{6.7} \\] ここで、切片\\(\\beta_1\\)と\\(\\sigma\\)は分かっていると仮定し、事後分布\\(P(\\beta_2|D)\\)を推定するとしよう。これを求めるには、式(6.6)で触れたように尤度\\(P(D|\\beta_2)\\)と事前分布\\(P(\\beta_2)\\)が必要である。 6.5.1 Likelihood function \\(P(D|\\beta_2)\\)はパラメータ\\(\\beta_2\\)が与えられたときにデータDが得られる確率、すなわち尤度である。卵の殻の厚さは連続変数なので、ここではモデル式にあるようにデータが正規分布から得られていると仮定する。 このとき、尤度は式(6.7)より以下のように書ける1。 \\[ P(D|\\beta_2) = \\prod_i ^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp\\Bigl(-\\frac{(Thickness_i - \\beta_1 - DDD_i \\times \\beta_2)^2}{2\\sigma^2}\\Bigl) \\tag{6.8} \\] 頻度論的な統計学では、この尤度が最大になるようにパラメータ\\(\\beta_2\\)を決定する。これは最尤推定法(maximum likelihood estimation)と呼ばれ、Rではglm関数などで実装されている。 6.5.2 Priors 続いて、事前分布\\(P(\\beta_2)\\)について考える。これには、先行研究などの結果や生物学的知識などから予想される分布を適用することができる。事前分布としては、例えば以下のように正規分布を仮定することができる。 \\[ \\beta_2 \\sim N(\\beta_2^0, \\sigma_0^2) \\] このとき、事前分布の確率密度関数は以下のように書ける。 \\[ P(\\beta_2) = \\frac{1}{\\sqrt{2 \\pi \\sigma_0^2}} exp\\Bigl(-\\frac{(\\beta_2 - \\beta_2^0)^2}{2\\sigma_0^2}\\Bigl) \\tag{6.9} \\] 6.5.3 Posterior distribution 式(6.8)の尤度と式(6.9)の事前分布から、事後分布は以下のように書ける。 \\[ \\begin{aligned} P(\\beta_2|D) &amp;\\propto P(D|\\beta_2) \\times P(\\beta_2) \\\\ &amp;= \\left[\\prod_i ^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp\\Bigl(-\\frac{(Thickness_i - \\beta_1 - DDD_i \\times \\beta_2)^2}{2\\sigma^2}\\Bigl) \\right] \\times \\left[ \\frac{1}{\\sqrt{2 \\pi \\sigma_0^2}} exp\\Bigl(-\\frac{(\\beta_2 - \\beta_2^0)^2}{2\\sigma_0^2}\\Bigl) \\right] \\end{aligned} \\] これは複雑な計算になるが、正規分布同士を掛け合わせているので事後分布も正規分布になる。このように、事前分布と事後分布の分布の関数形が同じになるようなとき、ベイズ統計ではこれらを共役分布という。このような分布の組み合わせはいくつかある(こちらを参照)。 これを計算すれば、事後分布やその期待値などを計算で求めることができる。なお、今回の場合は以下のような形になる。\\(\\hat{\\beta_2}\\)は\\(\\beta_2\\)の最尤推定値である。 \\[ \\begin{aligned} &amp;w = \\frac{\\sigma_0^2 \\times \\rm{something}}{\\sigma_0^2 \\times \\rm{something} + \\sigma^2}\\\\ &amp;E(\\beta_2|D) = \\hat{\\beta_2} \\times w + (w-1) \\times \\beta_2^0 + \\rm{Ugly \\; stuff} \\\\ &amp;var(\\beta_2|D) = \\sigma^2 \\times \\frac{w}{\\rm{Ugly \\; stuff}} \\end{aligned} \\tag{6.10} \\] 6.5.4 Diffuse prior 多くの場合、私たちは事前分布に関する知識を持たない。そのとき、以下のように非常に広い分布を事前分布として指定することが多い。 \\[ \\beta_2 \\sim N(0, 100) \\Leftrightarrow \\beta_2^0 = 0 \\; and \\; \\sigma_0 = 100 \\] このとき、\\(\\beta_2\\)はだいたい-200から200の間の値をとりうるということになる。このように広い範囲をもつ事前分布を無情報事前分布という。 無情報事前分布のとき(= \\(\\sigma_0\\)が大きいとき)、式(6.10)の\\(w\\)は1に近づく。よって、\\(P(\\beta_2|D)\\)の期待値は\\(\\hat{\\beta_2}\\)に近づき、頻度論的な統計学と同様に最尤推定値となる。 \\[ P(\\beta_2|D) \\approx \\hat{\\beta_2} \\] 実際に分布を書いてみるとこのことがよくわかる。図6.1は無情報事前分布のときの事前分布、尤度関数、事後分布を図示したものである。なお、\\(\\beta_1 = 51.7, \\sigma = 5.17\\)としている。無情報事前分布の場合、尤度関数と事後分布の形がほとんど同じになっていることが分かる。その結果、尤度関数における最尤推定値が事後分布の期待値とほぼ一致するのである。 beta2 &lt;- seq(-20, 10, length.out = 100) beta1 &lt;- 51.7 sigma &lt;- 5.17 ## 尤度 likelihood &lt;- vector() for(i in 1:100){ likelihood[i] &lt;- prod(dnorm(osp$THICK, mean = beta1 + beta2[i]*osp$DDD, sd = sigma)) } ## prior prior &lt;- dnorm(beta2, mean = 0, sd = 100) ## 図示 data.frame(beta2 = beta2, likelihood = likelihood, prior = prior) %&gt;% mutate(posterior = prior*likelihood) %&gt;% pivot_longer(2:4, names_to = &quot;type&quot;, values_to = &quot;probability&quot;) %&gt;% mutate(type = fct_relevel(type, &quot;prior&quot;,&quot;likelihood&quot;,&quot;posterior&quot;)) %&gt;% ggplot(aes(x = beta2))+ geom_line(aes(y = probability), linewidth = 1)+ facet_rep_wrap(~type, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(size = 13)) 図6.1: Prior, likelihood, and posterior distribution. 6.5.5 Informative prior 一方で、パラメータ\\(\\beta_2\\)に関してあらかじめ知識がある場合(e.g., 生態学的に考えて、ある範囲しか取り得ないなど)には、より狭い分布を持つ情報事前分布を用いることもできる。 例えば、以下のように非常に狭い事前分布を指定することもできる。 \\[ \\beta_2 \\sim N(-18, 1) \\Leftrightarrow \\beta_2^0 = -18 \\; and \\; \\sigma_0 = 1 \\] このとき、式(6.10)の\\(w\\)は0に近づいていく。その結果、事後分布の期待値は事前分布の期待値\\(\\beta_2^0\\)に近づいていく。 \\[ P(\\beta_2|D) \\approx \\beta_2^0 \\] これも図示してみるとよくわかる。図6.2は情報事前分布のときの事前分布、尤度関数、事後分布を図示したものである。このとき事後分布と事前分布の分布の形がほとんど同じになっていることが分かる。その結果、事後分布の期待値が事前分布の期待値とほとんど同じになるのである。 beta2 &lt;- seq(-23, 10, length.out = 100) beta1 &lt;- 51.7 sigma &lt;- 5.17 ## 尤度 likelihood &lt;- vector() for(i in 1:100){ likelihood[i] &lt;- prod(dnorm(osp$THICK, mean = beta1 + beta2[i]*osp$DDD, sd = sigma)) } ## prior prior &lt;- dnorm(beta2, mean = -18, sd = 1) ## 図示 data.frame(beta2 = beta2, likelihood = likelihood, prior = prior) %&gt;% mutate(posterior = prior*likelihood) %&gt;% pivot_longer(2:4, names_to = &quot;type&quot;, values_to = &quot;probability&quot;) %&gt;% mutate(type = fct_relevel(type, &quot;prior&quot;,&quot;likelihood&quot;,&quot;posterior&quot;)) %&gt;% ggplot(aes(x = beta2))+ geom_line(aes(y = probability), linewidth = 1)+ facet_rep_wrap(~type, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(size = 13)) 図6.2: Prior, likelihood, and posterior distribution. 以上のように、事前分布が情報を持たないほど(= 幅が広いほど)事後分布の期待値は最尤推定値に近づき、情報を持つほど(= 幅が狭いほど)事後分布の期待値は事前分布の期待値に近づく。 今回は\\(\\beta_2\\)についてのみ事前分布を設定したが、実際の分析では全てのパラメータについて事前分布を設定する必要がある。回帰係数の事前分布としては、正規分布やt分布などが用いられることが多い。一方で、標準偏差\\(\\sigma\\)は必ず0より大きい値をとるので、こうした分布は事前分布として不適切なことが多い。事前分布の選択については、こちらを参照。 Ntzoufras (2011) は、線形モデルの場合回帰係数\\(\\beta\\)の事前分布が正規分布、\\(\\sigma\\)の事前分布として逆ガンマ関数を用いると事前分布と事後分布が共役な分布になるとしている。\\(\\sigma^2\\)の事前分布として逆ガンマ関数を用いるのは、\\(\\tau = 1/\\sigma^2\\)の事前分布としてガンマ関数を用いるのと同じである。このとき、\\(\\tau\\)はprecision(精度)と呼ばれる。 本節では事後分布が手動で計算できるように共役な事前分布を用いた。しかし、これから見るような複雑なモデルでは手動で事後分布を求めることは困難になっていく。そこで用いられるのが次節で解説するMCMC法である。 6.6 Markov chain Monte Carlo simulation 6.6.1 underlying idea マルコフ連鎖モンテカルロ(MCMC)法は、手動ではなくシミュレーションによって事後分布を推測する方法である。MCMCでは、全てのパラメータについて同時にこれを行う。例えば、卵の殻の厚さに関する分析(式(6.7))では、3つのパラメータ\\(\\bf{\\theta} = (\\beta_1, \\beta_2, \\sigma)\\)について事後分布を同時に求める。 マルコフ連鎖とは、\\(\\bf{\\theta}\\)についてシミュレーションを行ったベクトル\\(\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\dots, \\theta^{(T)}\\)を指し、\\(\\theta^{(t+1)}\\)は\\(\\theta^{(t)}\\)のみに依存する。数学的には以下のように書ける。 \\[ f(\\theta^{(t+1)}|\\theta^{(t)}, \\dots, \\theta^{(1)}) = f(\\theta^{(t+1)}|\\theta^{(t)}) \\] MCMCでは各パラメータについて多くの(通常10000回以上)のシミュレーション値が得られる。これのシミュレーション値をヒストグラムにすると、それぞれのパラメータの事後分布に近似させることができることが数学的にわかっている。数学的な説明については、 Kruschke (2014) や McElreath (2020) などを参照。 6.6.2 Simple example of MCMC algorithm ここでは、MCMCがどのように分布を推定できるのかを見るため、MCMC法の一種であるメトロポリスアルゴリズム(Metropolis algorithm)の特殊例について簡単に見ていく(McElreath 2020)。 10の島からなる諸島があるとする。それぞれの島は2つの島に隣接しており、全体で円になっている。各島は面積が異なり、それに比例して人口も異なる。面積と人口は1つめの島から順に2倍、3倍、…10倍になっている(つまり、1つめの島の大きさと人口が1だとすれば、10個目の島はそれぞれ10である)。さて、この諸島の王様は1週間ごとに島々を訪れるが、その際には隣接している島にしか移動できない。王様は各島を人口比率に応じて訪れたいが、訪問計画を長期的に策定するのは面倒である。そこで、彼の側近は以下の方法で島を訪れることを提案した。この方法に従えば、各島に訪れる頻度が人口比率に一致する。 毎週王様はその島にとどまるか、隣接するいずれかの島に移動するかをコインを投げて決める。 もしコインが表なら、王様は時計回りに隣の島に移動することを考える。一方コインが裏なら、反時計回りに移動することを考える。ここで、提案された島をproposal islandとする。 王様はporposal islandの大きさだけ(7つめの島にいるなら7個)貝殻を集める。また、現在いる島の大きさだけ同様に石を集める。 もし貝殻の数が石よりも多ければ、王様はproposal islandへ移動する。一方で石の数の方が多い場合、王様は集めた石から貝殻と同数の石を捨てる(例えば石が6つ、貝殻が4つなら、手元には\\(6-4=2\\)個の石が残る)。その後、残された石と貝殻をカバンに入れ、王様はランダムにそのうちの一つを引く。もしそれが貝殻ならばproposal islandに移動し、石ならば今いる島に留まる。 この方法は一見奇妙だが、長期間繰り返していくと非常にうまくいく。以下でシミュレーションしてみよう。 set.seed(9) num_weeks &lt;- 1e6 positions &lt;- rep(0, num_weeks) current &lt;- 10 ## アルゴリズムの記述 for(i in 1:num_weeks){ ## 最初は島10からスタート positions[i] &lt;- current proposal &lt;- current + sample(c(-1,1), size=1) if(proposal &lt;1) proposal &lt;- 10 if(proposal &gt;10) proposal &lt;- 1 prob_move &lt;- proposal/current current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current) } 国王の動きを可視化してみる。 tibble(week = 1:1e6, island = positions) %&gt;% ggplot(aes(x=week, y = island))+ geom_line(linewidth = 1/3)+ geom_point()+ coord_cartesian(xlim = c(0,500))+ scale_y_continuous(breaks = seq(1,10,1))+ theme_bw()+ theme(aspect.ratio= 0.8) 各島を訪れた回数を見てみると以下のようになり、人口に応じて訪れていることが分かる。 tibble(week = 1:1e6, island = positions) %&gt;% mutate(island = factor(island)) %&gt;% ggplot(aes(x=island))+ geom_bar()+ theme_bw()+ theme(aspect.ratio = 0.9)+ scale_y_continuous(breaks = seq(0,180000, 20000)) 島を訪れている比率(prop)はおよそ人口通りになる。このアルゴリズムは、隣の島だけでなく全ての島への移動が可能であっても同様に機能する。 tibble(week = 1:1e6, island = positions) %&gt;% count(island) %&gt;% mutate(prop = n/n[1]) %&gt;% gt() %&gt;% fmt_number(&quot;prop&quot;,decimals=2) %&gt;% tab_options(table.align=&#39;left&#39;) #wqlbootwvl table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #wqlbootwvl thead, #wqlbootwvl tbody, #wqlbootwvl tfoot, #wqlbootwvl tr, #wqlbootwvl td, #wqlbootwvl th { border-style: none; } #wqlbootwvl p { margin: 0; padding: 0; } #wqlbootwvl .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: 0; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wqlbootwvl .gt_caption { padding-top: 4px; padding-bottom: 4px; } #wqlbootwvl .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wqlbootwvl .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #wqlbootwvl .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wqlbootwvl .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wqlbootwvl .gt_column_spanner_outer:first-child { padding-left: 0; } #wqlbootwvl .gt_column_spanner_outer:last-child { padding-right: 0; } #wqlbootwvl .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wqlbootwvl .gt_spanner_row { border-bottom-style: hidden; } #wqlbootwvl .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #wqlbootwvl .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wqlbootwvl .gt_from_md > :first-child { margin-top: 0; } #wqlbootwvl .gt_from_md > :last-child { margin-bottom: 0; } #wqlbootwvl .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wqlbootwvl .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #wqlbootwvl .gt_row_group_first td { border-top-width: 2px; } #wqlbootwvl .gt_row_group_first th { border-top-width: 2px; } #wqlbootwvl .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #wqlbootwvl .gt_first_summary_row.thick { border-top-width: 2px; } #wqlbootwvl .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wqlbootwvl .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wqlbootwvl .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_left { text-align: left; } #wqlbootwvl .gt_center { text-align: center; } #wqlbootwvl .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wqlbootwvl .gt_font_normal { font-weight: normal; } #wqlbootwvl .gt_font_bold { font-weight: bold; } #wqlbootwvl .gt_font_italic { font-style: italic; } #wqlbootwvl .gt_super { font-size: 65%; } #wqlbootwvl .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #wqlbootwvl .gt_asterisk { font-size: 100%; vertical-align: 0; } #wqlbootwvl .gt_indent_1 { text-indent: 5px; } #wqlbootwvl .gt_indent_2 { text-indent: 10px; } #wqlbootwvl .gt_indent_3 { text-indent: 15px; } #wqlbootwvl .gt_indent_4 { text-indent: 20px; } #wqlbootwvl .gt_indent_5 { text-indent: 25px; } island n prop 1 18142 1.00 2 36232 2.00 3 54787 3.02 4 72686 4.01 5 90272 4.98 6 108747 5.99 7 127527 7.03 8 145756 8.03 9 163703 9.02 10 182148 10.04 6.6.3 Methods in MCMC MCMCにも様々なアルゴリズムがあり、それぞれの方法を実装するためのソフトウェアが開発されている。例えば、ギブスサンプリングと呼ばれる方法(Kruschke 2014; McElreath 2020)を実装するソフトウェアとしてJAGSやWinBUGSがある。また、ハミルトニアン・モンテカルロ法という方法を用いるソフトウェアとしては(Stan)[https://mc-stan.org/]がある(松浦 2016; 馬場 2019)。いずれもR上で実行することができる。 いずれを用いてもMCMCによるベイズ推定を行えるが、現在はStanが用いられることが多くなっている(松浦 2016)。この理由としては、WinBUGSやJAGSが使いにくい点や、開発があまり継続的には行われておらず、マニュアルや用例が充実していない点が挙げられる。また、Stanで用いられるハミルトニアン・モンテカルロ法はギブスサンプリングよりも複雑なモデルを扱え、またサンプリングも効率的に行える。そこで、本稿では以下Stanを用いてモデリングを行う2。RでStanを動かすには、rstanパッケージが必要である。`Stanのインストール方法や使用方法などは 松浦 (2016) や 馬場 (2019) を参照。 6.6.4 Flowchart for running a model in Stan 以下、Stanを用いてMCMCによって事後分布を推定する。分析には、第3で用いたデータを用いる。以下の線形モデルを考える。ひとまず、データの疑似反復については気にしない。 \\[ \\begin{aligned} pH_i &amp;\\sim N(0,\\sigma^2)\\\\ \\mu_i &amp;= \\beta_1 + \\beta_2 \\times SDI_i\\\\ \\end{aligned} \\tag{6.11} \\] 6.6.4.1 Preparing the data for Stan Stanで分析を行うためには、まずデータをlist形式で準備する必要がある。なお、説明変数\\(SDI\\)はモデルの収束をよくするために標準化する。 iph %&gt;% mutate(SDI.std = scale(SDI)) -&gt; iph2 X &lt;- model.matrix(~ 1 + SDI.std, data = iph2) data_iph &lt;- list(Y = iph2$pH, X = X, ##回帰係数の数 K = ncol(X), ##データ数 N = nrow(iph2)) 6.6.4.2 Decide model formulation and priors パラメータの事前分布などを含めたモデルの詳細を決める。モデル式は式(6.11)の通りである。 パラメータ\\(\\beta\\)の事前分布としては、以下の正規分布の無情報事前分布を用いることにする。 \\[ \\beta_1 \\sim N(0,100^2) \\;\\; and \\;\\; \\beta_2 \\sim N(0,100^2) \\] \\(\\sigma\\)の事前分布としては、0から20までの一様分布を用いる。 \\[ \\sigma \\sim uniform(0,20) \\] 6.6.4.3 Preparing stan file 最後に、ここまでのモデルの情報を記した以下のようなStanファイルを用意する。dataセクションにはデータの情報を、parameterセクションにはパラメータの情報を、modelセクションにはモデル式や事前分布に関する情報を入れる。 ## // データ ## data { ## int N; ## int K; ## vector[N] Y; ## matrix[N, K] X; ## } ## ## // パラメータ ## parameters { ## vector[K] beta; ## real&lt;lower=0&gt; sigma; ## } ## ## // モデル式、事前分布 ## model { ## vector[N] mu = X*beta; ## Y ~ normal(mu, sigma); ## ## //βの事前分布 ## for(i in 1:K){ ## beta[i] ~ normal(0, 100); ## } ## ## //σの事前分布 ## sigma ~ uniform(0,20); ## } 6.6.4.4 Initial values パラメータのMCMCの初期値を定める場合には、指定することができる。今回は、\\(\\beta_1, \\beta_2\\)の初期値については平均0、標準偏差10の正規分布から、\\(\\sigma\\)の初期値は0から20までの一様分布から得られるとした。 K &lt;- ncol(X) inits &lt;- function() { list(beta = rnorm(K, 0, 10), sigma = runif(1, 0,20)) } 6.6.5 Running model in Stan それでは、実際にStanでモデルを回してみよう。 まず、rstanパッケージを読み込む。バックエンドとして、cmdstanrパッケージを用いる。 library(rstan) library(cmdstanr) library(posterior) 以下のオプションを実行すると、実行時間が短くなる。 rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) MCMCによるパラメータの推定は以下のように行う。 file: stanファイル data: リスト化したデータ init: 初期値 chains: 何セットの乱数生成(MCMC)を行うか iter_warmup: チューニングを行う回数。切り捨てる。 iter_sampling: warmup期間を含む各chainの乱数生成回数。 thin: 何回に一回の乱数を用いるか 今回の場合、4つのchainで繰り返し数(iter_sampling)が50000、間引き期間(thin)が10なので、\\((50000)/10 \\times 4 = 20000\\)個の乱数がパラメータごとに得られる。 mod &lt;- cmdstan_model(&quot;stanfile/lm-iph.stan&quot;) m7_1 &lt;- mod$sample(data = data_iph, init = inits, seed = 1234, ## 何回に一回のデータを使うか thin = 10, ## 最初の何回を捨てるか iter_warmup = 5000, ## 乱数生成の繰り返し数(warmupを除く) iter_sampling = 50000, ## chainの数 chains = 4) 6.6.6 Assess mixing 結果を見る前に、まず信頼できるMCMCサンプルが得られたかを確認する必要がある。 得られたMCMCサンプルは以下のように取り出せる。 draw_m7_1 &lt;- m7_1$draws(format = &quot;df&quot;) datatable(draw_m7_1) まずは、MCMCが収束しているかを確認する。視覚的には、横軸に繰り返し(iteration)数をとり、chainごとにその遷移を確認する。全てのchainがまじりあっていれば問題がない。図を見る限りは問題がなさそう。 mcmc_trace(draw_m7_1) また、収束をチェックするための指標としては、\\(\\hat{R}\\)と有向サンプルサイズ数がある。前者は1.1未満であれば、後者は100くらいあれば問題ないとされている(松浦 2016)。今回は問題なさそう(rhatとess_bulkをチェックする)。 m7_1$summary(NULL, c(&quot;Rhat&quot;, &quot;ess_bulk&quot;)) いよいよ、結果を確認する。まずは、事後分布の代表値なども一緒にチェックする。以下には、事後分布の平均(mean)、中央値(median)、標準偏差(sd)、中央値絶対偏差(mad)、2.5パーセンタイル(q2.5)、97.5パーセンタイル(q97.5)を示した。2.5パーセンタイルと97.5パーセンタイルの間の範囲を95%確信区間(credible interval)という。これらは全てMCMCで生成された乱数から計算されている。 \\(\\beta_2\\)の95%確信区間は\\([-0.463, -0.361]\\)で0を含まない。これは、\\(\\beta_2\\)が95%の確率でこの区間の値をとるということを表す。このことから、SDIはpHと強く関連しているといえそうだ。 m7_1$summary(variables = NULL, c(&quot;mean&quot;, &quot;median&quot;,&quot;sd&quot;, &quot;mad&quot;), quantiles = ~posterior::quantile2(., probs = c(.0275, .975))) -&gt; result7_1 result7_1 最後に、事後分布を実際に図示する。 mcmc_hist(draw_m7_1, pars = c(&quot;beta[1]&quot;,&quot;beta[2]&quot;, &quot;sigma&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Frequencies&quot;) 6.7 Integrated nested Laplace approximation Stanでは、前節と同様にして様々なモデルを実装することができる。しかし、時空間相関を考慮するなど複雑なモデルになると、MCMCでは時間がかかりすぎる場合やモデルが収束しない場合が出てくる。本節では、MCMCによらず事後分布を近似させる手法である integrated nested Laplace approximation(INLA)について学ぶ。INLAはMCMCよりもはるかに拘束に、かつ精度高く事後分布を推定することができる。しかし、以下の数学的説明はかなり高度なので、全てを理解する必要はない。 6.7.1 Joint posterior distribution ここまでと同様に、ミサゴの卵の厚さが殺虫剤の崩壊産物(DDD)によって変わるかを検討するとする(Steidl et al. 1991)。同様に以下のモデルを考える。 \\[ \\begin{aligned} &amp;\\mu_i = \\beta_1 + DDD_i \\times \\beta_2 \\\\ &amp;Thickness_i \\sim N(\\mu_i,\\sigma^2) \\end{aligned} \\tag{6.12} \\] 式(6.12)には3つのパラメータ(\\(\\beta_1, \\beta_2, \\sigma\\))があるが、\\(\\sigma\\)のようなパラメータはハイパーパラメータと呼ばれる。ハイパーパラメータには、負の二項分布モデルなどの分散パラメータや、ランダム効果(混合)モデルのランダム切片の分散パラメータ、時空間相関を考慮したモデルにおけるパラメータ(\\(\\phi, \\kappa\\)など)がある。 ベイズの定理から、以下の式が導ける。 \\[ \\begin{aligned} P(\\beta_1, \\beta_2, \\sigma|D) &amp;= \\frac{P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2, \\sigma)}{P(D)}\\\\ &amp;\\propto P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2, \\sigma) \\end{aligned} \\tag{6.13} \\] \\(P(\\beta_1, \\beta_2, \\sigma|D)\\)はデータ(D)が与えられた時のパラメータの同時分布である。\\(P(D|\\beta_1, \\beta_2, \\sigma)\\)はデータの尤度、\\(P(\\beta_1, \\beta_2, \\sigma))\\)はパラメータの事前分布である。\\(pH\\)が正の連続値であると考えると、正規分布かガンマ分布を用いて書くことができるだろう。\\(\\beta_1, \\beta_2\\)は全ての値が取れるのに対して\\(\\sigma\\)は0より大きい値しか取れないので、これらにすべて同じ事前分布を仮定することはできない。そのため、事前分布は\\(\\beta_1, \\beta_2\\)のためのものと、\\(\\sigma\\)のためのものの2種類を含むように書き直す必要がある。 式(6.1)より、式(6.13)は\\(P(\\beta_1, \\beta_2, \\sigma))\\)を変形して以下のように書き直せる。これにより、事前分布を2つの要素に分けることができた。 \\[ \\begin{aligned} P(\\beta_1, \\beta_2, \\sigma)|D) &amp;\\propto P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2, \\sigma) \\\\ &amp;= P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2| \\sigma) \\times P(\\sigma) \\end{aligned} \\tag{6.14} \\] \\(\\beta_s\\)の事前分布\\(P(\\beta_1, \\beta_2| \\sigma)\\)は少しトリッキーだが、互いに独立に多変量正規分布から得られていると仮定すればうまくいくことが多い。 6.7.2 Marginal distributions MCMCでは各パラメータの事後分布\\(P(\\beta_1|D), P(\\beta_2|D), P(\\sigma|D)\\)が得られた。これらは周辺分布(marginal distribution)といい、同時事後確率\\(P(\\beta_1, \\beta_2, \\sigma)|D)\\)を得たわけではなかった。 同時分布と周辺分布の違いを説明するため、ミヤコドリ(Haematopus palliates)を対象とした研究のデータを用いる。この研究では、3か所で12月から1月にミヤコドリによって食べられた二枚貝の長さが記録されている。ミヤコドリは、採食技術によってhammererまたはstabberに分類された。リサーチクエスチョンは、採食技術のタイプによって貝の長さが変わるかである。 oc &lt;- read_delim(&quot;data/Oystercatcher.txt&quot;) datatable(oc, options = list(scrollX = 20), filter = &quot;top&quot;) 下表(表6.1)は、hammererによって割られた二枚貝のサイズ(Large or Small)を場所ごとにまとめたものである。 oc %&gt;% filter(FeedingType == &quot;Hammerers&quot;) %&gt;% mutate(shell_size = ifelse(ShellLength &gt;= 2, &quot;Large&quot;,&quot;Small&quot;)) %&gt;% group_by(shell_size, FeedingPlot) %&gt;% summarise(N = n()) %&gt;% rename(&quot;Shell size&quot; = 1, &quot;Feeding site&quot; = 2) %&gt;% pivot_wider(names_from = &quot;Feeding site&quot;, values_from = N) %&gt;% ungroup() %&gt;% mutate(Total = A + B + C) -&gt; sum_oc sum_oc %&gt;% bind_rows(summarise(., across(where(is.numeric), sum), across(where(is.character), ~&#39;Total&#39;))) %&gt;% kable(booktabs = TRUE, align = c(&quot;l&quot;, rep(&quot;c&quot;,5)), caption = &quot;Number of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site.&quot;) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;Feed place&quot; = 4)) %&gt;% kable_styling(full_width = FALSE) 表6.1: Number of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site. Feed place Shell size A B C Total Large 45 29 36 110 Small 15 16 24 55 Total 60 45 60 165 これを割合データに直したのが表6.2である。 sum_oc %&gt;% bind_rows(summarise(., across(where(is.numeric), sum), across(where(is.character), ~&#39;Total&#39;))) %&gt;% mutate_if(is.numeric, .funs = ~./165) %&gt;% mutate_if(is.numeric, ~sprintf(&quot;%.3f&quot;, .)) %&gt;% kable(booktabs = TRUE, align = c(&quot;l&quot;, rep(&quot;c&quot;,5)), caption = &quot;Proportions of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site.&quot;) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;Feed place&quot; = 4)) %&gt;% kable_styling(full_width = FALSE) 表6.2: Proportions of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site. Feed place Shell size A B C Total Large 0.273 0.176 0.218 0.667 Small 0.091 0.097 0.145 0.333 Total 0.364 0.273 0.364 1.000 このとき、\\(P(\\rm{shell \\; size} \\; \\mathbf{and} \\rm{\\;Feed \\; place})\\)が同時確率であり、中の6つのセルの値である。 一方、\\(P(\\rm{Feed \\;place})\\)と\\(P(\\rm{Shell \\; size})\\)が周辺確率である。これらは、それぞれ一番下の行と一番右の列の値である。 \\[ \\begin{aligned} &amp;P(\\rm{Feed \\;place} = A) = 0.273 + 0.091 = 0.364 \\\\ &amp;P(\\rm{Feed \\;place} = B) = 0.176 + 0.097 = 0.273 \\\\ &amp;P(\\rm{Feed \\;place} = C) = 0.218 + 0.145 = 0.364 \\\\ \\\\ &amp;P(\\rm{Shell \\; size = Large}) = 0.273 + 0.16 + 0.218 = 0.667 \\\\ &amp;P(\\rm{Shell \\; size = Small}) = 0.091 + 0.097 + 0.145 = 0.333 \\end{aligned} \\] より一般的に、変数が離散的なとき周辺確率は以下のように書ける。 \\[ P(X = x) = \\sum_y P(X = x \\; \\rm{and} \\; Y = y) \\] 変数が連続的なとき、以下のように書ける。 \\[ P(X = x) = \\int_y P(X = x \\; \\rm{and} \\; Y = y) dy \\tag{6.15} \\] このように、複数の確率変数の同時分布(確率)から周辺分布(確率)を計算することを周辺化という(馬場 2019)。周辺事後分布\\(P(\\beta_1|D), P(\\beta_2|D), P(\\sigma|D)\\)を求めるときも、同じように積分を用いて周辺化を行う。 6.7.3 Back to high school それでは、積分とは何だろうか。例えば、図6.3Aの塗りつぶされた場所の面積を求めたいとする(なお、曲線は\\(f(x) = -2x^2 + 8\\))。いうまでもなく\\(\\int_0 ^1 f(x) dx\\)という積分計算を行えばこれを求めることができるが、積分を用いずにこれを近似することはできるだろうか? よく用いられるのは、面積を求めたいエリアの\\(x\\)軸(その範囲を\\(x_0\\)とする)をN等分したのち、面積を求めたいエリアを幅\\(x_0/N\\)、高さ\\(f(x)\\)の長方形N個で埋め尽くし、その面積の合計を近似値として求める方法である。例えば、図6.3Bは面積を求めたいエリアを5等分した場合である。Nを大きくすればするほど近似値は実際の面積に近づいていく(図6.3C)。これを区分求積法という。INLAでも、積分計算に区分求積法のような方法を用いることで近似を行う。 X &lt;- seq(-0.5, 2, length = 100) Y &lt;- -2*X^2 + 8 data.frame(X = X, Y = Y) %&gt;% ggplot(aes(x = X, y = Y))+ geom_area(aes(x = ifelse(X&gt;=0 &amp; X &lt;= 1 , X, 0)), fill = &quot;lightblue&quot;)+ geom_line(linewidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0.35,8))+ labs(title = &quot;A&quot;) -&gt; p1 int &lt;- data.frame(X = seq(0,0.8,0.2)) %&gt;% mutate(Y = -2*X^2 + 8) data.frame(X = X, Y = Y) %&gt;% ggplot(aes(x = X, y = Y))+ geom_area(aes(x = ifelse(X&gt;=0 &amp; X &lt;= 1 , X, 0)), fill = &quot;lightblue&quot;)+ geom_line(linewidth = 1)+ geom_col(data = int, color = &quot;black&quot;, alpha = 0, linewidth = 0.3, width = 0.2, position = position_nudge(x = 0.1)) + theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0.35,8))+ labs(title = &quot;B&quot;)-&gt; p2 int2 &lt;- data.frame(X = seq(0,0.9,0.1)) %&gt;% mutate(Y = -2*X^2 + 8) data.frame(X = X, Y = Y) %&gt;% ggplot(aes(x = X, y = Y))+ geom_area(aes(x = ifelse(X&gt;=0 &amp; X &lt;= 1 , X, 0)), fill = &quot;lightblue&quot;)+ geom_line(linewidth = 1)+ geom_col(data = int2, color = &quot;black&quot;, alpha = 0, linewidth = 0.2, width = 0.1, position = position_nudge(x = 0.05)) + theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0.35,8))+ labs(title = &quot;C&quot;)-&gt; p3 p1 + p2 + p3 図6.3: How integrals work. 実際の分析ではより複雑な関数を積分しなくてはいけないので、実際には積分を行うことが非常に難しいこともある。INLAではラプラス近似(テイラー展開を用いて関数を近似する方法)を用いて\\(f(x)\\)を近似することで、複雑な積分計算を可能にする。もう少し詳しい説明については、こちらなどを参照。 6.7.4 INLA 式(6.15)より、\\(\\beta_1, \\beta_2\\)の事後分布は以下のように書ける。 \\[ \\begin{aligned} &amp;P(\\beta_1|D) = \\int P(\\beta_1, \\sigma|D)d\\sigma \\\\ &amp;P(\\beta_2|D) = \\int P(\\beta_2, \\sigma|D)d\\sigma \\end{aligned} \\tag{6.16} \\] 混合モデルなど、ハイパーパラメータが2つあるときには、これらの事後分布を以下のように求める。 \\[ P(\\sigma_1|D) = \\int(\\sigma_1, \\sigma_2|D)d\\sigma_1 \\\\ P(\\sigma_2|D) = \\int(\\sigma_1, \\sigma_2|D)d\\sigma_2 \\] ひとまず、今回はハイパーパラメータが$$1つの場合を考える。このとき、式(6.16)は条件付き確率の書き換えルール(式(6.1))を用いて以下のように書き換えられる3。 \\[ \\begin{aligned} &amp;P(\\beta_1|D) = \\int P(\\beta_1|\\sigma,D) \\times P(\\sigma|D) d\\sigma \\\\ &amp;P(\\beta_2|D) = \\int P(\\beta_2|\\sigma,D) \\times P(\\sigma|D) d\\sigma \\end{aligned} \\] よって、事後分布を求めるには2つの要素を計算できれば良い。\\(P(\\sigma|D)\\)はハイパーパラメータが1つなので簡単に求められる。もし、ハイパーパラメータが2つ以上のときはこれをさらに簡単な要素に分解する。\\(P(\\beta_1|\\sigma,D)\\)の計算にはいくつかの方法があるが、INLAではラプラス近似を用いてこれを求める。 6.8 Examples using R-INLA 以下では、INLAパッケージを用いて式(6.12)の線形モデルを実行する。INLAのコードは非常にシンプルで、他の関数(lm、glm)と同じようにできる。 m7_2 &lt;- inla(pH ~ SDI.std, data = iph2, family = &quot;gaussian&quot;) 違う点は、分布をfamily =で必ず指定しなければいけない点である。INLAでは非常に多くの分布を扱える。 names(inla.models()$likelihood) ## [1] &quot;poisson&quot; &quot;xpoisson&quot; ## [3] &quot;cenpoisson&quot; &quot;cenpoisson2&quot; ## [5] &quot;gpoisson&quot; &quot;poisson.special1&quot; ## [7] &quot;0poisson&quot; &quot;0poissonS&quot; ## [9] &quot;bell&quot; &quot;0binomial&quot; ## [11] &quot;0binomialS&quot; &quot;binomial&quot; ## [13] &quot;xbinomial&quot; &quot;pom&quot; ## [15] &quot;bgev&quot; &quot;gamma&quot; ## [17] &quot;gammasurv&quot; &quot;gammajw&quot; ## [19] &quot;gammajwsurv&quot; &quot;gammacount&quot; ## [21] &quot;qkumar&quot; &quot;qloglogistic&quot; ## [23] &quot;qloglogisticsurv&quot; &quot;beta&quot; ## [25] &quot;betabinomial&quot; &quot;betabinomialna&quot; ## [27] &quot;cbinomial&quot; &quot;nbinomial&quot; ## [29] &quot;nbinomial2&quot; &quot;cennbinomial2&quot; ## [31] &quot;simplex&quot; &quot;gaussian&quot; ## [33] &quot;gaussianjw&quot; &quot;agaussian&quot; ## [35] &quot;circularnormal&quot; &quot;wrappedcauchy&quot; ## [37] &quot;iidgamma&quot; &quot;iidlogitbeta&quot; ## [39] &quot;loggammafrailty&quot; &quot;logistic&quot; ## [41] &quot;sn&quot; &quot;gev&quot; ## [43] &quot;lognormal&quot; &quot;lognormalsurv&quot; ## [45] &quot;exponential&quot; &quot;exponentialsurv&quot; ## [47] &quot;coxph&quot; &quot;weibull&quot; ## [49] &quot;weibullsurv&quot; &quot;loglogistic&quot; ## [51] &quot;loglogisticsurv&quot; &quot;stochvol&quot; ## [53] &quot;stochvolsn&quot; &quot;stochvolt&quot; ## [55] &quot;stochvolnig&quot; &quot;zeroinflatedpoisson0&quot; ## [57] &quot;zeroinflatedpoisson1&quot; &quot;zeroinflatedpoisson2&quot; ## [59] &quot;zeroinflatedcenpoisson0&quot; &quot;zeroinflatedcenpoisson1&quot; ## [61] &quot;zeroinflatedbetabinomial0&quot; &quot;zeroinflatedbetabinomial1&quot; ## [63] &quot;zeroinflatedbinomial0&quot; &quot;zeroinflatedbinomial1&quot; ## [65] &quot;zeroinflatedbinomial2&quot; &quot;zeroninflatedbinomial2&quot; ## [67] &quot;zeroninflatedbinomial3&quot; &quot;zeroinflatedbetabinomial2&quot; ## [69] &quot;zeroinflatednbinomial0&quot; &quot;zeroinflatednbinomial1&quot; ## [71] &quot;zeroinflatednbinomial1strata2&quot; &quot;zeroinflatednbinomial1strata3&quot; ## [73] &quot;zeroinflatednbinomial2&quot; &quot;t&quot; ## [75] &quot;tstrata&quot; &quot;nmix&quot; ## [77] &quot;nmixnb&quot; &quot;gp&quot; ## [79] &quot;dgp&quot; &quot;logperiodogram&quot; ## [81] &quot;tweedie&quot; &quot;fmri&quot; ## [83] &quot;fmrisurv&quot; &quot;gompertz&quot; ## [85] &quot;gompertzsurv&quot; 6.8.1 Posterior summary 推定された事後分布の要約は以下の通り。事後分布の平均、sd、パーセンタイル値などの情報が出る。結果はほぼMCMCのときと変わらない。 summary(m7_2) ## ## Call: ## c(&quot;inla.core(formula = formula, family = family, contrasts = contrasts, ## &quot;, &quot; data = data, quantiles = quantiles, E = E, offset = offset, &quot;, &quot; ## scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, ## &quot;, &quot; lp.scale = lp.scale, link.covariates = link.covariates, verbose = ## verbose, &quot;, &quot; lincomb = lincomb, selection = selection, control.compute ## = control.compute, &quot;, &quot; control.predictor = control.predictor, ## control.family = control.family, &quot;, &quot; control.inla = control.inla, ## control.fixed = control.fixed, &quot;, &quot; control.mode = control.mode, ## control.expert = control.expert, &quot;, &quot; control.hazard = control.hazard, ## control.lincomb = control.lincomb, &quot;, &quot; control.update = ## control.update, control.lp.scale = control.lp.scale, &quot;, &quot; ## control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, ## &quot;, &quot; inla.call = inla.call, inla.arg = inla.arg, num.threads = ## num.threads, &quot;, &quot; blas.num.threads = blas.num.threads, keep = keep, ## working.directory = working.directory, &quot;, &quot; silent = silent, inla.mode ## = inla.mode, safe = FALSE, debug = debug, &quot;, &quot; .parent.frame = ## .parent.frame)&quot;) ## Time used: ## Pre = 0.738, Running = 0.435, Post = 0.0589, Total = 1.23 ## Fixed effects: ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## (Intercept) 7.432 0.026 7.381 7.432 7.484 7.432 0 ## SDI.std -0.414 0.026 -0.465 -0.414 -0.362 -0.414 0 ## ## Model hyperparameters: ## mean sd 0.025quant 0.5quant ## Precision for the Gaussian observations 6.97 0.681 5.71 6.95 ## 0.975quant mode ## Precision for the Gaussian observations 8.37 6.91 ## ## Marginal log-Likelihood: -113.24 ## is computed ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also &#39;control.compute=list(return.marginals.predictor=TRUE)&#39;) ハイパーパラメータ以外の結果を知りたい場合は以下のようにしてみることができる。 m7_2$summary.fixed %&gt;% select(mean, sd, &quot;0.025quant&quot;, &quot;0.975quant&quot;) 事後分布の平均を用いた予測値や残差は以下のように計算できる。 X &lt;- model.matrix(~ 1 + SDI.std, data = iph2) beta &lt;- m7_2$summary.fixed %&gt;% select(&quot;mean&quot;) %&gt;% .[,1] fit7_2 &lt;- X %*% beta e7_2 &lt;- iph$pH - fit7_2 自分で計算しなくても、INLAでcontrol.predictorオプションを加えれば自動で計算を行ってくれる。95%確信区間の計算も行ってくれるようだ。 m7_2 &lt;- inla(pH ~ SDI.std, data = iph2, family = &quot;gaussian&quot;, control.predictor = list(compute = TRUE), control.compute = list(config = TRUE)) fit7_2 &lt;- m7_2$summary.fitted.values datatable(fit7_2) ハイパーパラメータは以下のように求めることができる。INLAパッケージでは標準偏差ではなくprecision(\\(\\tau = 1/\\sigma^2\\)が推定される。 m7_2$summary.hyperpar 6.8.2 Posterior marginal distributions ある特定のパラメータに関する事後分布は事後周辺分布(posterior marginal distribution)と呼ばれる4。以後、これを事後分布と呼ぶ(先ほどの節の結果で示されたのも事後周辺分布の要約である)。先ほど推定したモデルでは3つのパラメータ(\\(\\beta_1, \\beta_2, 1 / \\sigma^2\\))があった。これらの事後分布は以下のように抽出できる。 pmbeta1 &lt;- m7_2$marginals.fixed$`(Intercept)` pmbeta2 &lt;- m7_2$marginals.fixed$SDI.std pmtau &lt;- m7_2$marginals.hyperpar$`Precision for the Gaussian observations` INLAには事後周辺分布の確信区間などの要約統計量を算出するための関数が装備されている。例えば、95%確信区間と中央値は以下のように求められる。 inla.qmarginal(p = c(0.025, 0.5, 0.975), pmbeta1) ## [1] 7.380707 7.432135 7.483562 inla.zmarginalでは、自動的に要約統計量を算出してくれる。 inla.zmarginal(pmbeta2) ## Mean -0.413666 ## Stdev 0.0262696 ## Quantile 0.025 -0.465272 ## Quantile 0.25 -0.431393 ## Quantile 0.5 -0.413722 ## Quantile 0.75 -0.39605 ## Quantile 0.975 -0.362171 また、最高密度区間(highest posterior density)5は以下のように求められる。 inla.hpdmarginal(0.95, pmbeta2) ## low high ## level:0.95 -0.4652722 -0.3621714 precision\\(\\tau\\)は容易に\\(\\sigma\\)に変換できる。 pm.sigma &lt;- inla.tmarginal(function(x) sqrt(1/x), pmtau) 事後分布はこれらを用いて容易に作図できる。 ## beta1 pmbeta1 %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(beta[1]), y = expression(paste(&quot;P( &quot;, beta[1] ,&quot; | Data)&quot;))) -&gt; p1 ## beta2 pmbeta2 %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(beta[2]), y = expression(paste(&quot;P( &quot;, beta[2] ,&quot; | Data)&quot;))) -&gt; p2 ## tau pmtau %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(tau), y = expression(paste(&quot;P( &quot;, tau ,&quot; | Data)&quot;))) -&gt; p3 ## sigma pmtau %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(sigma), y = expression(paste(&quot;P( &quot;, sigma ,&quot; | Data)&quot;))) -&gt; p4 p1 + p2 + p3 + p4 + plot_layout(ncol = 2) 6.9 追記 INLAの詳しい使い方やそれを用いたモデリングについての詳しい解説は、以下の本が役に立つ。いずれも無料でオンラインで閲覧可能である。 Bayesian inference with INLA Bayesian Regression Modeling with INLA6 Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA Dynamic Time Series Models using R-INLA: An Applied Perspective References "],["Chapter8.html", "7 Multiple linear regression in R-INLA 7.1 Introduction 7.2 Data exploration 7.3 Linear regression result 7.4 Model validation 7.5 Model selection 7.6 Visualizing the model", " 7 Multiple linear regression in R-INLA 本章では、時空間相関を持つモデルを実行する方法について学ぶ前に、よりシンプルなモデル(重回帰分析)をINLAパッケージで実行する方法やそこから予測値や残差を抽出したり、モデル診断やモデル選択を行う方法を学ぶ。 7.1 Introduction 本章では、チンパンジーの道具使用を調べた Hopkins et al. (2015) のデータを用いる。リサーチクエスチョンは、アリ釣りの技術が性別、年齢、生育環境で変わるのかである。 データでは、アリ釣りの技術は1回成功するまでの時間(潜時: Latency)で測定されている。計243個体の平均潜時を標準化した値がデータとして用いられている。また、説明変数は年齢Age、性別Sex、生育環境(rear; 1: 母親に育てられた、2: 人間に育てられた、3: 野生由来)、事件が実施された研究施設(Colony; 1か2)である。データは以下の通り。 chimp &lt;- read_delim(&quot;data/Chimps.txt&quot;) datatable(chimp, options = list(scrollX = 20), filter = &quot;top&quot;) 7.2 Data exploration まずデータの確認を行う。図7.1は全ての変数のdotplot(Zuur 2012)を示したものである。平均潜時が大きい個体が2頭いる点に注意が必要である。 Hopkins et al. (2015) ではこれらは取り除かれたが、本章では入れて分析を行う。年齢は均等にばらついているように見える。 chimp %&gt;% select(Sex, Age, Z_Latency, Colony, rear) %&gt;% mutate(N = 1:n()) %&gt;% pivot_longer(1:5) %&gt;% ggplot(aes(x = value, y = N))+ geom_point()+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1) 図7.1: Cleveland dotplots of all the variables. このデータには疑似反復はないように思える。各個体のデータは1つずつしかないし、時間的・空間的な相関が生じる要素もない。遺伝的な関連を考慮する必要があるかもしれないがここではひとまず扱わない。モデルに遺伝的な相関を取り入れる方法については、 Ga and Fox などを参照。 ##Model formulation 以下のモデルを考える。なお、rearは3水準あるので2つの回帰係数のパラメータが推定される点は注意。 \\[ \\begin{aligned} &amp;Latency_i \\sim N(\\mu_i, \\sigma^2)\\\\ &amp;E(Latency_i) = \\mu_i \\; \\rm{and} \\; var(Latency_i) = \\sigma^2 \\\\ &amp;\\mu_i = \\beta_1 + \\beta_2 \\times Age_i + \\beta_3 \\times Sex_i + \\beta_4 \\times Colony_i + \\beta_5(\\rm{and \\; \\beta_6}) \\times rear_i \\end{aligned} \\] 7.3 Linear regression result 7.3.1 Executing the model in R=INLA まず、Sex、Colony、rearについては変数を因子型にする。 chimp &lt;- chimp %&gt;% mutate(fSex = factor(Sex), fColony = factor(Colony), frear = factor(rear)) 次に、INLAでモデリングを行う。 m8_1 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975))) 7.3.2 Output for betas 7.3.2.1 Numerical output for the betas \\(\\sigma\\)以外のパラメータの事後分布の情報は以下のとおりである。年齢の95%確信区間は0を含まないので、年齢は平均潜時に影響を与えているといえそう。そのほかの切片以外のパラメータは全て95%確信区間に0を含んでいる。 m8_1$summary.fixed 7.3.2.2 Graphical output for the betas \\(\\beta_2\\)の事後分布は以下のように図示できる。 beta2 &lt;- m8_1$marginals.fixed$Age beta2 %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(beta[2]), y = expression(paste(&quot;P( &quot;, beta[2] ,&quot; | Data)&quot;))) 7.3.3 Output for hyperparameters 7.3.3.1 Numerical output for hyper parameters ハイパーパラメータ\\(\\tau = 1/\\sigma^2\\)の事後分布の要約統計量は以下のように出せる。 m8_1$summary.hyperpar しかしこれらは\\(\\tau\\)についてのものであって、私たちが知りたいのは\\(\\sigma = 1/\\sqrt\\tau\\)の事後分布である。\\(\\tau\\)の期待値は以下のように書ける(第6.3節参照)。 \\[ E(\\tau) = \\int_{-\\infty}^{\\infty} \\tau \\times p(\\tau) d\\tau \\tag{7.1} \\] 一方で、$= h() = 1/ \\(とするとき、\\)$の期待値は以下のようになる。 \\[ E(\\sigma) = \\int_{-\\infty}^{\\infty} h(\\tau) \\times p(\\tau) d\\tau = \\int_{0}^{\\infty} \\frac{1}{\\sqrt{\\tau}} \\times p(\\tau) d\\tau \\tag{7.2} \\] これは、単純に\\(\\tau\\)の事後分布の期待値を\\(1/\\sqrt{\\tau}\\)で変換しても、それは\\(\\sigma\\)の期待値ではないことを示している。幸いなことに、INLAではこれを計算してくれる関数が用意されている。 tau &lt;- m8_1$marginals.hyperpar$`Precision for the Gaussian observations` sigma &lt;- inla.emarginal(function(x) 1/sqrt(x), tau) sigma ## [1] 0.9767155 確かにこの値は単純に\\(\\tau\\)の事後分布の期待値を\\(1/\\sqrt{E(\\tau)}\\)で変換したものとは違う。 etau &lt;- m8_1$summary.hyperpar[,&quot;mean&quot;] 1/sqrt(etau) ## [1] 0.9736711 他の要約統計量が知りたい場合は、inla.tmarginalを用いればよい。 pmtau &lt;- m8_1$marginals.hyperpar$`Precision for the Gaussian observations` pm.sigma &lt;- inla.tmarginal(function(x) sqrt(1/x), pmtau) inla.zmarginal(pm.sigma) ## Mean 0.9767 ## Stdev 0.0445711 ## Quantile 0.025 0.8939 ## Quantile 0.25 0.945629 ## Quantile 0.5 0.974946 ## Quantile 0.75 1.00581 ## Quantile 0.975 1.06894 7.3.3.2 Graphical output for the hyperparameters \\(\\tau\\)の事後分布は以下のように図示できる(図7.2のA)。ただし、これにはわずかに45ポイントのデータしか使用されていないので、少しカクカクしている。inla.smarginal関数を用いると、スプライン回帰によってよりスムーズにしてくれる(図7.2のB)。 pmtau %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(tau), y = expression(paste(&quot;P( &quot;, tau ,&quot; | Data)&quot;)))+ labs(title = &quot;A&quot;) -&gt; p1 tau.smooth &lt;- inla.smarginal(pmtau) tau.smooth %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(tau), y = expression(paste(&quot;P( &quot;, tau ,&quot; | Data)&quot;)))+ labs(title = &quot;B&quot;) -&gt; p2 p1 + p2 図7.2: Pusterior distribution of tau 7.3.4 Fitted model 推定されたパラメータの事後分布から、モデル式は以下のように書ける。 \\[ \\begin{aligned} &amp;Latency_i \\sim N(\\mu_i, 0.97^2)\\\\ &amp;E(Latency_i) = \\mu_i \\; \\rm{and} \\; var(Latency_i) = 0.97^2 \\\\ \\\\ &amp;\\rm{for \\; chimpanzee \\; of \\; sex = 1, colony = 1, and \\; rear = 1}\\\\ &amp;\\mu_i = -0.45 + 0.02 \\times Age_i\\\\ \\\\ &amp;\\rm{for \\; chimpanzee \\; of \\; sex = 2, colony = 2, and \\; rear = 2}\\\\ &amp;\\mu_i = -0.45 + 0.02 \\times Age_i -0.22 +0.09 + 0.05\\\\ &amp; \\;\\;\\; = -0.52 + 0.02 \\times Age_i \\end{aligned} \\] 7.4 Model validation 前章で計算したように事後平均を用いた\\(\\mu_i\\)の予測値を手動で計算することもできるが(6.8.1)、以下のように求めることもできる。fit8_1には予測値の95%確信区間も入っている。 fit8_1 &lt;- m8_1$summary.fitted.values resid &lt;- chimp$Z_Latency - fit8_1$mean 予測値と残差の関係を示したのが図7.3である。明らかに残差が大きい点が2つある。 data.frame(fitted = fit8_1$mean, resid = resid) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;) 図7.3: Fitted vs residuals 予測値と実測値の関係を見ても、あまり当てはまりがよいように見えない。 data.frame(Latency = chimp$Z_Latency, fitted = fit8_1$mean) %&gt;% ggplot(aes(x = fitted, y = Latency))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Latency&quot;) 図7.4: Fitted vs residuals 予測値を手動で計算する方法は、リンク関数が恒等関数のときのみ正確な値になる。なぜなら、もしリンク関数で線形予測子を変換した後の期待値は線形予測子の期待値を変換するものと一致しないからである(式(7.1)と式(7.2)も参照)。 \\[ E(h(x)) \\neq h(E(x)) \\] 7.5 Model selection 7.5.1 What should we do? ベイズ統計でモデル選択を行うとき、話は通常の頻度論的な場合よりも複雑になる。以下では、ベイズモデリング(特にINLA)で用いることのできるモデル選択方法について議論する。 7.5.2 Usind the DIC AIC(赤池情報量規準)はモデル選択の際に最も一般的な指標である。なお、\\(L\\)はパラメータが与えられたときのデータの尤度(e.g., \\(P(D|\\beta_1, \\beta_2, \\sigma)\\))、\\(k\\)はパラメータ数である。\\(log(L)\\)は対数尤度、\\(-2 \\times log(L)\\)は逸脱度(deviance)といわれる。共変量をたくさん入れればモデルの当てはまりはよくなるが(\\(Lが高くなる\\))、パラメータ数が増える(\\(p\\)が大きくなる)という関係が成り立っている。AICが低いほど「良い」モデルということになる。 \\[ AIC = -2 \\times log(L) + 2\\times p \\] もし事前分布が無情報なのであればパラメータ数は知ることができるが、事前分布が情報を持っている場合、回帰係数がとりうる範囲は限定されるので、モデルの自由度やパラメータ数は変わってくる。すなわち、このような場合にはAICは適していない。 このようなときに使えるのがDICである。DICは\\(\\theta\\)を全てのパラメータを含むベクトル、\\(f(y|\\theta)\\)を尤度、\\(D(\\bar{\\theta}) = -2 \\times p(y|\\bar{\\theta})\\)をパラメータの期待値7が与えられた時の逸脱度とするとき、以下のように定義される。 \\[ DIC = D(\\bar{\\theta}) + 2 \\times p_D \\] なお、\\(p_D\\)は有効パラメータ数と呼ばれるもので、事前分布が無情報に近づくとパラメータ数\\(p\\)と一致する。また、事後分布が無情報に近づくほど頻度論での最尤推定値がベイズ統計の事後分布の期待値と一致する。よって、事前分布が無情報であればAICとDICはほとんど一致する。 これを実際にRで確かめよう。 まず、AICは以下のようになる。 m8_2 &lt;- lm(Z_Latency ~ Age + fSex + fColony + frear, data = chimp) ## 対数尤度 logLik(m8_2) ## &#39;log Lik.&#39; -336.2983 (df=7) ## AIC AIC(m8_2) ## [1] 686.5965 続いて、INLAでDICも求める。control.computeオプションで、dic = TRUEとすればよい。INLAはデフォルトでは無情報事前分布が用いられている。 m8_1 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1$dic$dic ## [1] 686.6328 AICとDICはほとんど一致する。 7.5.2.1 Effective number of parameters 有効パラメータ数の求め方には2つある。1つ目は以下の通り。なお、\\(\\bar{D}\\)は逸脱度の平均を表す。 \\[ p_D = \\bar{D} - D(\\bar{\\theta}) \\] このとき、DICは以下のように書き直せる。 \\[ \\begin{aligned} DIC &amp;= D(\\bar{\\theta}) + 2 \\times p_D \\\\ &amp;= D(\\bar{\\theta}) + 2 \\times (\\bar{D} - D(\\bar{\\theta}))\\\\ &amp;= \\bar{D} + \\bar{D} -D(\\bar{\\theta})\\\\ &amp;= \\bar{D} + p_D \\end{aligned} \\] 7.5.2.2 DIC related output DICは実際のINLAの出力から計算することができる。 pD = m8_1$dic$mean.deviance - m8_1$dic$deviance.mean DIC &lt;- m8_1$dic$mean.deviance + pD DIC ## [1] 686.6328 7.5.2.3 Model selection using DIC それでは、実際にDICを比較してみる。先ほどのモデルから年齢以外の説明変数を1つずつ除いた以下のモデルを比較する。 m8_1b &lt;- inla(Z_Latency ~ fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1c &lt;- inla(Z_Latency ~ Age + fSex + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1d &lt;- inla(Z_Latency ~ Age + fSex + fColony, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) DICの結果、frearがないモデルが最もDICが低いことが分かった。 c(m8_1$dic$dic, m8_1b$dic$dic, m8_1c$dic$dic, m8_1d$dic$dic) ## [1] 686.6328 692.3986 685.0378 682.7590 ここからは、さらにm8_1dから1つずつ説明変数を除いたモデルを作成し、DICが減少しなくなるまで同様の比較を続ける。 m8_1e &lt;- m8_1 &lt;- inla(Z_Latency ~ Age + fColony, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1f &lt;- m8_1 &lt;- inla(Z_Latency ~ Age + fSex, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1dより、そこからfColonyを除いたモデルのDICの方が低い。 c(m8_1d$dic$dic, m8_1e$dic$dic, m8_1f$dic$dic) ## [1] 682.7590 683.7640 681.4553 さらにm8_1fからfSexを除いたモデルと比較する。 m8_1g &lt;- m8_1 &lt;- inla(Z_Latency ~ Age, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) 最終的に、m8_1fが最もDICが低いことが分かった。 c(m8_1f$dic$dic, m8_1g$dic$dic) ## [1] 681.4553 682.0625 7.5.3 WAIC DICのほかには、WAIC(widely applicable information criterion)を使うこともできる。WAICはDICをより発展させたものととらえられる。WAICの解説については、 McElreath (2020) も参照。 INLAでは以下のようにして計算できる。 m8_1 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(waic = TRUE)) m8_1$waic$waic ## [1] 696.295 7.5.4 Out of sample prediction 最後に、DICやWAICのような情報量規準ではなく、交差検証(cross validation)と呼ばれる方法を用いることもできる。この方法では、例えばデータをらなダムに2つ(\\(D_{fit}\\)と\\(D_{pred}\\))に分ける。その後\\(D_{fit}\\)に対してあるモデルを当てはめ、その結果をもとに\\(D_{fit}\\)の予測を行う。以上を何度も繰り返し、それらを総合してそのモデルの精度を評価する。これを複数のモデルに対して行い、そのモデルが最も良いかを調べるのが交差検証である。 INLAでも交差検証を行う。INLAでは、\\(D_{fit}\\)を1つだけの観測値を除いたデータとし、これを全ての観測値に対して行う交差検証を行う。これは”leave one out” 交差検証と呼ばれる。INLAは交差検証によってCPO(conditional predictive ordinate)やPIT(probability integral transform)と呼ばれる値を算出する。 CPOは、除かれた1つの観測値が、その他の観測値が与えられたときに得られる確率として定義される。\\(CPO_i\\)が高いほど他のデータを用いて推定されたモデルに従うことを示す。 \\[ CPO_i = Pr(除かれた観測値_i|そのほかの観測値) \\] PITはCPOの代替的な指標である。説明はこちらや Blangiardo and Cameletti (2015) に詳しい。 INLAでは\\(CPO_i\\)を以下のように算出できる。 m8_3 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(cpo = TRUE)) 以下のm8_3$cpoには3つのリストが含まれる。m8_3$cpo$cpoは\\(CPO_i\\)が、m8_3$cpo$pitは\\(PIT_i\\)がデータ数だけ含まれる。3つめのm3_8$cpo$failureはもし1であればその観測値のCPOやPITが信頼できないことを表す。 m8_3$cpo %&gt;% data.frame() %&gt;% datatable() CPOのdotplotを図示すると以下のようになる。それも低い値をとっており、モデルの当てはまりがよくないことが分かる。 m8_3$cpo %&gt;% data.frame() %&gt;% mutate(n = 1:n()) %&gt;% ggplot(aes(x = cpo, y = n))+ geom_point()+ coord_cartesian(xlim = c(0,1))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;CPO&quot;, y = &quot;Observation number&quot;) モデル選択では、様々なモデルに対して同様にCPOを算出し、どのモデルがよりよく当てはまっているかを比べる。しかし実際にこれを基に判断するのは難しい。他の方法としては、モデルごとに\\(CPO_i\\)を1つの値にまとめ、それをモデル間で比較するというものである。例えば、\\(log(CPO_i)\\)の合計をそのモデルの当てはまりの良さとして使用することができる。 sum(log(m8_3$cpo$cpo)) ## [1] -347.8294 7.5.5 Posterior predictive check モデルの当てはまりをチェックする方法としては、モデルから事後予測分布を算出するというものである。事後予測分布は、モデルから推定された事後分布をもとに新たにデータを生成したときに、新たに得られるデータの予測分布のことである。INLAでは以下のようにして事後予測分布を計算できる。 7.5.5.1 Zuur (2017)の方法 どうやら、以下は平均\\(\\mu_i\\)の事後周辺分布を算出しているに過ぎないよう。事後予測分布ではない点に注意。よって、事後予測p値も間違っている。 m8_4 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.predictor = list(compute = TRUE), control.compute = list(return.marginals.predictor=TRUE)) 例えば、1頭目のチンパンジーの平均潜時の事後予測分布は以下のようになる。実測値を黒い点で示した。 m8_4$marginals.fitted.values[[1]] %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ geom_point(data = chimp %&gt;% .[1,], aes(x = Z_Latency, y = 0), size = 4.5)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Latency scores of chimp 1&quot;, y = &quot;Density&quot;) 全観測値について95%予測区間(事後予測分布の95%区間)と観測値の関係を示したのが以下の図である。実測値が95%予測区間に入ってないものがかなり多くあることが分かる。このことは、このモデルから実際のデータが得られたとは言いにくいということを示している。 postpre8_4 &lt;- m8_4$marginals.fitted.values postpre_all &lt;- data.frame() for(i in 1:nrow(chimp)){ summary_i &lt;- inla.qmarginal(c(0.025, 0.5, 0.975), postpre8_4[[i]]) %&gt;% data.frame() %&gt;% rename(value = 1) %&gt;% mutate(col = c(&quot;q2.5&quot;,&quot;q50&quot;, &quot;q97.5&quot;)) %&gt;% pivot_wider(names_from = col, values_from = value) %&gt;% mutate(id = i) postpre_all &lt;- bind_rows(postpre_all, summary_i) } postpre_all %&gt;% mutate(id2 = c(rep(&quot;1~61&quot;,61),rep(&quot;62~122&quot;,61), rep(&quot;123~183&quot;,61), rep(&quot;184~243&quot;,60))) %&gt;% ggplot(aes(x = id))+ geom_errorbar(aes(ymin = q2.5, ymax = q97.5))+ geom_point(data = chimp %&gt;% mutate(id = 1:n(), id2 = c(rep(&quot;1~61&quot;,61),rep(&quot;62~122&quot;,61), rep(&quot;123~183&quot;,61), rep(&quot;184~243&quot;,60))), aes(x = id, y = Z_Latency), size = 1)+ theme(aspect.ratio = 0.5)+ facet_rep_wrap(~id2, repeat.tick.labels = TRUE, scales = &quot;free&quot;) 事後予測分布をもとにモデルの当てはまりを評価するために、事後予測p値という値が考えられているようだ。これは、事後予測分布が実測値よりも小さい値をとる確率\\(Pr(Latency_i^* \\le Latency_i|D)\\)で定義される。なお、\\(Latency_i^*\\)は事後予測分布の値である。事後予測p値が0や1に近い値が多いならば、このモデルの当てはまりは悪いということになる。 では、実際に算出してみる。図示すると、やはり0や1に近い値が多くてモデルの当てはまりが悪いことが分かる。 pval &lt;- rep(NA, nrow(chimp)) for(i in 1:nrow(chimp)){ pval[i] &lt;- inla.pmarginal(q = chimp$Z_Latency[[i]], marginal = postpre8_4[[i]]) } data.frame(pval = pval) %&gt;% ggplot()+ geom_histogram(aes(x = pval), bins = 20, alpha = 0, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(0,1,0.1)) 7.5.5.2 正しい方法 以下、事後予測分布をシミュレーションによってサンプリングする方法を解説する。参考にしたのはこちらとこちら。 INLAパッケージでは、事後同時分布からランダムに値を抽出できるinla.posterior.sample関数が存在する。これを使用するためには、モデルを実行する際にcontrol.computeオプションでconfig = TRUEとする必要がある。 m8_4b &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(config = TRUE)) 以下のようにして、事後同時分布からサンプルを抽出できる。 sim_jointpost &lt;- inla.posterior.sample(n = 10000, m8_4b) 例えば、1つ目のサンプルは以下のようになる。ここには、事後同時分布からサンプルされた各パラメータの値と、そのときの各個体の期待値(予測値、\\(\\mu_i\\))の値が格納されている。 sim_jointpost[[1]] ## $hyperpar ## Precision for the Gaussian observations ## 0.73403 ## ## $latent ## [,1] ## Predictor:1 -0.558618428 ## Predictor:2 0.219764665 ## Predictor:3 0.310161225 ## Predictor:4 0.100380575 ## Predictor:5 -0.199812090 ## Predictor:6 -0.473460892 ## Predictor:7 -0.417944955 ## Predictor:8 -0.367013972 ## Predictor:9 0.070738977 ## Predictor:10 -0.027355729 ## Predictor:11 0.249406264 ## Predictor:12 0.267582457 ## Predictor:13 -0.098604195 ## Predictor:14 0.034371134 ## Predictor:15 0.007842726 ## Predictor:16 -0.665065349 ## Predictor:17 -0.260567052 ## Predictor:18 -0.048645113 ## Predictor:19 -0.093365170 ## Predictor:20 -0.665065349 ## Predictor:21 -0.579907813 ## Predictor:22 -0.217988284 ## Predictor:23 -0.622486581 ## Predictor:24 -0.157233322 ## Predictor:25 -0.072075786 ## Predictor:26 -0.112513265 ## Predictor:27 0.006870825 ## Predictor:28 -0.388303356 ## Predictor:29 -0.239277668 ## Predictor:30 -0.473460892 ## Predictor:31 -0.027355729 ## Predictor:32 -0.112513265 ## Predictor:33 -0.072075786 ## Predictor:34 0.185538111 ## Predictor:35 0.164248727 ## Predictor:36 -0.473460892 ## Predictor:37 -0.388303356 ## Predictor:38 -0.155092033 ## Predictor:39 0.352739993 ## Predictor:40 -0.162472347 ## Predictor:41 -0.034736043 ## Predictor:42 0.411369121 ## Predictor:43 0.036512423 ## Predictor:44 -0.263680242 ## Predictor:45 0.560394809 ## Predictor:46 0.079091191 ## Predictor:47 -0.601197197 ## Predictor:48 0.093000262 ## Predictor:49 -0.141182963 ## Predictor:50 0.225003689 ## Predictor:51 -0.643775965 ## Predictor:52 -0.027355729 ## Predictor:53 0.291985032 ## Predictor:54 0.206827495 ## Predictor:55 -0.345724588 ## Predictor:56 -0.006066345 ## Predictor:57 -0.537329044 ## Predictor:58 -0.226340499 ## Predictor:59 -0.622486581 ## Predictor:60 0.347500969 ## Predictor:61 -0.601197197 ## Predictor:62 0.374029377 ## Predictor:63 -0.141182963 ## Predictor:64 -0.098604195 ## Predictor:65 -0.558618428 ## Predictor:66 0.121669959 ## Predictor:67 -0.516039660 ## Predictor:68 -0.014418559 ## Predictor:69 -0.391416547 ## Predictor:70 0.185538111 ## Predictor:71 -0.162472347 ## Predictor:72 0.203714305 ## Predictor:73 -0.388303356 ## Predictor:74 0.119528670 ## Predictor:75 -0.048645113 ## Predictor:76 0.164248727 ## Predictor:77 0.483589488 ## Predictor:78 0.441010720 ## Predictor:79 -0.155092033 ## Predictor:80 -0.409592740 ## Predictor:81 -0.133802649 ## Predictor:82 -0.077314811 ## Predictor:83 0.164248727 ## Predictor:84 -0.452171508 ## Predictor:85 0.121669959 ## Predictor:86 -0.050786402 ## Predictor:87 -0.430882124 ## Predictor:88 -0.141182963 ## Predictor:89 -0.048645113 ## Predictor:90 -0.119893579 ## Predictor:91 -0.566970643 ## Predictor:92 0.347500969 ## Predictor:93 -0.430882124 ## Predictor:94 -0.324435204 ## Predictor:95 -0.388303356 ## Predictor:96 -0.622486581 ## Predictor:97 0.390079737 ## Predictor:98 -0.409592740 ## Predictor:99 -0.409592740 ## Predictor:100 -0.609549411 ## Predictor:101 0.228116880 ## Predictor:102 0.036512423 ## Predictor:103 -0.473460892 ## Predictor:104 0.441010720 ## Predictor:105 -0.324435204 ## Predictor:106 0.225003689 ## Predictor:107 0.390079737 ## Predictor:108 -0.135943938 ## Predictor:109 -0.034736043 ## Predictor:110 0.057801807 ## Predictor:111 -0.162472347 ## Predictor:112 0.539105425 ## Predictor:113 0.560394809 ## Predictor:114 0.100380575 ## Predictor:115 0.057801807 ## Predictor:116 -0.119893579 ## Predictor:117 -0.162472347 ## Predictor:118 0.185538111 ## Predictor:119 -0.034736043 ## Predictor:120 0.036512423 ## Predictor:121 0.164248727 ## Predictor:122 0.007842726 ## Predictor:123 -0.077314811 ## Predictor:124 -0.069934497 ## Predictor:125 -0.013446658 ## Predictor:126 -0.452171508 ## Predictor:127 0.632615176 ## Predictor:128 0.100380575 ## Predictor:129 -0.247629883 ## Predictor:130 0.142959343 ## Predictor:131 0.006870825 ## Predictor:132 0.475237273 ## Predictor:133 0.432658505 ## Predictor:134 -0.750222885 ## Predictor:135 -0.537329044 ## Predictor:136 -0.048645113 ## Predictor:137 -0.345724588 ## Predictor:138 -0.027355729 ## Predictor:139 -0.750222885 ## Predictor:140 -0.409592740 ## Predictor:141 -0.396655571 ## Predictor:142 -0.056025427 ## Predictor:143 -0.643775965 ## Predictor:144 -0.494750276 ## Predictor:145 -0.077314811 ## Predictor:146 0.164248727 ## Predictor:147 0.249406264 ## Predictor:148 -0.239277668 ## Predictor:149 -0.098604195 ## Predictor:150 -0.303145820 ## Predictor:151 -0.750222885 ## Predictor:152 0.347500969 ## Predictor:153 -0.750222885 ## Predictor:154 -0.598688794 ## Predictor:155 -0.556110026 ## Predictor:156 -0.282461224 ## Predictor:157 0.294493434 ## Predictor:158 -0.236769266 ## Predictor:159 0.333959012 ## Predictor:160 0.312669628 ## Predictor:161 -0.641267562 ## Predictor:162 -0.109032962 ## Predictor:163 -0.194190498 ## Predictor:164 0.060310210 ## Predictor:165 0.103860879 ## Predictor:166 -0.385794954 ## Predictor:167 -0.133435536 ## Predictor:168 -0.282461224 ## Predictor:169 0.419116548 ## Predictor:170 0.251914666 ## Predictor:171 -0.428373722 ## Predictor:172 0.180666200 ## Predictor:173 -0.598688794 ## Predictor:174 -0.194190498 ## Predictor:175 -0.279348034 ## Predictor:176 -0.470952490 ## Predictor:177 -0.449663106 ## Predictor:178 0.610721004 ## Predictor:179 -0.449663106 ## Predictor:180 0.270090860 ## Predictor:181 0.355248396 ## Predictor:182 -0.282461224 ## Predictor:183 -0.449663106 ## Predictor:184 0.333959012 ## Predictor:185 -0.159963944 ## Predictor:186 -0.282461224 ## Predictor:187 -0.303750608 ## Predictor:188 -0.577399410 ## Predictor:189 0.228483993 ## Predictor:190 -0.303750608 ## Predictor:191 0.376537780 ## Predictor:192 0.504274084 ## Predictor:193 -0.236769266 ## Predictor:194 0.207194608 ## Predictor:195 0.036879536 ## Predictor:196 -0.598688794 ## Predictor:197 0.397827164 ## Predictor:198 -0.534820642 ## Predictor:199 0.039020826 ## Predictor:200 0.568142236 ## Predictor:201 -0.598688794 ## Predictor:202 -0.346329376 ## Predictor:203 0.419116548 ## Predictor:204 -0.197303688 ## Predictor:205 -0.218593072 ## Predictor:206 -0.598688794 ## Predictor:207 0.419116548 ## Predictor:208 0.036879536 ## Predictor:209 -0.096095792 ## Predictor:210 -0.074806408 ## Predictor:211 -0.577399410 ## Predictor:212 0.270090860 ## Predictor:213 0.355248396 ## Predictor:214 0.273204050 ## Predictor:215 0.074219280 ## Predictor:216 0.249773377 ## Predictor:217 0.180666200 ## Predictor:218 -0.321926802 ## Predictor:219 -0.069567384 ## Predictor:220 -0.513531258 ## Predictor:221 0.270090860 ## Predictor:222 -0.010938256 ## Predictor:223 -0.131294247 ## Predictor:224 -0.385794954 ## Predictor:225 -0.282461224 ## Predictor:226 -0.385794954 ## Predictor:227 0.549966042 ## Predictor:228 -0.449663106 ## Predictor:229 0.015590152 ## Predictor:230 -0.641267562 ## Predictor:231 -0.026988616 ## Predictor:232 0.397827164 ## Predictor:233 -0.154724920 ## Predictor:234 0.166757130 ## Predictor:235 0.039020826 ## Predictor:236 -0.385794954 ## Predictor:237 -0.556110026 ## Predictor:238 -0.032227640 ## Predictor:239 -0.556110026 ## Predictor:240 0.124178362 ## Predictor:241 -0.513531258 ## Predictor:242 0.079458304 ## Predictor:243 0.397827164 ## (Intercept):1 -0.346696489 ## Age:1 0.021289384 ## fSex2:1 -0.595130852 ## fColony2:1 0.108955323 ## frear2:1 0.231070034 ## frear3:1 -0.029641599 ## ## $logdens ## $logdens$hyperpar ## [1] -4.42645 ## ## $logdens$latent ## [1] 3.895123 ## ## $logdens$joint ## [1] -0.5313266 例えば、1つ目のサンプルにおける243番目の個体の予測値とその時使用されたパラメータの値は以下のようになる。 tail(sim_jointpost[[1]]$latent, n = 7) ## [,1] ## Predictor:243 0.39782716 ## (Intercept):1 -0.34669649 ## Age:1 0.02128938 ## fSex2:1 -0.59513085 ## fColony2:1 0.10895532 ## frear2:1 0.23107003 ## frear3:1 -0.02964160 全個体について、予測値(期待値)とハイパーパラメータ\\(\\tau\\)を10000サンプル分まとめる。 post_samples &lt;- matrix(ncol = nrow(chimp), nrow = 10000) tau &lt;- rep(NA, 10000) for(i in 1:10000){ for(j in 1:nrow(chimp)){ post_samples[i,j] &lt;- sim_jointpost[[i]]$latent[j,1] tau[i] &lt;- sim_jointpost[[i]]$hyperpar[1] } } 例えば、個体21について得られた予測値のサンプルの分布を描くと、図7.5Aのようになる。これは、m8_4$marginal.fitted.valuesで取得した分布(図7.5B)とほぼ一致する。このことからも、m8_4$marginal.fitted.valuesで取得されたのはやはり期待値\\(\\mu_i\\)の事後分布であり、事後予測分布ではなかったことが分かる。 data.frame(x21 = post_samples[,21]) %&gt;% ggplot(aes(x = x21))+ geom_density()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Linear predictor of chimp 1&quot;, y = &quot;Density&quot;)+ coord_cartesian(xlim = c(-0.75, 0.15))+ labs(title = &quot;Simulation based&quot;) -&gt; p1 m8_4$marginals.fitted.values[[1]] %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Linear predictor of chimp 1&quot;, y = &quot;Density&quot;)+ coord_cartesian(xlim = c(-0.75, 0.15))+ labs(title = &quot;Using `marginal.fitted.values`&quot;) -&gt; p2 p1 + p2 図7.5: Posterior distribution of the linear predictor of sample 21. A: siulation based, B: using marginal.fitted.values 事後予測分布を得るためには、ここからさらに\\(\\sigma\\)(\\(\\tau\\))も入れたうえで正規分布からサンプリングを行う必要がある。以下のようにして、平均\\(\\mu_i\\)、標準偏差\\(\\sigma\\)の正規分布からサンプリングを行う。 y.sim &lt;- matrix(ncol = nrow(chimp), nrow = 10000) for(j in 1:nrow(chimp)){ y.sim[,j] &lt;- rnorm(10000, mean = post_samples[,j], sd = 1/sqrt(tau)) } 得られた値は以下の通り(最初の10サンプルのみ表示)。 y.sim %&gt;% data.frame() %&gt;% head(10) %&gt;% datatable(options = list(scrollX = 243)) 例えば、21番目の個体の事後予測分布は以下のようになる。当然だが、やはり期待値\\(\\mu_i\\)の事後分布(図7.5)よりも広い範囲の値をとる。 data.frame(x = y.sim[,21]) %&gt;% ggplot(aes(x = x))+ geom_histogram(aes(y = ..density..), color = &quot;black&quot;, alpha = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Posterior predictive samples of chimp 1&quot;, y = &quot;Density&quot;) 全個体の95%予測区間(事後予測分布の95%区間)を算出し、それと実測値の関係を見てみよう。図示すると(図7.6)、概ね実測値が95%予測区間の中に納まっているが、その範囲に入らないデータが6つあることが分かる。 int_pre &lt;- data.frame(id = 1:nrow(chimp), pi.lower = NA, pi.upper = NA) for(j in 1:nrow(chimp)){ int_pre[j,2] &lt;- quantile(y.sim[,j], probs = 0.025) int_pre[j,3] &lt;- quantile(y.sim[,j], probs = 0.975) } int_pre %&gt;% mutate(id2 = c(rep(&quot;1~61&quot;,61),rep(&quot;62~122&quot;,61), rep(&quot;123~183&quot;,61), rep(&quot;184~243&quot;,60))) %&gt;% ggplot(aes(x = id))+ geom_errorbar(aes(ymin = pi.lower, ymax = pi.upper))+ geom_point(data = chimp %&gt;% mutate(id = 1:n(), id2 = c(rep(&quot;1~61&quot;,61),rep(&quot;62~122&quot;,61), rep(&quot;123~183&quot;,61), rep(&quot;184~243&quot;,60))), aes(x = id, y = Z_Latency), size = 1)+ theme(aspect.ratio = 0.5)+ facet_rep_wrap(~id2, repeat.tick.labels = TRUE, scales = &quot;free&quot;) 図7.6: 95% predictive interval and observed values. 最後に事後予測p値を算出してヒストグラムを書く。わずかながら1にかなり近い値をとるデータがあり、当てはまりがあまり良いわけではないことが分かった。 pval &lt;- NA for(j in 1:nrow(chimp)){ pval[j] &lt;- sum(y.sim[,j] &lt;= chimp$Z_Latency[j])/nrow(y.sim) } data.frame(pval = pval) %&gt;% ggplot()+ geom_histogram(aes(x = pval), bins = 40, alpha = 0, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(0,1,0.1))+ scale_y_continuous(breaks = seq(0,16,1))+ coord_cartesian(xlim = c(0,1)) 7.6 Visualizing the model 最後に、モデルの予測値とその95%確信区間をデータ上に可視化する。 lm関数を用いた重回帰分析ではこれがかなり簡単に行える。例えば、fColony = 1、frear = 1のときの予測値とその95%信頼区間は以下のように描ける。 fit8_2 &lt;- ggpredict(m8_2, terms = c(&quot;Age[4:50,by = 0.1]&quot;,&quot;fSex&quot;), condition = c(fColony = &quot;1&quot;, frear = &quot;1&quot;)) fit8_2 %&gt;% data.frame() %&gt;% rename(Age = x, fSex = group) %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)) %&gt;% ggplot(aes(x = Age, y = predicted))+ geom_line()+ geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.4)+ geom_point(data = chimp %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)), aes(y = Z_Latency), shape = 1)+ facet_rep_wrap(~fSex)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Latency&quot;) INLAで同様のグラフを95%確信区間で書く方法は2つある。そのうち1つをここで紹介する(もう一つは第8章で紹介する)。 この方法は少しトリッキーだがうまくいく。まず、予測値を求めたい範囲のデータを格納し、かつZ_Latency = NAのデータフレームを作成する。 newdata &lt;- crossing(Z_Latency = NA, Age = seq(4,50,length = 100), fSex = c(&quot;1&quot;,&quot;2&quot;), fColony = &quot;1&quot;, frear = &quot;1&quot;) これをもとのデータにくっつけてモデルを実行すると、パラメータの推定自体に影響はないが、先ほどnewdataで指定した範囲についても予測値を算出することができる。 chimp2 &lt;- bind_rows(chimp, newdata) m8_5 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp2, control.predictor = list(compute = TRUE), control.compute = list(return.marginals.predictor=TRUE)) 確信区間等を算出し、244番目以降のデータについて抽出すればnewdataで指定したデータについての予測値と95%確信区間が得られる。図示した結果は頻度論の結果とほぼ変わらない。 fit8_5 &lt;- m8_5$summary.fitted.values[244:443,] %&gt;% bind_cols(newdata) fit8_5 %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)) %&gt;% ggplot(aes(x = Age, y = mean))+ geom_line()+ geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), alpha = 0.4)+ geom_point(data = chimp %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)), aes(y = Z_Latency), shape = 1)+ facet_rep_wrap(~fSex)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Latency&quot;) References "],["Chapter9.html", "8 Mixed effects modelling in R-INLA to analysis otolith data 8.1 Otoliths in plaice 8.2 Model formulation 8.3 Dependency 8.4 Data exploration 8.5 Running the model in R-INLA 8.6 Model validation 8.7 Model selection 8.8 Model interpretation 8.9 Multiple random effects 8.10 Changin prior of fixed parameters 8.11 Changing priors of hyperparameters", " 8 Mixed effects modelling in R-INLA to analysis otolith data 本章では、INLAで線形混合モデルを実行する方法を学ぶ。 8.1 Otoliths in plaice 平衡石(otholith)は魚類の96%にある耳内の器官で、海水から炭化カルシウムを生成して作られている。よって、平衡石の組成を調べればその魚がどこの海域にいたかを推定できる可能性がある。しかし、それを知るためには環境要因と生理的要因がそれぞれどのように平衡石の組成に影響しているかを調べなければならない。 本章では Sturrock et al. (2015) による実験研究のデータを用いる。25個体が7から12ヶ月自然環境に近い状況でタンクに入れて飼育され、生理学的変数(全長、体重、フルトンのcondition factor8、成長率、血漿中のタンパク質、元素濃度)と環境的変数(塩分濃度、温度、海水の元素濃度)が少なくとも1ヶ月ごとに測定された。 \\(^7Li, ^{26}Mg, ^{41}K,^{48}Ca, ^{88}Sr, ^{138}Ba\\)などの元素濃度が海水中、血漿中、そして平衡石中で測定された。また、性別や魚が生息していた海域、産卵を促すために特定のホルモン(GnRH)を与えられていたかなども測定された。 oto &lt;- read_csv(&quot;data/OTODATA.csv&quot;) datatable(oto, options = list(scrollX = 80), filter = &quot;top&quot;) 8.2 Model formulation Sturrock et al. (2015) では様々な元素濃度を用いたモデリングを行っているが、本章ではそのうちの一つであるSr(ストロンチウム)/Ca(カルシウム)比を応答変数とするモデルの解説を行う。 モデルの共変量としては、性別とGnRHの有無、生息していた海域、環境的変数(塩分濃度、気温、水中のSr濃度、水中のSr/Ca比)と生理学的変数(年齢、全長、体重、condition factor、成長率、血漿中タンパク質、血中Sr濃度、血中Sr/Ca比)が用いられた。交互作用は考えないものとする。 8.3 Dependency 分析するのに十分な平衡石の成長が見られたのは25頭中19頭だけだった。各個体について複数時点のデータがあるため、データは独立ではない(図8.1)。 oto %&gt;% mutate(Date = as.Date(Date, format = &quot;%d/%m/%Y&quot;)) %&gt;% group_by(Fish) %&gt;% mutate(date_num = Date - min(Date) + 1) %&gt;% ungroup() -&gt; oto oto %&gt;% ggplot(aes(x = Date, y = O.Sr.Ca))+ geom_point()+ scale_x_date(labels = date_format(&quot;%m&quot;), date_breaks = &quot;2 months&quot;) + facet_rep_wrap(~Fish, repeat.tick.labels = TRUE)+ labs(y = &quot;Sr / Ca ratio (mmmol / mol)&quot;, x = &quot;Time (months)&quot;)+ theme_bw()+ theme(aspect.ratio = 0.8) 図8.1: Plot of the Sr / Ca ratio versus time for each fish. ランダム切片に個体IDを入れることでこれについてはある程度対処できる(第4章参照)。この場合、同じ魚からのデータは全て相関\\(\\phi\\)であり、異なる魚の相関は0であると仮定される。ただし、時系列相関は考慮されない。モデル式は大まかに以下のように書ける。本章では分析をシンプルにするため、応答変数が正規分布から得られているとして分析を行う。 \\[ \\begin{aligned} \\rm{Sr/Ca \\; ratio} = &amp; \\rm{Intercept + Sex + GnRH + Origin} + \\\\ &amp;+ \\rm{lots \\; of \\; environmental \\; variables} \\\\ &amp;+ \\rm{lots \\; of \\; ephysiological \\; variables} \\\\ &amp;+ \\rm{random \\; intercept} + noise \\end{aligned} \\] 8.4 Data exploration 各変数のdotplotを以下に示した(図8.2)。平衡石の成長率(Otolithgrowthrate)のみすこし外れ値があるようだが、他は問題ないようだ。ひとまずはこのまま進む。 oto %&gt;% select(Age, Opacity, Growthrate, Otolithgrowthrate, B.Sr, B.Sr.Ca, Plasmaprotein,Condition, Totallength, O.Sr.Ca, Temp, Sal, SW.Sr, SW.Sr.Ca) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% mutate(n = 1:n()) %&gt;% ungroup() %&gt;% ggplot(aes(x = value, y = n))+ geom_point(size = 0.4)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 0.8) 図8.2: Cleveland dotplots of each variable. 現在説明変数がデータ数に対してかなり多い。一般的に、1パラメータ当たり15データが必要だといわれている。そこで、変数の多重共線性を調べて相関の高い変数がないかをVIF(分散拡大係数)で確認する。 library(car) m9_vif &lt;- lm(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + B.Sr.Ca + Plasmaprotein + Condition + Totallength+ Temp + Sal + SW.Sr + SW.Sr.Ca, data = oto) vif(m9_vif) %&gt;% data.frame() %&gt;% rename(vif=1) %&gt;% arrange(vif) いくつかVIFの高い変数があることが分かる。ここでは保守的にVIFが3以上の変数は用いないこととする(通常は閾値は5か10で構わない)。海水中のSr濃度(SW.Sr)が最も高いVIF(13.31)を示している。各変数間の相関を調べてみると(図8.3)、気温(Temp)や塩分濃度(Sal)、海中Sr/Ca比(SW.Sr.Ca)と強く相関していることが分かる。よって、これらのどれかを除くとVIFは小さくなりそう。本章では、SW.Srを除くことにする。また、これ以外にVIFが高かった全長(Totallength)も除くことにする。 ggpairs(oto %&gt;% select(Age, Opacity, Growthrate, Otolithgrowthrate, B.Sr, B.Sr.Ca, Plasmaprotein,Condition, Totallength, Temp, Sal, SW.Sr, SW.Sr.Ca)) 図8.3: Relationship between covariates. 改めてVIFを調べると、まだVIFが3を超えるものが3つだけあることが分かる。血中Sr濃度と血中Sr/Ca比も中程度の相関があるようなので、血中Sr/Ca比を除くことにする。 m9_vif2 &lt;- lm(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + B.Sr.Ca + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca, data = oto) vif(m9_vif2) %&gt;% data.frame() %&gt;% rename(vif=1) %&gt;% arrange(vif) 最終的に全てのVIFが3以下になった。 m9_vif3 &lt;- lm(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca, data = oto) vif(m9_vif3) %&gt;% data.frame() %&gt;% rename(vif=1) %&gt;% arrange(vif) 8.5 Running the model in R-INLA 最終的に選ばれた変数から、以下のようなモデルを実行する。 \\[ \\begin{aligned} &amp;SrCa_{ij} = \\rm{Intercept + Covariates} + a_i + \\epsilon_{ij}\\\\ &amp;a_i \\sim N(0, \\sigma_{Fish}^2)\\\\ &amp;\\epsilon_{ij} \\sim N(0, \\sigma^2) \\end{aligned} \\] モデルの収束をよくするため、連続値の説明変数は標準化する。Opacityは3つの値(0, 0.5, 1)しか取らないので標準化しなかった。 oto %&gt;% select(Fish, O.Sr.Ca, Sex, GnRH, Age, Origin, Growthrate, Otolithgrowthrate, B.Sr, Plasmaprotein, Condition, Temp, Sal, SW.Sr.Ca) %&gt;% mutate_if(is.numeric, ~scale(.)[,1]) %&gt;% mutate(Opacity = oto$Opacity) %&gt;% mutate(Date = oto$Date, date_num = oto$date_num) %&gt;% drop_na() -&gt; oto2 モデルは以下の通り。ランダム切片はf(Fish, model = \"iid)のように指定する。iidはindependent and identical distributed を表す。すなわち、同じ分布から独立に得られたと仮定するということである。 m9_1 &lt;- inla(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca + f(Fish, model = &quot;iid&quot;), control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975)), control.compute = list(dic = TRUE), data = oto2) 固定効果の結果は以下の通り。血中Sr濃度(B.Sr)、血漿中タンパク(Plasmaprotein)、気温(Temp)、塩分濃度Salinityは95%確信区間に0を含んでおらず、これらの変数は影響があるといえそう。 m9_1$summary.fixed %&gt;% select(1,2,3,5) ハイパーパラメータの結果は以下の通り。しかし、前章で見たようにこれらは\\(\\tau = 1/\\sigma^2\\)の事後推定値である。 m9_1$summary.hyperpar %&gt;% select(1,2,3,5) \\(\\sigma\\)と\\(\\sigma_{Fish}\\)の事後平均値は以下のように求められる。 tau &lt;- m9_1$marginals.hyperpar$`Precision for the Gaussian observations` tau_fish &lt;- m9_1$marginals.hyperpar$`Precision for Fish` sigma &lt;- inla.emarginal(function(x) 1/sqrt(x), tau) sigma_fish &lt;- inla.emarginal(function(x) 1/sqrt(x), tau_fish) c(sigma, sigma_fish) ## [1] 0.6628616 0.4673066 級内相関係数は以下の通り。すなわち、同じ個体のデータの相関は0.33くらいであると推定された。 sigma_fish^2/(sigma^2 + sigma_fish^2) ## [1] 0.3319982 8.6 Model validation モデルの予測値と残差は以下のように計算できる。 fit9_1 &lt;- m9_1$summary.fitted.values fit9_1 %&gt;% bind_cols(oto2) %&gt;% mutate(resid = O.Sr.Ca - mean) -&gt; fit9_1b 残差と予測値にはパターンはなく、等分散性の仮定は満たされていそう。 fit9_1b %&gt;% ggplot(aes(x = mean, y = resid))+ geom_point()+ theme_bw()+ theme(aspect.ratio = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) 残差と説明変数の関係をプロットしても明確なパターンはなさそう? fit9_1b %&gt;% select(resid, Sex:Opacity) %&gt;% select(-Sex, -Origin, -GnRH) %&gt;% pivot_longer(2:11) %&gt;% ggplot(aes(x = value, y = resid))+ geom_point(shape = 1)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1) fit9_1b %&gt;% select(resid, Sex, Origin, GnRH) %&gt;% pivot_longer(2:4) %&gt;% ggplot(aes(x = value, y = resid))+ geom_boxplot(shape = 1)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 1) QQプロットを見ても問題はなさそう。残差の正規性も問題ない。 qqPlot(fit9_1b$resid, ylab = &quot;Sample quantiles&quot;) ## [1] 120 187 最後に、残差の時系列相関があるかを確認する。図を見ると明確に時間的に近いポイントで残差が類似した値をとっていることが見て取れる。すなわち、残差は独立ではなく時系列相関が存在すると考えられる。 fit9_1b %&gt;% ggplot(aes(x = Date, y = resid))+ geom_point(shape = 1)+ scale_x_date(labels = date_format(&quot;%m&quot;), date_breaks = &quot;2 months&quot;)+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 0.8)+ facet_rep_wrap(~Fish, repeat.tick.labels = TRUE) 本来はここで時系列相関を考慮したモデルを作るべきだが、ひとまずここではこのまま解説を続ける。続いて、ランダム効果の前提が満たされているかも確認する。 各個体の\\(a_i\\)の事後分布の要約統計量は以下のように確認できる。 a &lt;- m9_1$summary.random a$Fish 19個しかないのでその正規性をきちんと検討することはできないが、QQプロットを見る限りそこまで大きな問題はなさそう? qqPlot(a$Fish$mean, ylab = &quot;a&quot;) ## [1] 5 7 8.7 Model selection 前章でやったように、DICやWAICでモデル選択をすることはできる。ここではやらない。 8.8 Model interpretation モデルを解釈する際には、結果を可視化することが重要だ。ある説明変数と応答変数の関係についてみる場合には、それ以外の説明変数を固定する必要がある。通常は連続変数であれば平均を(今回は標準化しているので全て0)、離散変数であれば特定の水準に固定することが多い。これを行う方法は2つあるが、そのうち一つは前章(7.6)で解説したので、本節ではもう一つの方法も解説する。 8.8.1 Option 1 for prediction: Adding extra data まずは前章でも見た一つ目の方法で行う。以下では、血漿中タンパク質とSr/Ca比の関連についてプロットする。ここでは、ランダム効果を含まない予測値を図示したいので、Fish = NAとする。また、連続変数は血漿中タンパク質以外は0(Opacityだけ標準化されていないので平均をとる)、離散変数についてはOrigin‘はEC(English channel)、GnRHはNon-treated、SexはF`に固定する。 newdata &lt;- data.frame(O.Sr.Ca = rep(NA, 25),# Fish = factor(NA, levels =levels(oto2$Fish)), Sex = factor(&quot;F&quot;, levels = c(&quot;F&quot;, &quot;M&quot;)), Origin = factor(&quot;EC&quot;, levels = c(&quot;EC&quot;, &quot;IS&quot;)), GnRH = factor(&quot;Non-treated&quot;, levels = c(&quot;Non-treated&quot;,&quot;Treated&quot;)), Temp = 0, Sal = 0, SW.Sr.Ca = 0, B.Sr = 0, Plasmaprotein = seq(from = min(oto2$Plasmaprotein), to =max(oto2$Plasmaprotein), length = 100), Condition = 0, Age = 0, Opacity = mean(oto2$Opacity), Growthrate = 0, Otolithgrowthrate = 0 ) oto3 &lt;- bind_rows(oto2, newdata) %&gt;% select(-Date, -date_num) それでは、実際にモデルを回して予測値と95%確信区間を得る。 m9_2 &lt;- inla(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca + f(Fish, model = &quot;iid&quot;), control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975)), control.compute = list(dic = TRUE), data = oto3) 以下に結果を図示する。事後平均を用いた平均の予測値と、その95%確信区間である。 fit9_2 &lt;- m9_2$summary.fitted.values[210:309,] %&gt;% bind_cols(newdata) %&gt;% ## 血漿中タンパク質は元のスケールに戻す mutate(Plasmaprotein = Plasmaprotein*sd(oto2$Plasmaprotein) + mean(oto2$Plasmaprotein)) fit9_2 %&gt;% ggplot(aes(x = Plasmaprotein))+ geom_line(aes(y = mean))+ geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), alpha = 0.3)+ geom_point(data = oto2, aes(y = O.Sr.Ca), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1) 8.8.2 Option 2 for prediction: Using the inla.make.lincombs 続いて、もう一つの方法を解説する。ここでは、inla.make.limcombsを使用する。先ほどと全く同じではないが似た結果が得られる。 まず、1つ目の方法と同様に予測値が欲しい範囲の変数を格納したデータフレームを作る。ただし、このときランダム効果と応答変数は含めなくていい。 newdata2 &lt;- data.frame(Sex = factor(&quot;F&quot;, levels = c(&quot;F&quot;, &quot;M&quot;)), Origin = factor(&quot;EC&quot;, levels = c(&quot;EC&quot;, &quot;IS&quot;)), GnRH = factor(&quot;Non-treated&quot;, levels = c(&quot;Non-treated&quot;,&quot;Treated&quot;)), Temp = 0, Sal = 0, SW.Sr.Ca = 0, B.Sr = 0, Plasmaprotein = seq(from = min(oto2$Plasmaprotein), to =max(oto2$Plasmaprotein), length = 100), Condition = 0, Age = 0, Opacity = mean(oto2$Opacity), Growthrate = 0, Otolithgrowthrate = 0 ) 次に、これらを切片を含むマトリックスにする。 Xmat &lt;- model.matrix(~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca, data = newdata2) 最後にこれをデータフレームにする。 Xmat &lt;- as.data.frame(Xmat) それでは、inlaでモデルを実行する。このとき、あらかじめXmatを変換する必要がある。その後、inlaでlimcomb =(linear combinationの意)で作成したオブジェクトを指定する。 lcb &lt;- inla.make.lincombs(Xmat) m9_3 &lt;- inla(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca + f(Fish, model = &quot;iid&quot;), lincomb = lcb, family = &quot;gaussian&quot;, control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975)), data = oto2) m9_3$summary.lincomb.derivedに予測値と確信区間が格納されているので、これをnewdata2と結合する。 fit9_3 &lt;- m9_3$summary.lincomb.derived %&gt;% bind_cols(newdata2) %&gt;% mutate(Plasmaprotein = Plasmaprotein*sd(oto2$Plasmaprotein) + mean(oto2$Plasmaprotein)) 最後にこれを図示する。 fit9_3 %&gt;% ggplot(aes(x = Plasmaprotein))+ geom_line(aes(y = mean))+ geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), alpha = 0.3)+ geom_point(data = oto2, aes(y = O.Sr.Ca), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1) 8.9 Multiple random effects INLAでも2つ以上のランダム切片を追加することはできる。 8.10 Changin prior of fixed parameters 本稿では、ここまで事前分布にINLAのデフォルトを使用してきた。しかし、今回のように1湯のランダム切片しか持たないときは問題ないが、ランダム効果を2つ以上持つ場合や、それらに時空間的相関を仮定するときには、事前分布の影響を確認した方がよい。 INLAでは固定効果のパラメータのデフォルトの事前分布は平均0で精度$\\(0.001の正規分布になっている。\\)\\(を\\)\\(に直すと、\\)= 31.62$である。 \\[ \\beta_i \\sim N(0, 31.6^2) \\] 正規分布では\\(±3 \\times \\sigma\\)の範囲に99%の値が入るので、この事前分布はパラメータがおよそ-95.8から94.8の値をとることを贈呈していることになる。これは十分に広い。なお、切片のパラメータの精度は0にされている。 以下では、事前分布を変えたときに結果がどのように変化するかを見ていく。話を単純にするため、先ほどの結果で影響があった4つの変数のみをモデルに含める。また、変数変換は行わないものとする。 まず、デフォルトの事前分布でモデリングを行う。 m9_4a &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;), family = &quot;gaussian&quot;, data = oto) 得られたハイパーパラメータ以外の事後分布の要約統計量は以下の通り。 m9_4a$summary.fixed %&gt;% select(1,2,3,5) それでは、次に情報事前分布を用いてモデルを回す。ここでは、例えば先行研究などの結果からPlasmaproteinの回帰係数\\(\\beta_{Plasma}\\)が以下の事前分布を持つとする。 \\[ \\beta_{Plasma} \\sim N(-0.22, 0.01^2) \\] \\(\\sigma = 0.01\\)のとき\\(\\tau = 10000\\)である。一方で、その他のパラメータはデフォルトと同様に平均0で精度0.001の無情報事前分布を事前分布に定める。また、切片のパラメータの事前分布もデフォルトと同様である。inlaでは、control.fixedオプションで事前分布を指定できる。 m9_4b &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;), control.fixed = list(mean = list(Plasmaprotein = -0.22, Temp = 0, Sal = 0, B.Sr = 0), prec = list(Temp = 0.001, Sal = 0.001, B.Sr = 0.001, Plasmaprotein = 10000), mean.intercept = 0, prec.intercept = 0), data = oto) 血漿中タンパクの回帰係数の推定値がかなり変わっている。 結果が明らかにおかしい。何らかのバグ？おそらく事前分布の平均が反映されていない。 m9_4b$summary.fixed %&gt;% select(1,2,3,5) 8.11 Changing priors of hyperparameters 先ほどのモデルにはハイパーパラメータが2つあった(\\(\\sigma\\)と\\(\\sigma_{Fish}\\))。しかし、INLAでは精度(\\(\\tau = 1/\\sigma^2, \\tau_{Fish} = 1/\\sigma_{Fish}^2\\)が推定される。これらのデフォルトの事前分布は以下の通り。これは、\\(\\tau\\)と\\(\\tau_{Fish}\\))がガンマ分布を事前分布に持つのと同じことである。 \\[ \\begin{aligned} &amp;log(\\tau) \\sim LogGamma(1, 0.00005)\\\\ &amp;log(\\tau_{Fish}) \\sim LogGamma(1, 0.00005)\\\\ \\end{aligned} \\] ガンマ分布は2つのパラメータshapeとscaleを持っており、それぞれ\\(a\\)とと\\(b\\)で示されることが多い。ただし、INLAでは\\(b\\)をscaleパラメータの逆数に用いているためややこしい。以下では、INLAと同様にscaleパラメータの逆数(rateパラメータという)を\\(b\\)で示す。このとき、ガンマ分布の平均は\\(a/b\\)で分散は\\(a/b^2\\)となる。 INLAでは、\\(\\tau\\)と\\(\\tau_{Fish}\\)の事前分布に\\(Gamma(a = 1, b = 0.00001)\\)を設定している。これは、ほぼ一様分布のようになる(図8.4のA)。一方で、 Carroll et al. (2015) は、INLAではポワソンGLMMのときには\\(Gamma(1, 0.5)\\)の方がデフォルトよりもうまく分析できることを示している。この時のガンマ分布は図8.4のBのようになる。 x &lt;- seq(0, 20, length = 1000) data.frame(x = x, y = dgamma(x, shape =1, rate = 0.00001)) %&gt;% ggplot()+ geom_line(aes(x = x, y = y))+ coord_cartesian(ylim = c(0,0.00001))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;A: shape =, rate = 0.00001&quot;)-&gt; p1 data.frame(x = x, y = dgamma(x, shape =1, rate = 0.5)) %&gt;% ggplot()+ geom_line(aes(x = x, y = y))+ coord_cartesian(ylim = c(0,0.5))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;B: shape = 1, rate = 0.5&quot;)-&gt; p2 p1 + p2 図8.4: Gamma distribution with shape = 1 and rate = 0.00001. では、\\(\\tau\\)が\\(Gamma(1,0.5)\\)に従うとき、\\(\\sigma\\)はどのような値をとるだろうか。シミュレーションによってこの分布から\\(\\tau\\)をランダムに抽出したときの\\(\\sigma\\)の値の分布を示したのが図8.5である。ここから、この事前分布では\\(\\sigma\\)はおおよそ0から5までの間の値をとることが多いことが分かる。 set.seed(123) tau &lt;- rgamma(n = 1000, shape = 1, rate = 0.5) data.frame(sigma = 1/sqrt(tau)) %&gt;% ggplot(aes(x = sigma))+ geom_histogram(binwidth = 1, alpha = 0, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1) 図8.5: 1000 simulated values of sigmas when sampling tau from Gamma(1, 0.5) ただし、 Carroll et al. (2015) はポワソン分布の場合の話であり、リンク関数にログ関数を用いていることは注意が必要である。私たちが現在使っているのは正規分布のモデルでリンク関数は恒等関数である。 さて、それではハイパーパラメータの事前分布を変えたときに結果がどのように変わるかを見てみる。\\(\\sigma\\)の事前分布はcontrol.familyオプションで、\\(\\sigma_{Fish}\\)の事前分布は式のf(Fish, model = \"iid\", ...)の中で指定できる。まずは、デフォルト(\\(\\sigma, \\sigma_{Fish} \\sim Gamma(1,0.00001)\\)のモデルを回す。 m9_5a &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;), data = oto) 続いて、事前分布に\\(\\sigma, \\sigma_{Fish} \\sim Gamma(1,0.5)\\)を用いてみる。 m9_5b &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;, hyper = list(prec = list(prior = &quot;loggamma&quot;, param = c(1,0.5)))), control.family = list(hyper = list(prec = list( prior = &quot;loggamma&quot;, param = c(1, 0.5)))), data = oto) 固定効果の推定値や95%確信区間などはほとんど変わらなかった。 m9_5a$summary.fixed %&gt;% select(1,2,3,5) %&gt;% mutate(model = &quot;m9_5a&quot;) %&gt;% rownames_to_column(var = &quot;Parameter&quot;) %&gt;% bind_rows(m9_5b$summary.fixed %&gt;% select(1,2,3,5) %&gt;% mutate(model = &quot;m9_5b&quot;) %&gt;% rownames_to_column(var = &quot;Parameter&quot;)) 一方で、推定されたハイパーパラメータの事後分布を示すと、特に\\(\\sigma_{Fish}\\)はかなり違うことが分かる。 tau5a &lt;- m9_5a$marginals.hyperpar$`Precision for the Gaussian observations` tau5b &lt;- m9_5b$marginals.hyperpar$`Precision for the Gaussian observations` tau_fish5a &lt;- m9_5a$marginals.hyperpar$`Precision for Fish` tau_fish5b &lt;- m9_5b$marginals.hyperpar$`Precision for Fish` ## sigmaにする myfun &lt;- function(x) 1/sqrt(x) sigma5a &lt;- inla.tmarginal(myfun, tau5a) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5a&quot;) sigma5b &lt;- inla.tmarginal(myfun, tau5b) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5b&quot;) sigma_fish5a &lt;- inla.tmarginal(myfun, tau_fish5a) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5a&quot;) sigma_fish5b &lt;- inla.tmarginal(myfun, tau_fish5b) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5b&quot;) ## 図示 sigma5a %&gt;% bind_rows(sigma5b) %&gt;% ggplot(aes(x = x, y = y))+ geom_line(aes(color = model))+ scale_color_manual(values = c(&quot;red&quot;,&quot;blue&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ guides(color = &quot;none&quot;)+ labs(x = expression(sigma), y = expression(paste(&quot;Pr(&quot;, sigma, &quot;|D)&quot;))) -&gt; p1 sigma_fish5a %&gt;% bind_rows(sigma_fish5b) %&gt;% ggplot(aes(x = x, y = y))+ geom_line(aes(color = model))+ scale_color_manual(values = c(&quot;red&quot;,&quot;blue&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(sigma[Fish]), y = expression(paste(&quot;Pr(&quot;, sigma[Fish], &quot;|D)&quot;)))-&gt; p2 p1 + p2 References "],["Chapter10.html", "9 Poisson, negative binomial, binomial and g amma GLMs in R-INLA 9.1 Poisson and negative binomial GLMs in R-INLA 9.2 Bernoulli and binomial GLM 9.3 Gamma GLM", " 9 Poisson, negative binomial, binomial and g amma GLMs in R-INLA 本章では、ポワソン分布、負の二項分布、二項分布、そしてガンマ分布の一般化線形モデル(GLM: generalized linea model)をINLAで行う方法を学ぶ。 9.1 Poisson and negative binomial GLMs in R-INLA 9.1.1 Introduction 本節では、ブラジルに生息するトラギスという魚の体表にいる寄生虫の数を分析した Timi et al. (2008) の研究データを用いる。魚のサンプルはアルゼンチンの3つの海域で採集された(Location)。また、性別(SEX)、体長(LT)、重さ(Weight)、矢状長(LS)が測定されている。LocationとSexは因子型に変換しておく。 sp &lt;- read_delim(&quot;data/Turcoparasitos.txt&quot;) %&gt;% mutate(fSex = as.factor(SEX), fLoc = as.factor(Location)) datatable(sp, options = list(scrollX = 20), filter = &quot;top&quot;) 9.1.2 Data exploration まずはデータの確認を行う。変数のdotplotを見たところ、そこまで極端な外れ値はないよう。 sp %&gt;% mutate(n = 1:n()) %&gt;% pivot_longer(2:7) %&gt;% ggplot(aes(x = value, y = n))+ geom_point()+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ labs(y = &quot;Sample number&quot;) 続いて、変数間の関係を確認してみる。体重と体長、矢状長はかなり強く相関しており、これらを同じモデルで使うのは望ましくない。本節では、体長のみを用いる。 sp %&gt;% select(2:7) %&gt;% ggpairs() 図9.1は海域(Location)ごとに体長と寄生虫の数の関連をプロットしたものである。曲線はポワソン分布のGLMを当てはめたものである。明らかに海域によって傾向が違うことが分かる。つまり、モデルには体長と海域の交互作用を入れる必要がある。 sp %&gt;% ggplot(aes(x = LT, y = Totalparasites))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~Location)+ geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;poisson&quot;)) 図9.1: Scatterplot of total number of parasites per fish plotted versus length of the fish. Each pane l corresponds to a location. 性別でも見てみたが、こちらはそこまで明確ではない(図9.2)。よって、性別については交互作用を考慮しないこととする。 sp %&gt;% ggplot(aes(x = LT, y = Totalparasites))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ SEX)+ geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;poisson&quot;)) 図9.2: Scatterplot of total number of parasites per fish plotted versus length of the fish. Each pane l corresponds to sex. 9.1.3 Poisson GLM an R-INLA 以上から、以下のモデルを考える。\\(TP_i\\)は寄生虫の数である。なお、回帰係数は省いている。 \\[ \\begin{aligned} &amp;TP_i \\sim Poisson(\\mu_i) \\\\ &amp;E(TP_i) = \\mu_i \\; and \\; var(TP_i) = \\mu_i\\\\ &amp;log(\\mu_i) = Intercept + Sex_i + LT_i + Location_i + LT_i \\times Location_i \\end{aligned} \\] INLAでは以下のように実行できる。 m10_1 &lt;- inla(Totalparasites ~ fSex + LT*fLoc, family = &quot;poisson&quot;, control.compute = list(dic = TRUE), data = sp) 結果は以下の通り。 summary(m10_1) ## ## Call: ## c(&quot;inla.core(formula = formula, family = family, contrasts = contrasts, ## &quot;, &quot; data = data, quantiles = quantiles, E = E, offset = offset, &quot;, &quot; ## scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, ## &quot;, &quot; lp.scale = lp.scale, link.covariates = link.covariates, verbose = ## verbose, &quot;, &quot; lincomb = lincomb, selection = selection, control.compute ## = control.compute, &quot;, &quot; control.predictor = control.predictor, ## control.family = control.family, &quot;, &quot; control.inla = control.inla, ## control.fixed = control.fixed, &quot;, &quot; control.mode = control.mode, ## control.expert = control.expert, &quot;, &quot; control.hazard = control.hazard, ## control.lincomb = control.lincomb, &quot;, &quot; control.update = ## control.update, control.lp.scale = control.lp.scale, &quot;, &quot; ## control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, ## &quot;, &quot; inla.call = inla.call, inla.arg = inla.arg, num.threads = ## num.threads, &quot;, &quot; blas.num.threads = blas.num.threads, keep = keep, ## working.directory = working.directory, &quot;, &quot; silent = silent, inla.mode ## = inla.mode, safe = FALSE, debug = debug, &quot;, &quot; .parent.frame = ## .parent.frame)&quot;) ## Time used: ## Pre = 0.732, Running = 0.471, Post = 0.0719, Total = 1.27 ## Fixed effects: ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## (Intercept) 0.171 0.202 -0.224 0.171 0.567 0.171 0 ## fSex2 0.008 0.036 -0.063 0.008 0.079 0.008 0 ## LT 0.119 0.006 0.107 0.119 0.131 0.119 0 ## fLoc2 2.977 0.462 2.071 2.977 3.883 2.977 0 ## fLoc3 0.892 0.484 -0.057 0.892 1.840 0.892 0 ## LT:fLoc2 -0.146 0.014 -0.173 -0.146 -0.118 -0.146 0 ## LT:fLoc3 -0.071 0.013 -0.096 -0.071 -0.045 -0.071 0 ## ## Deviance Information Criterion (DIC) ...............: 2752.51 ## Deviance Information Criterion (DIC, saturated) ....: 2057.57 ## Effective number of parameters .....................: -128.12 ## ## Marginal log-Likelihood: -1552.05 ## is computed ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also &#39;control.compute=list(return.marginals.predictor=TRUE)&#39;) この結果から、\\(log(\\mu_i)\\)は以下のように書ける。 \\[ \\begin{aligned} log(\\mu_i) = \\begin{cases} 0.171 + 0.119 \\times LT_i \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\rm{for \\; location = 1, Sex = 1}\\\\ 0.171 + 2.977 + (0.119 - 0.146) \\times LT_i \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\rm{for \\; location = 2, Sex = 1}\\\\ 0.171 + 0.892 + (0.119 - 0.071) \\times LT_i \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\rm{for \\; location = 3, Sex = 1}\\\\ 0.171 + 0.008 + 0.119 \\times LT_i \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\rm{for \\; location = 1, Sex = 2}\\\\ 0.171 + 0.008 + 2.977 + (0.119 - 0.146) \\times LT_i \\;\\;\\;\\; \\rm{for \\; location = 2, Sex = 2}\\\\ 0.171 + 0.008 + 0.892 + (0.119 - 0.071) \\times LT_i \\;\\;\\;\\; \\rm{for \\; location = 3, Sex = 2} \\end{cases} \\end{aligned} \\] 9.1.3.1 Checking overdispersion 9.1.3.1.1 Calculating dispersion parameter モデル選択やモデルの解釈に移る前に、まずはこのデータに対してポワソン分布が適切かを確認する。過分散の有無を確認するため、分散パラメータを算出する。分散パラメータ\\(\\phi\\)は以下のように計算できる。なお、\\(N\\)はサンプル数、\\(k\\)はパラメータ数である。もし\\(\\phi\\)が1を超えていれば過分散が生じており、1以下であれば過少分散である。通常、\\(\\phi = 1.5\\)くらいまでであれば問題ないと判断される(健太郎 2010)。 \\[ \\begin{aligned} &amp;E_i = \\frac{TP_i - E(TP_i)}{\\sqrt{var(TP_i)}}\\\\ &amp;\\phi = \\frac{\\sum_{i=1}^k E_i^2}{N - k} \\end{aligned} \\] Rでは以下のように算出できる。分散パラメータは18.19であり、明らかに過分散が生じている。 mu &lt;- m10_1$summary.fitted.values$mean E &lt;- (sp$Totalparasites - mu)/sqrt(mu) N &lt;- nrow(sp) p &lt;- nrow(m10_1$summary.fixed) phi &lt;- sum(E^2)/(N-p) phi ## [1] 18.18584 9.1.3.1.2 Bayesian method for looking for over/under-dispersion ただし、ベイズモデリングの場合、事前分布が無情報ではない場合には分散パラメータがそのまま解釈できない可能性がある。そこで、ベイズモデリングでは異なる方法で確認を行う。 MCMCの場合には、各MCMCサンプルごとにデータをシミュレートして実データと比べることで過分散の検討を行える(Zuur and Ieno 2016)。INLAではMCMCをしていないので、事後分布から新たなデータをシミュレートし、これを実測値と比較することで過分散がないかを確認する。具体的には、以下の手順を行う。 INLAでGLMを実行する。 事後分布から1セットの回帰係数\\(\\beta_1, \\dots, \\beta_7\\)をサンプリングする。 サンプリングしたパラメータを用いて期待値\\(\\bf{\\mu} = exp(\\bf{X} \\times \\bf{\\beta})\\)を算出する。 計算した期待値からrpois関数を用いてデータをシミュレートする。 シミュレートしたデータセットのピアソン残差(\\(E_i\\))を算出し、その平方和(\\(\\sum_i^N E_i^2\\))を計算する。 2から5を1000回繰り返す。 シミュレートしたデータセットのピアソン残差の平方和と実測値のピアソン残差の平方和を比較する。 シミュレートしたデータセットのピアソン残差の平方和の分布は、もしモデルが正しいときにそれに従うデータセットが持つピアソン残差の平方和の分布である。もし過分散/過少分散が生じているのであれば、実際のデータセットのピアソン残差の平方和がこの分布から外れた値をとるはずである。 それでは、実際に行ってみよう。事後分布からパラメータのサンプリングを行うには、control.computeオプションでconfig = TRUEとする必要がある。 m10_2 &lt;- inla(Totalparasites ~ fSex + LT*fLoc, family = &quot;poisson&quot;, control.compute = list(dic = TRUE, config = TRUE), data = sp) それでは、パラメータの事後同時分布から1000セットのパラメータをサンプリングする(第7.5.5.2節を参照)。 sim_param &lt;- inla.posterior.sample(n = 1000, m10_2) 例えば1セット目にサンプリングされた値は以下の通り。なお、ここでは既にサンプリングしたパラメータを用いた期待値\\(\\bf{\\mu} = exp(\\bf{X} \\times \\bf{\\beta})\\)も算出されている(最初の155行)。最後の7行はサンプリングされたパラメータの値である。 sim_param[[1]]$latent %&gt;% data.frame() %&gt;% rename(mu = 1) %&gt;% datatable() それでは、抽出した1000セットのパラメータを用いて1000個のデータセットをシミュレートする。 y_sim &lt;- matrix(nrow = nrow(sp), ncol = 1000) for(i in 1:1000){ y_sim[,i] &lt;- rpois(n = nrow(sp), lambda = exp(sim_param[[i]]$latent[1:nrow(sp),])) } 続いて、それぞれのデータセットについてピアソン残差の平方和を算出する。 sum_E2_sim &lt;- vector() for(i in 1:1000){ E &lt;- (y_sim[,i] - mu)/sqrt(mu) sum_E2_sim[i] &lt;- sum(E^2) } さて、実際に得られた実測値のピアソン残差の平方和は以下の通り、2691.504であった。 E &lt;-(sp$Totalparasites - mu)/sqrt(mu) sum_E2 &lt;- sum(E^2) sum_E2 ## [1] 2691.504 これをシミュレートしたデータセットのピアソン残差の平方和と比べると、そのすべてよりも大きいことが分かった。すなわち、実データはデータが想定するよりも非常に大きなばらつきがあるといえる(= 過分散が生じている)。 mean(sum_E2 &gt; sum_E2_sim) ## [1] 1 これは、シミュレートしたでーらセットにおけるピアソン残差の平方和の分布をみても明らかである。モデルに従うのであれば、ピアソン残差の平方和はせいぜい100から300くらいの値しか取らない。 data.frame(x = sum_E2_sim) %&gt;% ggplot(aes(x = x)) + geom_histogram(binwidth = 5) + theme_bw()+ theme(aspect.ratio = 0.8) 図9.3: シミュレートされたデータのピアソン残差の平方和の分布 過分散はデータのばらつきがポワソン分布が仮定するよりも大きすぎるときのほかに、外れ値の影響や共変量を入れていないこと、交互作用がないことやリンク関数が間違っていること、非線形のパターンがあることやゼロ過剰、データの非独立性などが原因でも起きる。データをしっかりとみて原因に合った解決をしなくてはならない。 今回はゼロ過剰や外れ値の影響はなさそうである。また、予測値とピアソン残差の関係を見ても、明確にパターンがあるわけではなさそう。また、ピアソン残差と共変量の間にパターンもなく、応答変数と説明変数の間に非線形な関係があるというわけでもなさそう。 data.frame(resid = (sp$Totalparasites - mu)/sqrt(mu), fitted = m10_2$summary.fitted.values$mean) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point()+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Pearson residuals&quot;)-&gt; p1 data.frame(resid = (sp$Totalparasites - mu)/sqrt(mu), LT = sp$LT) %&gt;% ggplot(aes(x = LT, y = resid))+ geom_point()+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;LT&quot;, y = &quot;Pearson residuals&quot;)-&gt; p2 data.frame(resid = (sp$Totalparasites - mu)/sqrt(mu), Loc = sp$fLoc, Sex = sp$fSex) %&gt;% pivot_longer(2:3) %&gt;% ggplot(aes(x = value, y = resid))+ geom_boxplot()+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;&quot;, y = &quot;Pearson residuals&quot;)-&gt; p3 (p1 + p2)/p3 そこで、本節では以下で負の二項分布を適用したモデリングを行う。 9.1.4 Negative binomial GLM in R-INLA モデル式は以下のとおりである。\\(k\\)は負の二項分布の分散パラメータで、分布の分散を調整する。INLAではsizeパラメータと呼ばれる。 \\[ \\begin{aligned} &amp;TP_i \\sim NegBinomial(\\mu_i, k) \\\\ &amp;E(TP_i) = \\mu_i \\; and \\; var(TP_i) = \\mu_i + \\frac{\\mu_i^2}{k}\\\\ &amp;log(\\mu_i) = Intercept + Sex_i + LT_i + Location_i + LT_i \\times Location_i \\end{aligned} \\] INLAでは以下のように実行する。 m10_3 &lt;- inla(Totalparasites ~ fSex + LT*fLoc, family = &quot;nbinomial&quot;, control.compute = list(dic = TRUE, config = TRUE), data = sp) 結果は以下の通り。ポワソンモデルのときと比べて、確信区間が全て広くなっている。 summary(m10_3) ## ## Call: ## c(&quot;inla.core(formula = formula, family = family, contrasts = contrasts, ## &quot;, &quot; data = data, quantiles = quantiles, E = E, offset = offset, &quot;, &quot; ## scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, ## &quot;, &quot; lp.scale = lp.scale, link.covariates = link.covariates, verbose = ## verbose, &quot;, &quot; lincomb = lincomb, selection = selection, control.compute ## = control.compute, &quot;, &quot; control.predictor = control.predictor, ## control.family = control.family, &quot;, &quot; control.inla = control.inla, ## control.fixed = control.fixed, &quot;, &quot; control.mode = control.mode, ## control.expert = control.expert, &quot;, &quot; control.hazard = control.hazard, ## control.lincomb = control.lincomb, &quot;, &quot; control.update = ## control.update, control.lp.scale = control.lp.scale, &quot;, &quot; ## control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, ## &quot;, &quot; inla.call = inla.call, inla.arg = inla.arg, num.threads = ## num.threads, &quot;, &quot; blas.num.threads = blas.num.threads, keep = keep, ## working.directory = working.directory, &quot;, &quot; silent = silent, inla.mode ## = inla.mode, safe = FALSE, debug = debug, &quot;, &quot; .parent.frame = ## .parent.frame)&quot;) ## Time used: ## Pre = 0.658, Running = 0.168, Post = 0.109, Total = 0.935 ## Fixed effects: ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## (Intercept) -1.005 1.452 -3.857 -1.005 1.847 -1.005 0 ## fSex2 0.010 0.159 -0.303 0.010 0.323 0.010 0 ## LT 0.153 0.044 0.066 0.153 0.240 0.153 0 ## fLoc2 4.392 1.910 0.644 4.392 8.144 4.391 0 ## fLoc3 1.812 2.126 -2.363 1.812 5.989 1.812 0 ## LT:fLoc2 -0.188 0.058 -0.301 -0.188 -0.075 -0.188 0 ## LT:fLoc3 -0.099 0.060 -0.217 -0.099 0.019 -0.099 0 ## ## Model hyperparameters: ## mean sd 0.025quant ## size for the nbinomial observations (1/overdispersion) 1.56 0.186 1.22 ## 0.5quant 0.975quant mode ## size for the nbinomial observations (1/overdispersion) 1.55 1.95 1.53 ## ## Deviance Information Criterion (DIC) ...............: 1276.63 ## Deviance Information Criterion (DIC, saturated) ....: 185.45 ## Effective number of parameters .....................: 8.00 ## ## Marginal log-Likelihood: -673.93 ## is computed ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also &#39;control.compute=list(return.marginals.predictor=TRUE)&#39;) INLAではsizeパラメータ\\(k\\)の事前分布は、\\(\\theta = log(k)\\)の事前分布が\\(logGamma(1,0.1)\\)になるようになっている。\\(k\\)の事後平均値は1.56であった。事後分布は以下の通り。 m10_3$marginals.hyperpar$`size for the nbinomial observations (1/overdispersion)` %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(k), y = expression(paste(&quot;Pr(&quot;,k,&quot;|D)&quot;))) もし\\(k\\)の値を固定したいときは以下のようにすればよい。モデル選択をする際など\\(k\\)の値が変わると困る場合に用いればよい。 hyp.nb &lt;- list(size = list(initial = 1, fixed = TRUE)) m10_4 &lt;- inla(Totalparasites ~ fSex + LT*fLoc, family = &quot;nbinomial&quot;, control.compute = list(dic = TRUE, config = TRUE), control.family = list(hyper = hyp.nb), data = sp) 以下では、ポワソン分布のときと同じように過分散のチェックを行う。確認の結果、シミュレーションによって得られたポワソン残差の平方和の分布と実際のポワソン残差の平方和を示したのが図9.4である。実際の平方和はシミュレーションの値の87%より大きいが、ポワソン分布に比べると過分散がかなり改善していることが分かった。 sim_param.nb &lt;- inla.posterior.sample(n = 1000, m10_3) y_sim.nb &lt;- matrix(nrow = nrow(sp), ncol = 1000) for(i in 1:1000){ y_sim.nb[,i] &lt;- rnbinom(n = nrow(sp), mu = exp(sim_param[[i]]$latent[1:nrow(sp),]), size = sim_param.nb[[i]]$hyperpar[[1]]) } ### シミュレートしたデータセットのピアソン残差の平方和 sum_E2_sim.nb &lt;- vector() mu &lt;- m10_3$summary.fitted.values$mean k &lt;- m10_3$summary.hyperpar$mean for(i in 1:1000){ E &lt;- (y_sim.nb[,i] - mu)/sqrt(mu + mu^2/k) sum_E2_sim.nb[i] &lt;- sum(E^2) } ### 実データのピアソン残差の平方和 E &lt;-(sp$Totalparasites - mu)/sqrt(mu + mu^2/k) sum_E2.nb &lt;- sum(E^2) ### 比較 p &lt;- mean(sum_E2.nb &gt; sum_E2_sim.nb) data.frame(x = sum_E2_sim.nb) %&gt;% ggplot(aes(x = x)) + geom_histogram(binwidth = 5) + theme_bw()+ theme(aspect.ratio = 0.8) + geom_vline(xintercept = sum_E2.nb, color = &quot;red2&quot;)+ geom_text(aes(x = 210, y = 60), label = str_c(&quot;p = &quot;, p)) 図9.4: シミュレートされたデータのピアソン残差の平方和の分布の実データのピアソン残差の平方和 9.1.5 Model selection for the NB GLM モデル選択は議論の多い話題ではあるが、以下ではひとまずDICとWAICによるモデル選択を行う。なお、比較のため\\(k\\)は先ほどのモデルで得られた値に固定する。ひとまず、1つずつ説明変数をなくした場合と比較を行う。 hyper.nb &lt;- list(size = list(initial = k, fixed = TRUE)) ## フルモデル m10_5 &lt;- inla(Totalparasites ~ fSex + LT*fLoc, family = &quot;nbinomial&quot;, control.compute = list(dic = TRUE, waic = TRUE, config = TRUE), control.family = list(hyper = hyp.nb), data = sp) ## fSexなし m10_5a &lt;- inla(Totalparasites ~ LT*fLoc, family = &quot;nbinomial&quot;, control.compute = list(dic = TRUE, waic = TRUE, config = TRUE), control.family = list(hyper = hyp.nb), data = sp) ## 交互作用項なし m10_5b &lt;- inla(Totalparasites ~ fSex + LT + fLoc, family = &quot;nbinomial&quot;, control.compute = list(dic = TRUE, waic = TRUE, config = TRUE), control.family = list(hyper = hyp.nb), data = sp) まずこれらの3つのモデルでDICとWAICを比較したところ、fSexがないモデルがどちらも最も低いことが分かった。 dic10_5 &lt;- c(m10_5$dic$dic, m10_5a$dic$dic, m10_5b$dic$dic) waic10_5 &lt;- c(m10_5$waic$waic, m10_5a$waic$waic, m10_5b$waic$waic) data.frame(&quot;type&quot; = c(&quot;Full&quot;, &quot;-fSex&quot;, &quot;-LT × fLoc&quot;), DIC = dic10_5, WAIC = waic10_5) %&gt;% column_as_rownames(var = &quot;type&quot;) 最後に、ここから交互作用を除いたモデルと比較を行う。 m10_5c &lt;- inla(Totalparasites ~ LT + fLoc, family = &quot;nbinomial&quot;, control.compute = list(dic = TRUE, waic = TRUE, config = TRUE), control.family = list(hyper = hyp.nb), data = sp) その結果、やはり交互作用を含むモデルの方がDICとWAICは低い。 dic10_5.2 &lt;- c(m10_5a$dic$dic, m10_5c$dic$dic) waic10_5.2 &lt;- c(m10_5a$waic$waic, m10_5c$waic$waic) data.frame(&quot;type&quot; = c(&quot;Full&quot;, &quot;-LT × fLoc&quot;), DIC = dic10_5.2, WAIC = waic10_5.2) %&gt;% column_as_rownames(var = &quot;type&quot;) 以上の結果は、m10_5aが最適なモデルであることを示唆している。このモデルの残差と予測値、残差と共変量の関連を示したのが図@ref(fig:modelvalidation10.5a)である。パターンがあるように見えるが、 Zuur (2017) は問題がなかったと述べている。 mu &lt;- m10_5a$summary.fitted.values$mean k &lt;- k resid &lt;- (sp$Totalparasites - mu)/sqrt(mu + mu^2/k) data.frame(resid = resid, fitted = mu) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point()+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Pearson residuals&quot;)-&gt; p1 data.frame(resid = resid, LT = sp$LT) %&gt;% ggplot(aes(x = LT, y = resid))+ geom_point()+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;LT&quot;, y = &quot;Pearson residuals&quot;)-&gt; p2 data.frame(resid = resid, Loc = sp$fLoc, Sex = sp$fSex) %&gt;% pivot_longer(2:3) %&gt;% ggplot(aes(x = value, y = resid))+ geom_boxplot()+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;&quot;, y = &quot;Pearson residuals&quot;)-&gt; p3 (p1 + p2)/p3 (#fig:modelvalidation10.5a)Model validation for m10_5a これまで同様に過分散のチェックも行ったが、大きな問題はないよう。 sim_param.nb &lt;- inla.posterior.sample(n = 1000, m10_5a) y_sim.nb &lt;- matrix(nrow = nrow(sp), ncol = 1000) for(i in 1:1000){ y_sim.nb[,i] &lt;- rnbinom(n = nrow(sp), mu = exp(sim_param[[i]]$latent[1:nrow(sp),]), size = k) } ### シミュレートしたデータセットのピアソン残差の平方和 sum_E2_sim.nb &lt;- vector() mu &lt;- m10_5a$summary.fitted.values$mean k &lt;- k for(i in 1:1000){ E &lt;- (y_sim.nb[,i] - mu)/sqrt(mu + mu^2/k) sum_E2_sim.nb[i] &lt;- sum(E^2) } ### 実データのピアソン残差の平方和 E &lt;-(sp$Totalparasites - mu)/sqrt(mu + mu^2/k) sum_E2.nb &lt;- sum(E^2) ### 比較 p &lt;- mean(sum_E2.nb &gt; sum_E2_sim.nb) data.frame(x = sum_E2_sim.nb) %&gt;% ggplot(aes(x = x)) + geom_histogram(binwidth = 5) + theme_bw()+ theme(aspect.ratio = 0.8) + geom_vline(xintercept = sum_E2.nb, color = &quot;red2&quot;)+ geom_text(aes(x = 210, y = 60), label = str_c(&quot;p = &quot;, p)) 図9.5: シミュレートされたデータのピアソン残差の平方和の分布の実データのピアソン残差の平方和 9.1.6 Visualization of the NB GLM 以下では、結果の可視化を行う。なお、ここでは前章(8.8.2)で用いたinla.make.lincomsを用いる方法で実行する。 まずは予測値が欲しい範囲の変数を格納したデータフレームを作る。 newdata &lt;- crossing(LT = seq(min(sp$LT), max(sp$LT),length =100), fLoc = c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;)) X &lt;- model.matrix(~ LT*fLoc, data = newdata) %&gt;% as.data.frame() 次に、lincombsオプションでlcbを指定してモデルを実行する。 lcb &lt;- inla.make.lincombs(X) m10_6 &lt;- inla(Totalparasites ~ LT*fLoc, family = &quot;nbinomial&quot;, lincomb = lcb, control.predictor = list(compute = TRUE), control.compute = list(return.marginals.predictor = TRUE), control.family = list(hyper = hyper.nb), data = sp) 注意しなければならないのは、m10_6$summary.lincomb.derivedなどは線形予測子、つまり\\(log(\\mu_i)\\)の事後分布についての情報を返してくるということだ。私たちは\\(\\mu_i\\)の予測値が欲しいので、これを変換する必要がある。 m10_6$summary.lincomb.derived %&gt;% head(10) 以下のようにして変換して事後分布の要約統計量を算出する。 ## 線形予測子の事後周辺分布 post_pred10_6 &lt;- m10_6$marginals.lincomb.derived ## 変換を行って要約統計量を計算 ## 95%確信区間 ci.10_6 &lt;- map_df(post_pred10_6, ~inla.qmarginal(c(0.025, 0.975), inla.tmarginal(exp,.))) %&gt;% t() %&gt;% as.data.frame() %&gt;% rename(lower = 1, upper = 2) ## 事後平均値 mean.10_6 &lt;- map_df(post_pred10_6, ~inla.emarginal(exp,.)) %&gt;% t() %&gt;% as.data.frame() %&gt;% rename(fitted = 1) 結果を図示したのが以下の図である。 ## 作図 bind_cols(newdata, ci.10_6, mean.10_6) %&gt;% mutate(fLoc = str_c(&quot;Location = &quot;, fLoc)) %&gt;% ggplot(aes(x = LT, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2)+ geom_point(data = sp %&gt;% mutate(fLoc = str_c(&quot;Location = &quot;, fLoc)), aes(y = Totalparasites), shape = 1)+ facet_rep_wrap(~fLoc, repeat.tick.labels = TRUE)+ coord_cartesian(ylim = c(0,300))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Total parasites&quot;) 図9.6: Posterior mean fitted values and 95% credible intervals. 9.2 Bernoulli and binomial GLM 本節では、INLAでベルヌーイ分布と二項分布のモデルを実行する方法を学ぶ。 9.2.1 Bernoulli GLM ここでは、オーストラリアでワニに襲われた人の生死を分析した Fukuda et al. (2015) のデータを用いる。襲われた場所(Position)、ワニと人間の体重の差(DeltaWeight)などの要因が生死(Survival)に与える影響が分析されている。 croco &lt;- read_delim(&quot;data/Crocodiles.txt&quot;) datatable(croco, options = list(scrollX = 80), filter = &quot;top&quot;) ここでは、よりシンプルに考えるため体重差のみを説明変数に入れたモデルを考える。 \\[ \\begin{aligned} &amp;Survived_i \\sim Bernoulli(\\pi_i)\\\\ &amp;E(Survived_i) = \\pi_i \\; and \\; var(Survived_i) = \\pi_i \\times (1-\\pi_i)\\\\ &amp;logit(\\pi_i) = log \\Bigl(\\frac{\\pi_i}{1 - \\pi_i} \\Bigl) = \\beta_1 + \\beta_2 \\times DeltaWeight_i \\end{aligned} \\] Rでは以下のように実行する。応答変数は数字である必要がある。また、ベルヌーイ分布の場合はNtrials = 1となる(なくても実行はできる)。 m10_7 &lt;- inla(Survived01 ~ DeltaWeight, data = croco, family = &quot;binomial&quot;, control.predictor = list(compute = TRUE), Ntrials = 1) 結果は以下の通り。 summary(m10_7) ## ## Call: ## c(&quot;inla.core(formula = formula, family = family, contrasts = contrasts, ## &quot;, &quot; data = data, quantiles = quantiles, E = E, offset = offset, &quot;, &quot; ## scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, ## &quot;, &quot; lp.scale = lp.scale, link.covariates = link.covariates, verbose = ## verbose, &quot;, &quot; lincomb = lincomb, selection = selection, control.compute ## = control.compute, &quot;, &quot; control.predictor = control.predictor, ## control.family = control.family, &quot;, &quot; control.inla = control.inla, ## control.fixed = control.fixed, &quot;, &quot; control.mode = control.mode, ## control.expert = control.expert, &quot;, &quot; control.hazard = control.hazard, ## control.lincomb = control.lincomb, &quot;, &quot; control.update = ## control.update, control.lp.scale = control.lp.scale, &quot;, &quot; ## control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, ## &quot;, &quot; inla.call = inla.call, inla.arg = inla.arg, num.threads = ## num.threads, &quot;, &quot; blas.num.threads = blas.num.threads, keep = keep, ## working.directory = working.directory, &quot;, &quot; silent = silent, inla.mode ## = inla.mode, safe = FALSE, debug = debug, &quot;, &quot; .parent.frame = ## .parent.frame)&quot;) ## Time used: ## Pre = 0.592, Running = 0.113, Post = 0.0354, Total = 0.74 ## Fixed effects: ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## (Intercept) 2.760 0.516 1.748 2.760 3.772 2.760 0 ## DeltaWeight -0.017 0.003 -0.024 -0.017 -0.010 -0.017 0 ## ## Marginal log-Likelihood: -37.99 ## is computed ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also &#39;control.compute=list(return.marginals.predictor=TRUE)&#39;) この結果から、\\(\\mu_i\\)は以下のように書ける。 \\[ \\begin{aligned} logit(\\pi_i) &amp;= 2.70 -0.017 \\times DeltaWeight_i \\\\ \\therefore \\pi_i &amp;= \\frac{exp(2.70 -0.017 \\times DeltaWeight_i)}{1 + exp(2.70 -0.017 \\times DeltaWeight_i)} \\end{aligned} \\] 結果を可視化すると以下のようになる(図9.7)。 newdata &lt;- data.frame(DeltaWeight= seq(min(croco$DeltaWeight),max(croco$DeltaWeight),length = 100)) Xmat &lt;- model.matrix(~ DeltaWeight, data = newdata) X &lt;- as.data.frame(Xmat) lcb &lt;- inla.make.lincombs(X) m10_8 &lt;- inla(Survived01 ~ DeltaWeight, data = croco, lincomb = lcb, family = &quot;binomial&quot;, control.predictor = list(compute = TRUE), control.compute = list(return.marginals.predictor=TRUE), Ntrials = 1) ## 線形予測子の事後周辺分布 post_pred10_8 &lt;- m10_8$marginals.lincomb.derived ## 変換を行って要約統計量を計算 ## 95%確信区間 myfun &lt;- function(x) {exp(x)/(1+exp(x))} ci.10_8 &lt;- map_df(post_pred10_8, ~inla.qmarginal(c(0.025, 0.975), inla.tmarginal(myfun,.))) %&gt;% t() %&gt;% as.data.frame() %&gt;% rename(lower = 1, upper = 2) ## 事後平均値 mean.10_8 &lt;- map_df(post_pred10_8, ~inla.emarginal(myfun,.)) %&gt;% t() %&gt;% as.data.frame() %&gt;% rename(fitted = 1) ## 図示 bind_cols(newdata, mean.10_8, ci.10_8) %&gt;% ggplot(aes(x = DeltaWeight, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2)+ geom_point(data = croco , aes(y = Survived01), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Survived&quot;) 図9.7: Fitted values of the Bernoulli model applied on the crocodile attack data. summary(m10_7) ## ## Call: ## c(&quot;inla.core(formula = formula, family = family, contrasts = contrasts, ## &quot;, &quot; data = data, quantiles = quantiles, E = E, offset = offset, &quot;, &quot; ## scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, ## &quot;, &quot; lp.scale = lp.scale, link.covariates = link.covariates, verbose = ## verbose, &quot;, &quot; lincomb = lincomb, selection = selection, control.compute ## = control.compute, &quot;, &quot; control.predictor = control.predictor, ## control.family = control.family, &quot;, &quot; control.inla = control.inla, ## control.fixed = control.fixed, &quot;, &quot; control.mode = control.mode, ## control.expert = control.expert, &quot;, &quot; control.hazard = control.hazard, ## control.lincomb = control.lincomb, &quot;, &quot; control.update = ## control.update, control.lp.scale = control.lp.scale, &quot;, &quot; ## control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, ## &quot;, &quot; inla.call = inla.call, inla.arg = inla.arg, num.threads = ## num.threads, &quot;, &quot; blas.num.threads = blas.num.threads, keep = keep, ## working.directory = working.directory, &quot;, &quot; silent = silent, inla.mode ## = inla.mode, safe = FALSE, debug = debug, &quot;, &quot; .parent.frame = ## .parent.frame)&quot;) ## Time used: ## Pre = 0.592, Running = 0.113, Post = 0.0354, Total = 0.74 ## Fixed effects: ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## (Intercept) 2.760 0.516 1.748 2.760 3.772 2.760 0 ## DeltaWeight -0.017 0.003 -0.024 -0.017 -0.010 -0.017 0 ## ## Marginal log-Likelihood: -37.99 ## is computed ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also &#39;control.compute=list(return.marginals.predictor=TRUE)&#39;) 9.2.2 10.2.2 Model selection with the marginal likelihood ここでは、ベイズファクター(Bayes factor)を用いてモデル比較を行う方法を解説する。ここで、2つのモデルがあるとしよう。1つ目は先ほど実行したモデルで、切片と体重差を含むモデル(Model1)、もう1つは切片のみを含むモデル(Model2)である。このとき、ベイズファクターは以下のように定義される。 \\[ \\begin{aligned} \\rm{Bayes} \\; \\rm{factor} &amp;= \\frac{Prob(Model1|D)}{Prob(Model2|D)} \\\\ &amp;= \\frac{Prob(D|Model1)}{Prob(D|Model2)} \\times \\frac{Model1}{Model2} \\end{aligned} \\] 周辺尤度\\(Prob(D|Model1)\\)と\\(Prob(D|Model2)\\)はそれに対数をとったものがINLAの結果で示されている(それぞれ-37.97と-54.43)。各モデルの事前確率\\(Prob(Model1), Prob(Model2)\\)は分からないが、何も知識がない状況ではどちらのモデルが正しいかはわからない(五分五分)なので、その比は\\(0.5/0.5 = 1\\)とする。 このとき、ベイズファクターは以下の値になる。この結果は、モデル1が正しい確率がモデル2が正しい確率よりもはるかに大きいことを示す。すなわち、体重差は生存に大きく影響しているといえる。 \\[ \\begin{aligned} \\rm{Bayes} \\; \\rm{factor} &amp;= \\frac{Prob(D|Model1)}{Prob(D|Model2)} \\times \\frac{Model1}{Model2}\\\\ &amp;= \\frac{exp(-37.97)}{exp(-54.43)} \\times 1\\\\ &amp;= 14076257 \\end{aligned} \\] 過分散の診断を含むモデル診断も行う必要があるが、ここでは省略する。 9.2.3 Binomial GLM ここからは、商用のダニ駆除剤がミツバチへのダニの寄生に影響するかを調べたMaggi(unpublished data)のデータを用いる。4種類の駆除剤(Toxic)が異なる濃度(Concentration)で使用された24時間後に死亡したダニの数(Dead_mites)がバッチごとに記録されている。Totalはもともといたダニの数を示す。 mite &lt;- read_delim(&quot;data/Drugsmites.txt&quot;) %&gt;% mutate(fToxic = as.factor(Toxic)) datatable(mite, options = list(scrollX = 80), filter = &quot;top&quot;) 応答変数をバッチごとに死んだダニの割合(Dead_mites/Total)とする以下のモデルを考える。ただし、\\(N_i = Total_i\\)である。回帰係数は省略している。 \\[ \\begin{aligned} &amp;Deadmites_i \\sim Binomial(\\pi_i, N_i)\\\\ &amp;E(Deadmites_i) = \\pi_i \\times N_i \\; and \\; var(Deadmites_i) = N_i \\times \\pi_i \\times (1-\\pi_i)\\\\ &amp;logit(\\pi_i ) = Intercept + Concentration_i + Toxic_i + Concentration_i \\times Toxic_i \\end{aligned} \\] Rでは以下のように実行する。 m10_9 &lt;- inla(Dead_mites ~ Concentration*fToxic, family = &quot;binomial&quot;, data = mite, Ntrials = Total, control.compute = list(waic = TRUE, dic = TRUE), control.predictor = list(compute = TRUE)) 交互作用がないモデルとどちらが良いか確かめるためDICとWAICを用いたモデル選択を行う。結果、交互作用を含むモデルの方がよいことが分かった。 m10_10 &lt;- inla(Dead_mites ~ Concentration + fToxic, family = &quot;binomial&quot;, data = mite, Ntrials = Total, control.compute = list(waic = TRUE, dic = TRUE), control.predictor = list(compute = TRUE)) waic.10 &lt;- c(m10_9$waic$waic, m10_10$waic$waic) dic.10 &lt;- c(m10_9$dic$dic, m10_10$dic$dic) data.frame(type = c(&quot;Full&quot;, &quot;- Conc × Toxic&quot;), WAIC = waic.10, DIC = dic.10) %&gt;% column_to_rownames(var = &quot;type&quot;) 過分散の診断を含むモデル診断も行う必要があるが、ここでは省略する。 9.3 Gamma GLM ここでは、イタリアのトスカーナ地方のアメリカザリガニについて調査した Ligas (2008) のデータを用いる。746個体について6つの形態学的特徴が記録されている。ここでは、体重(Weight)と性別(Sex)、体長(CTL)のみに着目する。 cray &lt;- read_delim(&quot;data/Procambarus.txt&quot;) %&gt;% mutate(fSex = as.factor(Sex)) datatable(cray, options = list(scrollX = 80), filter = &quot;top&quot;) 以下のモデルを考える。回帰係数は省略している。 \\[ \\begin{aligned} &amp;Weight_i \\sim Gamma(\\mu_i, \\phi)\\\\ &amp;E(Weight_i) = \\mu_i \\; and \\; var(Weight_i) = \\frac{\\mu_i^2}{\\phi}\\\\ &amp;log(\\mu_i) = Length_i + Sex_i + +ength_i \\times Sex_i \\end{aligned} \\] Rでは以下のように実行する。 m10_11 &lt;- inla(Weight ~ CTL*fSex, family = &quot;Gamma&quot;, control.compute = list(waic = TRUE, dic = TRUE), control.family = list(link = &quot;log&quot;, hyper = list(prec = list( prior = &quot;loggamma&quot;, param = c(1,0.5) ))), data = cray) ガンマ分布のパラメータ\\(\\phi\\)は負の二項分布の\\(k\\)と同じように機能する9。デフォルトの事前分布としては、\\(log(\\phi)\\)に対してガンマ分布が用いられている。INLAでは\\(\\phi\\)はprecisionパラメータと呼ばれ、モデルの結果に推定値が直接示されている。 m10_11$summary.hyperpar モデル選択を行うため、交互作用なしのモデルとフルモデルの比較を行ったところ、交互作用のないモデルの方がDICとWAICが低い値をとることが分かった。 m10_11b &lt;- inla(Weight ~ CTL + fSex, family = &quot;Gamma&quot;, control.compute = list(waic = TRUE, dic = TRUE), control.family = list(link = &quot;log&quot;, hyper = list(prec = list( prior = &quot;loggamma&quot;, param = c(1,0.5) ))), data = cray) waic.11 &lt;- c(m10_11$waic$waic, m10_11b$waic$waic) dic.11 &lt;- c(m10_11$dic$dic, m10_11b$dic$dic) data.frame(type = c(&quot;Full&quot;, &quot;- Conc × Toxic&quot;), WAIC = waic.11, DIC = dic.11) %&gt;% column_to_rownames(var = &quot;type&quot;) 過分散の診断を含むモデル診断も行う必要があるが、ここでは省略する。 References "],["Chapter11.html", "10 Matern correlation and SPDE 10.1 Continuous Gaussian field 10.2 Models that we have in mind 10.3 Matern correlation 10.4 SPDE approach 10.5 Weighting factors … again", " 10 Matern correlation and SPDE 本章では、回帰モデルに空間的相関を加える方法をシミュレーションデータを用いて学ぶ。 10.1 Continuous Gaussian field N個の空間的座標(\\(s_1, s_2, \\dots, s_N\\))があり、それぞれの場所でデータ\\(y(s_1), y(s_2), \\dots, y(s_N)\\)が確率過程\\(Y(s)\\)によって得られるとする。もし\\(y(s_i)\\)が正規分布に従うとするとき、\\(Y(s)\\)を連続ガウス場(continuous gaussian field)という。この正規分布には平均と分散共分散行列が必要である。 ここでは、応答変数ではなく空間的相関を表す項\\(u(s_1), u(s_2), \\dots, u(s_N)\\)が確率過程\\(U(s)\\)によって得られるとする(第5章を参照)。このとき、\\(u(s_i)\\)が正規分布から得られると仮定するとき、\\(U(s)\\)を連続ランダムガウス場という。 10.2 Models that we have in mind 通常の空間データに対する線形回帰モデルは以下のように書ける。 \\[ \\begin{aligned} &amp;y(s_i) \\sim N(\\mu(s_i), \\sigma^2)\\\\ &amp;\\mu(s_i) = Covariates(s_i) \\end{aligned} \\] ポワソン分布のGLMなら同様に以下のように書ける。 \\[ \\begin{aligned} &amp;y(s_i) \\sim Poisson(\\mu(s_i))\\\\ &amp;log(\\mu(s_i)) = Covariates(s_i) \\end{aligned} \\] これらは空間的な相関を考慮していない。空間的な相関を考慮したモデルは以下のようになる(第5章を参照)。 \\[ \\begin{aligned} &amp;y(s_i) \\sim N(\\mu(s_i), \\sigma^2)\\\\ &amp;\\mu(s_i) = Covariates(s_i) + u(s_i) \\end{aligned} \\tag{10.1} \\] ポワソン分布のGLMなら同様に以下のように書ける。 \\[ \\begin{aligned} &amp;y(s_i) \\sim Poisson(\\mu(s_i))\\\\ &amp;log(\\mu(s_i)) = Covariates(s_i) + u(s_i) \\end{aligned} \\tag{10.2} \\] 10.3 Matern correlation \\(u(s_i)\\)の分散共分散行列としては、サンプリングをした場所のユークリッド距離とMatern相関関数(第3.3参照)を用いる。Matern関数は以下のように書ける。\\(K_{\\nu}()\\)は第2種ベッセル関数である。 \\[ cor_{Matern}(U(s_i), U(s_j)) = \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\times (\\kappa \\times ||s_i - s_j||)^\\nu \\times K_\\nu(\\kappa \\times ||s_i - s_j||) \\] この関数を説明するため、100か所(\\(s_1, s_2, \\dots, s_{100}\\))からデータをサンプリングしたとするシミュレーションを行う。X座標とY座標を以下のようにランダムにシミュレートする。 set.seed(123) x1 &lt;- runif(100, min = 0, max= 100) y1 &lt;- runif(100, min = 0, max= 100) 得られた\\(s_i\\)をプロットすると以下のようになる。 data.frame(x = x1, y = y1) %&gt;% ggplot(aes(x = x, y = y))+ geom_point()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;X-coordinate&quot;, y = &quot;Y-coordinate&quot;) 2つの場所間の距離\\(||s_i - s_j||\\)のヒストグラムと、距離の累積割合を示したのが図10.1である。 dist &lt;- dist(cbind(x1,y1)) %&gt;% as.matrix() diag(dist) &lt;- NA dist.vec &lt;- as.vector(dist) %&gt;% na.omit() data.frame(dist = dist.vec) %&gt;% ggplot(aes(x = dist))+ geom_histogram(alpha = 0, color = &quot;black&quot;, binwidth = 8)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;A&quot;, x = &quot;Distances between sites&quot;, y = &quot;Frequency&quot;) -&gt; p1 data.frame(x = sort(dist.vec), y = 1:length(dist.vec)/length(dist.vec)) %&gt;% ggplot(aes(x =x, y = y))+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;B&quot;, x = &quot;Distances between sites&quot;, y = &quot;Cumlutive proportion&quot;) -&gt; p2 p1 + p2 図10.1: A: Histogram of distances between sites in the simulation study. B: Cumulative proportion versus distance between sites. ここで、\\(\\nu = 1\\)とするときのMatern関数は以下のようになる。これは、INLAのデフォルトでもある。 \\[ cor_{Matern}(U(s_i), U(s_j)) = \\kappa \\times ||s_i - s_j|| \\times K_1(\\kappa \\times ||s_i - s_j||) \\] \\(\\kappa\\)の値を様々に変えたときのMatern関数は以下のように計算できる。 kappa &lt;- c(0.01,0.03,0.05,0.07,0.1,0.3,0.5,1,2) d &lt;- seq(0, max(dist.vec), length = 1000) corMatern &lt;- data.frame() for(i in 1:length(kappa)){ corMatern_i &lt;- data.frame(kappa = kappa[i], dist = d, cor =kappa[i]*d*besselK(kappa[i]*d,1)) corMatern_i[1,3] &lt;- 1 corMatern &lt;- bind_rows(corMatern, corMatern_i) } 第3章で、自己相関がなくなるまでの距離をレンジ(range)と呼んだ。Matern関数では、レンジ\\(r\\)は以下の式で表せる。 \\[ r = \\frac{\\sqrt{8 \\times \\nu}}{\\kappa} \\] 様々な\\(\\kappa\\)のMatern関数を示したのが図(10.2)である。縦の点線でレンジを表している。また、横の点線はMatern関数の値が0.1のところを示している。\\(\\kappa\\)の値が大きいほどより近い距離で空間的な相関がなくなることがわかる。 r_kappa &lt;- data.frame(kappa = str_c(&quot;kappa = &quot;, kappa), r = sqrt(8)/kappa) corMatern %&gt;% filter(cor &gt;= 0.01) %&gt;% mutate(kappa = str_c(&quot;kappa = &quot;, kappa)) %&gt;% ggplot(aes(x = dist, y = cor))+ geom_line()+ geom_vline(data = r_kappa, aes(xintercept = r), linetype = &quot;dashed&quot;)+ geom_hline(yintercept = 0.1, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~kappa, repeat.tick.labels = TRUE, scales = &quot;free&quot;) 図10.2: Matérn correlation plotted versus distance for the simulated data set in Figure 11.1. Each panel corresponds to a different κ value. さて、第5章でも触れたように、空間的な相関を加えたモデル(式(10.1))では空間的相関を表す項\\(u_i\\)の分散共分散行列\\(\\bf{\\Sigma}\\)にMatern関数を用いる。 \\[ \\bf{\\Sigma} = cov_{Matern}\\bigl( U(s_i), U(s_j)\\bigl) = \\sigma_u^2 \\times cor_{Matern}\\bigl( U(s_i), U(s_j)\\bigl) \\] これを用いて、モデル式を以下のように書ける。GFはガウス場であることを表している。すなわち、私たちはガウス場の分散共分散を得るために2つのパラメータ\\(\\kappa, \\sigma_{u}\\)を推定する必要がある。最尤推定によって求めることもできるが、モデルが複雑になるとそれは難しくなってくる。 \\[ \\begin{aligned} &amp;y(s_i) \\sim N(\\mu(s_i), \\sigma^2)\\\\ &amp;\\mu(s_i) = Covariates(s_i) + u(s_i)\\\\ &amp;\\bf{u} \\sim GF(0, \\bf{\\Sigma}) \\end{aligned} \\tag{10.3} \\] ポワソン分布のGLMなら同様に以下のように書ける。 \\[ \\begin{aligned} &amp;y(s_i) \\sim Poisson(\\mu(s_i))\\\\ &amp;log(\\mu(s_i)) = Covariates(s_i) + u(s_i)\\\\ &amp;\\bf{u} \\sim GF(0, \\bf{\\Sigma}) \\end{aligned} \\tag{10.4} \\] 10.4 SPDE approach 通常のガウス場はサンプルサイズが大きくなると問題が生じることがある。計算をシンプルにするために用いられる方法の一つが、ガウスマルコフランダム場(Gaussian Markovian RandomField: GMRF)を用いることである。GMRFを用いれば、GFの分散共分散行列を近似することができる。 さらに、GMRFについて推定する際には以下の2つのショートカットを用いることができる。まず一つ目は、確率偏微分方程式(SPDE)を用いることである(理解する必要はない)。以下の式(10.5)を解くと、GMRFのハイパーパラメータが得られるとが分かっている。左辺は、\\(U(s)\\)の要素を二次微分したものの合計を表す。右辺は、ガウス場でのホワイトノイズ過程を表す。 \\[ (\\kappa^2 - \\Delta)^{\\alpha/2} \\tau U(s) = W(s) \\tag{10.5} \\] Lindgren and Rue (2015) はこの式を解くと以下が導かれることを示している。なお、\\(d\\)は空間の次元を表し、2次元空間モデルなら2、時系列モデルなら1である。INLAのデフォルトでは\\(\\alpha = 2\\)なので、2次元空間モデルでは\\(\\nu = 1\\)となる。 \\[ \\nu = \\alpha - \\frac{d}{2} \\tag{10.6} \\] また、式(10.5)を解くと\\(\\sigma^2_{u}\\)外貨のように推定できる。 \\[ \\sigma_{u}^2 = \\frac{\\Gamma(\\nu)}{\\Gamma(\\alpha) \\times (4 \\pi)^{d/2} \\times \\kappa^{2\\nu} \\times \\tau^2} \\] それでは、(10.5)はどのように解くことができるだろうか? Lindgren et al. (2011) はそのための理論を構築している。 10.4.1 Mesh Lindgren et al. (2011) では、メッシュと呼ばれるイレギュラーなグリッドを用いる。メッシュは、調査区間をかぶらないように三角形に分ける。これらの三角形は隣接する各三角形と1つの共通の辺と2つの共通の点を有する。三角形を作成する方法としてはいろいろな方法がある。例えば、ドロネー法と呼ばれる方法では、三角形の内角の最小値を最大にするように三角形に分割する。例として、先ほどシミュレートした100個のデータについてメッシュを作成したものを図10.3に示した。 loc &lt;- cbind(x1, y1) mesh1 &lt;- inla.mesh.2d(loc, ## 三角形の辺の長さの最大値 max.edge=c(10), ## ポイント間の最小距離 cutoff = 0.5) par(mfrow=c(1,1), mar=c(0,0,2,0)) plot(mesh1) points(loc, col = 1, pch = 16, cex = 2) 図10.3: Triangularisation for simulated data. Black dots are sampling locations. Where triangles come together is called a vertex. 10.4.2 Finite element approach メッシュを作成したことで有限要素アプローチ(finite element approach)という以下の式が成り立つ。 \\[ u(s_i) = \\Sigma_{k=1}^G a_k(s_i) \\times w_k \\tag{10.7} \\] これはどういうことだろうか?以下のシミュレーションで説明する。 10.4.3 Simulation study with five points 100ポイントでは説明するのにあまりに複雑なので、5ポイントのデータで説明を行う。まず、5ポイントのデータをシミュレートする。 set.seed(123) S &lt;- cbind(x1 = runif(n = 5), y1 = runif(n = 5)) 続いて、この5ポイントについてメッシュを作成する。 mesh &lt;- inla.mesh.2d(S, max.edge = 1) plot(mesh) points(S, pch = 16, cex = 2) さて、それでは式(10.7)の説明に入る。\\(G\\)はメッシュ内の頂点の数であり、Rでは以下のように求められる。 mesh$n ## [1] 31 よって、例えば1つ目のポイント\\(s_1\\)については以下のように書ける。 \\[ u(s_1) = \\Sigma_{k=1}^{31} a_k(s_1) \\times w_k \\tag{10.8} \\] \\(a_k(s_1)\\)は単純なもので、\\(k\\)番目の頂点が\\(s_1\\)であるか否か(1/0)である。これは、以下のように確認できる。31列のデータが5行あり、各行は\\(s_1, \\dots s_5\\)に対応する。ドットは0を表す。すなわち、\\(s_1\\)は9番目の頂点ということである。つまり、\\(a_1(s_1) = 0, a_2(s_1) = 0, \\dots, a_8(s_1) = 0, a_9(s_1) =1, a_{10}(s_1) = 0, \\dots, a_{31}(s_1) = 0\\)である。 A &lt;- inla.spde.make.A(mesh, loc = S) A ## 5 x 31 sparse Matrix of class &quot;dgCMatrix&quot; ## ## [1,] . . . . . . . 0 1 . . . . . . . . . . . . . 0 . . . . . . . . ## [2,] . . . . . . . . . 1 . . . 0 . . . . . . . . . . . . 0 . . . . ## [3,] . . . . . . . . . . 1 . . . . . . . . . . 0 . . . . 0 . . . . ## [4,] . . . . . . . . . . . 1 0 . . 0 . . . . . . . . . . . . . . . ## [5,] . . 0 . . . . . . . . . 1 . . . . . . . . . . . 0 . . . . . . 全長点の座標は以下のように確認できる。\\(s_1\\)は9行目のデータである。 mesh$loc[,1:2] %&gt;% data.frame() 最後に\\(w_k\\)である。INLAでは、式(10.5)を少し修正したものを用いて\\(w_k\\)とその分散共分散行列を取得する。式(10.7)の利点は、\\(w_1, w_2, \\dots, w_{31}\\)を求めることができる点である。 10.5 Weighting factors … again 先ほどは全てのサンプリングポイントがメッシュの三角形の頂点と一致したが、三角形の内側にサンプリングポイントを作ることも可能である。図10.4はその一例を示したものである。作成方法については後程説明する。 set.seed(1231) coords &lt;- cbind(x1 = runif(5), y1 = runif(5)) pl.dom &lt;- cbind(c(0,1,1,0), c(0,0,1,1)) mesh2 &lt;- inla.mesh.2d(pl.dom, max.edge= 0.5) plot(mesh2) points(coords, pch=16, cex = 2) 図10.4: Different mesh for the five sampling locations. In this case all sampling locations are inside triangles and not on the vertices. メッシュは41ポイントを有する。\\(a_k(s_i)\\)は以下のようになる。先ほどのように1か0ではなく、0と0から1の間の少数のいずれかであることが分かる。 A &lt;- inla.spde.make.A(mesh2, loc = S) A %&gt;% as.matrix() %&gt;% as.data.frame() %&gt;% datatable(options = list(scrollX = 41)) %&gt;% formatRound(columns = 1:41, digits = 3) 例えば、\\(a_{14}(s_1) = 0.338, a_{19}(s_1) = 0.100, a_{36}(s_1) = 0.562\\)で、それ以外の\\(a_k(s_1)\\)は0である。0以外の値をとる頂点は、\\(s_1\\)が含まれる三角形の頂点であるので、\\(u(s_1)\\)は式(10.8)から以下のように書ける。 \\[ u(s_1) = 0.338 \\times w_{14} + 0.100 \\times w_{19} + 0.562 \\times w_{36} \\] References "],["Chapter12.html", "11 Linear regression model with spatial dependency for the Irish pH data 11.1 Introduction 11.2 Model formulation 11.3 Linear regression results 11.4 Model validation 11.5 Adding spatial correlation to the model 11.6 Defining the mesh for the Irish pH data 11.7 Define the weight factor aik 11.8 Define the SPDE 11.9 Define the spatial field 11.10 Define the stack 11.11 Define the formula for the spatial model 11.12 Execute the spatial model in R 11.13 Results 11.14 Model selection 11.15 Model validation 11.16 Model interpretation 11.17 Detailed information about the stack", " 11 Linear regression model with spatial dependency for the Irish pH data 本章では、前章で学んだ手法を実際の空間データに適用して分析を行う。 11.1 Introduction 用いるのは第1章で用いた、アイルランドの257の川において、川のpHがSDI(Sodium Dominance Index; 陽イオン中のナトリウムイオン)と関連しているかを、緯度(Altitude)やその場所が森林化されているか(Forested)も考慮したうえで調べた Cruikshanks et al. (2006) のデータである。第1章では、地理的に近いデータほど類似しており、疑似反復の問題を避けるためには空間的相関を考慮したモデルを適用する必要があることを確認した。 11.2 Model formulation まず、空間的な相関を考慮しないモデルとして以下のモデルを考える。2次の交互作用項と3次の交互作用項をすべて含んでいる。 \\[ \\begin{aligned} &amp;pH_i \\sim N(\\mu_i, \\sigma^2)\\\\ &amp;E(pH_i) = \\mu_i \\; and \\; var(pH_i) = \\sigma^2\\\\ &amp;\\mu_i = \\alpha + \\beta_1 \\times SDI_i + \\beta_2 \\times logAltitude_i + \\beta_3 + Forested_i \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\; + \\beta_4 \\times SDI_i \\times LogAltitude_i + \\beta_5 \\times SDI_i \\times Forested_i + \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\; + \\beta_6 \\times LogAltitude_i \\times Forested_i \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\; + \\beta_7 \\times LogAltitude_i \\times Forested_i \\end{aligned} \\] 11.3 Linear regression results それでは、INLAで上記のモデルを実行する。 iph %&gt;% mutate(logAlt = log10(Altitude)) %&gt;% mutate(fForested = fct_relevel(fForested,&quot;yes&quot;,&quot;no&quot;))-&gt; iph m12_1 &lt;- inla(pH ~ logAlt*SDI*fForested, family = &quot;gaussian&quot;, control.predictor = list(compute = TRUE), data = iph) 結果は以下の通り。3-way interactionは95%確信区間に0を含んでおり、 m12_1$summary.fixed %&gt;% select(mean, sd, &quot;0.025quant&quot;, &quot;0.975quant&quot;) ハイパーパラメータの要約統計量は以下の通り。ここでは、\\(\\sigma\\)について情報を算出した。 tau &lt;- m12_1$marginals.hyperpar$`Precision for the Gaussian observations` sigma &lt;- inla.tmarginal(function(x) 1/sqrt(x), tau) sigma_summary &lt;- inla.qmarginal(p = c(0.025, 0.5, 0.975), sigma) %&gt;% data.frame() %&gt;% t() colnames(sigma_summary) &lt;- c(&quot;0.025quant&quot;, &quot;0.5quant&quot;, &quot;0.975quant&quot;) sigma_summary ## 0.025quant 0.5quant 0.975quant ## . 0.3408095 0.3743001 0.4136209 11.4 Model validation 続いて、モデル診断を行う。 まず、残差と予測値、残差と共変量の関係を調べたら問題はなかった。これは第1と一緒である。 fitted &lt;- m12_1$summary.fitted.values$mean resid &lt;- iph$pH - fitted data.frame(fitted = fitted, resid = resid) %&gt;% ggplot(aes(x= fitted, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;Fitted values&quot;, y = &quot;Residuals&quot;) -&gt; p1 data.frame(SDI = iph$SDI, resid = resid) %&gt;% ggplot(aes(x= SDI, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;SDI&quot;, y = &quot;Residuals&quot;) -&gt; p2 data.frame(SDI = iph$logAlt, resid = resid) %&gt;% ggplot(aes(x= SDI, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;Log(Altitude)&quot;, y = &quot;Residuals&quot;) -&gt; p3 data.frame(forested = iph$fForested, resid = resid) %&gt;% ggplot(aes(x= forested, y = resid))+ geom_boxplot()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;Forested&quot;, y = &quot;Residuals&quot;) -&gt; p4 (p1 + p2)/(p3+p4) 続いて、バリオグラムを確認する。第1章で確認したときと同様、やはり空間的な相関が存在することがわかる。 vario_12_1 &lt;- data.frame(resid = resid, Easting.km = iph$Easting/1000, Northing.km = iph$Northing/1000) sp::coordinates(vario_12_1) &lt;- c(&quot;Easting.km&quot;, &quot;Northing.km&quot;) vario_12_1 %&gt;% variogram(resid ~ Easting.km + Northing.km, data = ., ## 0が南北方向、90が東西方向 alpha = c(0, 90), cressie = TRUE, cutoff = 150, width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ dir.hor, repeat.tick.labels = TRUE, labeller = as_labeller(c(&quot;0&quot; = &quot;North-South&quot;, &quot;90&quot; = &quot;East-West&quot;)), scales = &quot;free&quot;)+ labs(y = &quot;semivariogram&quot;) 11.5 Adding spatial correlation to the model それでは、空間的な相関を考慮したモデルを実行する。モデル式は以下の通り。先ほどとの唯一の違いは\\(u_i\\)が入っている点である。まず、\\(u_i\\)は正規分布に従っており、ガウス場である。続いて、その分散共分散行列はマルコフ過程に従う(隣り合う観測値のみが相関する)。このとき、\\(u_i\\)はガウスマルコフランダム場(GMRF)から得られる。\\(\\bf{\\Sigma}\\)はMatern関数を用いて表現される。 \\[ \\begin{aligned} &amp;pH_i \\sim N(\\mu_i, \\sigma^2)\\\\ &amp;E(pH_i) = \\mu_i \\; and \\; var(pH_i) = \\sigma^2\\\\ &amp;\\mu_i = \\alpha + \\beta_1 \\times SDI_i + \\beta_2 \\times logAltitude_i + \\beta_3 + Forested_i \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\; + \\beta_4 \\times SDI_i \\times LogAltitude_i + \\beta_5 \\times SDI_i \\times Forested_i + \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\; + \\beta_6 \\times LogAltitude_i \\times Forested_i \\\\ &amp; \\;\\;\\;\\;\\;\\;\\;\\; + \\beta_7 \\times LogAltitude_i \\times Forested_i + u_i\\\\ &amp;u_i \\sim GMRF(0,\\bf{\\Sigma}) \\end{aligned} \\] Matern関数のパラメータは、確率偏微分方程式(SPDE)を解くことで求められる。これを解くため、サンプリング空間に多くの三角形から成るメッシュが作られる。最後に、有限要素アプローチ(finite element approach)で各頂点について\\(w_k\\)が得られ、これをもとに\\(u_i\\)の事後分布が得られる。 INLAで上記のようなことを行うには、以下のステップを踏む。 メッシュを作成する。 各頂点の重みづけ因子\\(a_{ik}\\)を定義する。 確率偏微分方程式(SPDE)を定義する。 ランダム場を定義する。 メッシュのどの点で応答変数と共変量を得たか、またランダム効果などがあればメッシュのどの点にあるかをINLAに伝える。 モデル式を決める。 INLAで空間モデルを実行する。 11.6 Defining the mesh for the Irish pH data ここでは、アイルランドの河川データに対してメッシュを作成する。まず、データの座標をkmに直す。 iph %&gt;% mutate(Easting.km = Easting/1000, Northing.km = Northing/1000) -&gt; iph 2つの場所間の距離\\(||s_i - s_j||\\)のヒストグラムと、距離の累積割合を示したのが図11.1である。図11.1Bは、50%以上の観測値が200km以内でサンプリングされたことを示している。 dist_iph &lt;- dist(cbind(iph$Easting.km, iph$Northing.km)) %&gt;% as.matrix() diag(dist_iph) &lt;- NA dist_iph.vec &lt;- as.vector(dist_iph) %&gt;% na.omit() data.frame(dist = dist_iph.vec) %&gt;% ggplot(aes(x = dist))+ geom_histogram(alpha = 0, color = &quot;black&quot;, binwidth = 8)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;A&quot;, x = &quot;Distances between sites&quot;, y = &quot;Frequency&quot;) -&gt; p1 data.frame(x = sort(dist_iph.vec), y = 1:length(dist_iph.vec)/length(dist_iph.vec)) %&gt;% ggplot(aes(x =x, y = y))+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;B&quot;, x = &quot;Distances between sites&quot;, y = &quot;Cumlutive proportion&quot;) -&gt; p2 p1 + p2 図11.1: A: Histogram of distances between sites in the simulation study. B: Cumulative proportion versus distance between sites. メッシュは以下のように作成する。max.edgeはメッシュの内側と外側の辺の最大の長さをそれぞれ指定する。これが小さいほどメッシュ内の三角形の数は多くなる。作成したメッシュは図11.2の1行目の一番左である。 mesh12_1 &lt;- inla.mesh.2d(loc = cbind(iph$Easting.km, iph$Northing.km), max.edge = c(10,10), cutoff = 0) メッシュは太い線で内側と外側に分けられている(図11.2)。メッシュは\\(w_k\\)を計算するのに用いられ、アルゴリズムはその過程で近傍の情報を利用する。もし三角形が調査地の端に位置しているとすると、近傍の三角形が少なくなるので頂点の\\(w_k\\)のばらつきが大きくなってしまう可能性がある。これを避けるため、メッシュの外側のエリアが使われる。このエリアは2つの太い線に囲われる領域で、サンプリングポイントが存在しない(図11.2)。外側のエリアは内側のエリアに先ほどの問題が生じないようにする緩衝領域だと考えることができる。offsetというオプションを用いると、外側と内側のエリアの範囲を調整することができる。一般的に、外側のエリアはレンジ(空間相関がなくなる距離)よりも広いことが推奨されている。 cutoffオプションは、その距離より近いサンプリングポイント同士が1つの頂点に入れ替えられることを示す。以下、max.edgeとcutoffに様々な値を割り当てたメッシュを作成し、図11.2に示した。 Loc &lt;- cbind(iph$Easting.km, iph$Northing.km) mesh12_2 &lt;- inla.mesh.2d(loc = Loc, max.edge = c(10,10), cutoff = 10) mesh12_3 &lt;- inla.mesh.2d(loc = Loc, max.edge = c(50,50)) mesh12_4 &lt;- inla.mesh.2d(loc = Loc, max.edge = c(75,75), cutoff = 1) mesh12_5 &lt;- inla.mesh.2d(loc = Loc, max.edge = c(25,50), cutoff = 1) mesh12_6 &lt;- inla.mesh.2d(loc = Loc, max.edge = c(50,80), cutoff = 1) mesh12_7 &lt;- inla.mesh.2d(loc = Loc, max.edge = c(100,120), cutoff = 1) mesh12_8 &lt;- inla.mesh.2d(loc = Loc, max.edge = c(150,150), cutoff = 1) par(mfrow=c(3,3), mar=c(1,1,1,1)) for(i in 1:8){ plot(get(paste(&#39;mesh12_&#39;, i, sep = &#39;&#39;)), main = &quot;&quot;,asp=1) points(Loc, col = 2, pch = 16, cex = 1) } 図11.2: Various meshes. Top row from left to right: meshes 1 to 3. Middle row from left to right: meshes 4 to 6. Bottom row from left to right: meshes 7 to 9. 各メッシュの頂点の数は以下の通り。 c(mesh12_1$n, mesh12_2$n, mesh12_3$n, mesh12_4$n, mesh12_5$n, mesh12_6$n, mesh12_7$n, mesh12_8$n) ## [1] 4982 4856 649 523 737 528 515 515 他のアプローチとしては、すべてのサンプリングポイントが境界領域内にあるように境界領域を指定することである。 bound &lt;- inla.nonconvex.hull(Loc) mesh12_9 &lt;- inla.mesh.2d(loc = Loc, boundary = bound, max.edge = 50, cutoff = 5) plot(mesh12_9, main = &quot;&quot;, asp=1) points(Loc, col = 2, pch = 16, cex = 1) メッシュの選択には、確率偏微分方程式(SPDE)の近似の精度と計算時間のトレードオフがある。700-800の頂点しかない場合は計算が数秒で終わるが、4000-5000個あると数分かかる。一般的にはまず700-800の頂点を持つメッシュで最初の分析を行い、最終的な結果はより多くの頂点を持つメッシュで示す。ひとまず、ここでは737個の頂点があるメッシュmesh12_5を用いて分析する。 plot(mesh12_5, main = &quot;&quot;, asp=1) points(Loc, pch = 16, cex = 1) 11.7 Define the weight factor aik メッシュmesh12_5は737個の頂点があるので、分析の結果737個の\\(w_k\\)(\\(w_1,w_2,\\dots, w_{737}\\))の事後分布を得る。また、データは210個あるので、\\(u_i\\)(\\(u_1, u_2, \\dots. u_{210}\\))も210個ある。メッシュの種類によって各サンプリングポイントはメッシュの三角形内か頂点に配置されるが、今回選択したメッシュ(mesh12_5)では頂点にある。つまり今回の場合は\\(s_i\\)がk番目の頂点にあるとき、\\(u_i\\)は\\(w_k\\)と一致する。一方で、もし\\(s_i\\)が三角形内にあるのであれば、\\(u_i\\)はその三角形の頂点\\(w_k\\)の重みづけ平均になる(第10章、式(10.7)参照)。 \\[ u_i = \\Sigma_{k=1}^{737} a_{ik} \\times w_k \\tag{11.1} \\] \\(a_{ik}\\)は重みづけ関数と呼ばれる。Rでは以下のように確認できる。例えば、\\(a_{1k}\\)は以下のようになる。 A12_5 &lt;- inla.spde.make.A(mesh12_5, loc = Loc) A12_5[1,] ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 ## [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [149] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [186] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [223] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [260] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [297] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [334] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [371] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [408] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [445] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [482] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [519] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [556] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [593] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [630] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [667] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [704] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 11.8 Define the SPDE 空間相関を持つランダム切片\\(u_i\\)で、その分散共分散行列がMatern関数で表現されるとき、SPDEは以下のように定義できる。alpha = 2はMatern関数のパラメータ\\(\\nu\\)が1であることを示す(式(10.6)を参照)。 spde &lt;- inla.spde2.matern(mesh12_5, alpha = 2) 11.9 Define the spatial field 続いて、ランダム切片の行列\\(\\bf{u}\\)を求めるためのリストを作成する。\\(\\bf{u}\\)は\\(\\bf{A}\\)と\\(\\bf{w}\\)を以下のように定義するとき、\\(\\bf{u} = \\bf{A} \\times \\bf{w}\\)と書ける。\\(\\bf{w}\\)はINLAで推定する必要がある。 \\[ \\begin{aligned} &amp;\\bf{A} = \\begin{pmatrix} a_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,737} \\\\ \\vdots &amp; \\ddots &amp; &amp; \\vdots \\\\ a_{210,1} &amp; a_{210,2} &amp; \\cdots &amp; a_{210,737} \\end{pmatrix} \\\\ &amp;\\bf{w} = (w_1, w_2, \\dots, w_{737}) \\end{aligned} \\tag{11.2} \\] \\(\\bf{w}\\)はINLAで推定する必要がある。これは以下のようにできる。w.index中のwは1から737の数字を含む。w.groupとw.replについては時空間モデルを実行するときに解説する。 w.index &lt;- inla.spde.make.index( name = &#39;w&#39;, n.spde = spde$n.spde, n.group = 1, n.repl = 1) str(w.index) ## List of 3 ## $ w : int [1:737] 1 2 3 4 5 6 7 8 9 10 ... ## $ w.group: int [1:737] 1 1 1 1 1 1 1 1 1 1 ... ## $ w.repl : int [1:737] 1 1 1 1 1 1 1 1 1 1 ... 11.10 Define the stack 続いて、メッシュのどの点で応答変数と共変量を得たかをINLAに伝える必要がある。Rでは、inla.stack関数を用いてこれを行う。これについて理解するため、まずモデルをマトリックス形式で書く。 \\[ \\mu_i = \\alpha + \\Sigma_{j = 1}^7 \\beta_j X_{ij} + u_i \\] \\(X_{ij}\\)は交互作用項を含む説明変数(\\(SDI_i,LogAltitude_i, \\dots, SDI_i \\times LogAltitude_i \\times Forested_i\\))を含む。また、式(11.1)よりこの式は以下のように変形できる。 \\[ \\mu_i = \\alpha + \\Sigma_{j = 1}^7 \\beta_j X_{ij} + \\Sigma_{k=1}^{731} a_{ik} \\times w_k \\] 行列式で書くと以下のように書ける。 \\[ \\bf{X} = 1 \\times \\alpha + \\bf{X \\times \\beta} + \\bf{A \\times w} \\tag{11.3} \\] ハイパーパラメータはpHが得られる正規分布の標準偏差\\(\\sigma\\)、Matern関数の\\(\\kappa\\)と\\(u_i\\)の分散共分散行列の\\(\\sigma_u\\)、そして\\(\\bf{w}\\)である。式(11.3)を実行するためには、INLAにinla.stack関数で3つの要素を与える必要がある。 一つ目は共変量を含む行列\\(\\bf{X}\\)で、以下のように作成する。 Xm &lt;- model.matrix(~ logAlt * SDI * fForested, data = iph) X &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4], Alt.SDI = Xm[,5], Alt.fFor = Xm[,6], SDI.fFor = Xm[,7], Alt.SDI.fFor = Xm[,8]) それでは、inla.stack関数でINLAに情報を与える。これで作られたオブジェクトは”stack”といわれる。Aのリストはガウス場への射影行列で、effectsの各要素に対応している。 N &lt;- nrow(iph) StackFit &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = X, w = w.index)) 11.11 Define the formula for the spatial model それでは、以下で空間相関のあるモデルとないモデルをフィットする。煩雑になるので、モデル式はあらかじめ作っておく。 ## 空間相関なし f2a &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.SDI + Alt.fFor + SDI.fFor + Alt.SDI.fFor ## 空間相関あり f2b &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.SDI + Alt.fFor + SDI.fFor + Alt.SDI.fFor + f(w, model = spde) 11.12 Execute the spatial model in R それでは、モデルを実行する。 m12_2a &lt;- inla(f2a, family = &quot;gaussian&quot;, data = inla.stack.data(StackFit), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFit))) m12_2b &lt;- inla(f2b, family = &quot;gaussian&quot;, data = inla.stack.data(StackFit), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFit))) DICとWAICを用いてモデル比較を行うと、空間相関を考慮した方がはるかにいいことが分かる。 waic12_2 &lt;- c(m12_2a$waic$waic, m12_2b$waic$waic) dic12_2 &lt;- c(m12_2a$dic$dic, m12_2b$dic$dic) modelcomp12_2 &lt;- cbind(waic12_2, dic12_2) rownames(modelcomp12_2) &lt;- c(&quot;Gaussian lm&quot;, &quot;Gaussian lm + SPDE&quot;) modelcomp12_2 ## waic12_2 dic12_2 ## Gaussian lm 196.9916 194.5744 ## Gaussian lm + SPDE 127.7375 124.2912 11.13 Results ハイパーパラメータ以外の結果は以下の通り。 m12_2a$summary.fixed[,c(&quot;mean&quot;,&quot;sd&quot;,&quot;0.025quant&quot;,&quot;0.975quant&quot;)] %&gt;% mutate_if(is.numeric, ~round(.,3)) %&gt;% bind_cols(m12_2b$summary.fixed[,c(&quot;mean&quot;,&quot;sd&quot;,&quot;0.025quant&quot;,&quot;0.975quant&quot;)] %&gt;% mutate_if(is.numeric, ~round(.,3)) %&gt;% rename(&quot; mean&quot; = 1, &quot; sd&quot; = 2, &quot; 0.025quant&quot; = 3, &quot; 0.975quanr&quot; = 4)) %&gt;% kbl(align = &quot;lcccccccc&quot;) %&gt;% add_header_above(c(&quot;&quot;, &quot;空間相関なし&quot; = 4, &quot;空間相関有り&quot; = 4)) 空間相関なし 空間相関有り mean sd 0.025quant 0.975quant mean sd 0.025quant 0.975quanr Intercept 8.247 0.764 6.747 9.748 8.928 0.706 7.541 10.312 Alt 0.108 0.390 -0.658 0.873 -0.245 0.350 -0.932 0.443 SDI -0.028 0.017 -0.062 0.006 -0.044 0.016 -0.076 -0.012 fFor 1.790 2.062 -2.259 5.839 0.852 1.775 -2.633 4.336 Alt.SDI 0.002 0.009 -0.015 0.019 0.010 0.008 -0.005 0.026 Alt.fFor -0.883 1.008 -2.862 1.096 -0.335 0.873 -2.048 1.379 SDI.fFor -0.008 0.037 -0.081 0.064 0.006 0.032 -0.057 0.068 Alt.SDI.fFor 0.004 0.018 -0.032 0.039 -0.005 0.015 -0.035 0.025 事後平均と95%確信区間を図示すると以下のようになる。そこまで大きい違いはないので、空間的相関を表すランダム効果の効果はそこまで大きくないのかもしれない。 m12_2a$summary.fixed[,c(&quot;mean&quot;,&quot;0.025quant&quot;,&quot;0.975quant&quot;)] %&gt;% mutate(model = &quot;m12_2a&quot;) %&gt;% rownames_as_column(var = &quot;parameter&quot;) %&gt;% bind_rows(m12_2b$summary.fixed[,c(&quot;mean&quot;,&quot;0.025quant&quot;,&quot;0.975quant&quot;)] %&gt;% mutate(model = &quot;m12_2b&quot;) %&gt;% rownames_as_column(var = &quot;parameter&quot;)) %&gt;% ggplot(aes(x = model, y = mean))+ geom_errorbar(aes(ymin = `0.025quant`, ymax = `0.975quant`), width = 0.2)+ geom_point()+ geom_hline(yintercept= 0, linetype = &quot;dashed&quot;)+ facet_rep_wrap(~parameter, repeat.tick.labels = TRUE, scales = &quot;free&quot;) 続いて、ハイパーパラメータの結果を見ていく。推定の結果、\\(\\kappa\\)と\\(\\sigma_u\\)の事後平均はそれぞれ0.0319と0.2804であることが分かった。レンジの事後平均は105.61である。 SpFi.w &lt;- inla.spde2.result(inla = m12_2b, name = &quot;w&quot;, spde = spde, do.transfer = TRUE) ## Kappa kappa &lt;- inla.emarginal(function(x) x, SpFi.w$marginals.kappa[[1]]) kappa ## [1] 0.03180548 ##sigma sigma &lt;- inla.emarginal(function(x) sqrt(x), SpFi.w$marginals.variance.nominal[[1]]) sigma ## [1] 0.2804851 ## range range = inla.emarginal(function(x) x, SpFi.w$marginals.range.nominal[[1]]) range ## [1] 105.7647 \\(\\kappa\\)が分かればMatern関数を描写することができる。 D &lt;- as.vector(dist(mesh12_5$loc[,1:2])) d.vec &lt;- seq(0, max(D), length = 100) corM &lt;- (kappa*d.vec)*besselK(kappa*d.vec,1) corM[1] &lt;- 1 data.frame(Distance = d.vec, Correlation = corM) %&gt;% ggplot(aes(x = Distance, y = Correlation))+ geom_line()+ geom_vline(xintercept = range, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1) \\(w_k\\)の事後平均は以下のように求めることができる。 w.pm &lt;- m12_2b$summary.random$w$mean この\\(w_k\\)の事後平均をランダムガウス場に図示することができる。inla.mesh.projector関数はメッシュを用いて特定の範囲に格子を作成してくれる。通常はメッシュの最大最小の範囲に格子が作られる。 w.proj &lt;- inla.mesh.projector(mesh12_5) 続いて、inla.mesh.projector関数で格子上にw.pmの事後平均を投影する。通常は、100×100の格子が用いられる。 w.pm100_100 &lt;-inla.mesh.project(w.proj, w.pm) 最後に、格子状に\\(w_k\\)を図示する。 expand.grid(x = w.proj$x, y = w.proj$y) %&gt;% mutate(z = as.vector(w.pm100_100)) -&gt; grid ggplot(grid %&gt;% drop_na(), aes(x = x, y = y))+ geom_tile(aes(fill = z))+ scale_fill_gradient2(high = muted(&quot;lightblue&quot;), low = muted(&quot;pink&quot;), mid = &quot;white&quot;, midpoint = -0.1)+ geom_point(aes(x = Easting.km, y = Northing.km), data = iph, shape = 1)+ stat_contour(aes(z = z, color = ..level..))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Easting(km)&quot;, y = &quot;Northing(km)&quot;)+ guides(color = &quot;none&quot;) 11.14 Model selection WAICとDICを用いて、モデルに改善が見られなくなるまで1つずつ説明変数/交互作用項を除いていくという作業(step関数と同じ作業)を行っていく。まず、3次の交互作用項と2次の交互作用項を一つずつ除いたものを比較する。 ## 3-way interractionなし f2c &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.SDI + Alt.fFor + SDI.fFor + f(w, model = spde) Xc &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4], Alt.SDI = Xm[,5], Alt.fFor = Xm[,6], SDI.fFor = Xm[,7]) StackFitc &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = Xc, w = w.index)) m12_2c &lt;- inla(f2c, family = &quot;gaussian&quot;, data = inla.stack.data(StackFitc), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFitc))) ## SDI.fForなし f2d &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.SDI + Alt.fFor + f(w, model = spde) Xd &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4], Alt.SDI = Xm[,5], Alt.fFor = Xm[,6]) StackFitd &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = Xd, w = w.index)) m12_2d &lt;- inla(f2d, family = &quot;gaussian&quot;, data = inla.stack.data(StackFitd), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFitd))) ## Alt.fForなし f2e &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.SDI + SDI.fFor + f(w, model = spde) Xe &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4], Alt.SDI = Xm[,5], SDI.fFor = Xm[,7]) StackFite &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = Xe, w = w.index)) m12_2e &lt;- inla(f2e, family = &quot;gaussian&quot;, data = inla.stack.data(StackFite), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFite))) ## Alt.SDIなし f2f &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.fFor + SDI.fFor + f(w, model = spde) Xf &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4], Alt.fFor = Xm[,6], SDI.fFor = Xm[,7]) StackFitf &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = Xf, w = w.index)) m12_2f &lt;- inla(f2f, family = &quot;gaussian&quot;, data = inla.stack.data(StackFitf), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFitf))) その結果、3次の交互作用項と2次の交互作用項Alt.SDIを含まないモデルが最もWAICが低いことが分かった。一方で、DICは3次の交互作用のみを含まないモデルが最も低い。ここでは、m12_2fを採用することにする。 ## モデル比較 waic12_2 &lt;- c(m12_2b$waic$waic, m12_2c$waic$waic, m12_2d$waic$waic, m12_2e$waic$waic, m12_2f$waic$waic) dic12_2 &lt;- c(m12_2b$dic$dic, m12_2c$dic$dic, m12_2d$dic$dic, m12_2e$dic$dic, m12_2f$dic$dic) modelcomp12_2 &lt;- cbind(waic12_2, dic12_2) rownames(modelcomp12_2) &lt;- c(&quot;Full&quot;,&quot;-Alt.SDI.fFor &quot;, &quot;-SDI.fFor&quot;, &quot;-Alt.fFor&quot;,&quot;-Alt.SDI&quot;) modelcomp12_2 ## waic12_2 dic12_2 ## Full 127.7375 124.2912 ## -Alt.SDI.fFor 126.5898 122.6982 ## -SDI.fFor 127.6033 123.5803 ## -Alt.fFor 133.1570 130.0797 ## -Alt.SDI 126.5112 123.0979 続いて、残った2次の交互作用項を1つずつ除いたものと、交互作用項を含まないモデルとの比較を行う。 ## Alt.fForなし f2g &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + SDI.fFor + f(w, model = spde) Xg &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4], SDI.fFor = Xm[,7]) StackFitg &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = Xg, w = w.index)) m12_2g &lt;- inla(f2g, family = &quot;gaussian&quot;, data = inla.stack.data(StackFitg), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFitg))) ## SDI.fForなし f2h &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.fFor + f(w, model = spde) Xh &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4], Alt.fFor = Xm[,6]) StackFith &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = Xh, w = w.index)) m12_2h &lt;- inla(f2h, family = &quot;gaussian&quot;, data = inla.stack.data(StackFith), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFith))) ## 交互作用なし f2i &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + f(w, model = spde) Xi &lt;- data.frame(Alt = Xm[,2], SDI = Xm[,3], fFor = Xm[,4]) StackFiti &lt;- inla.stack( tag = &quot;Fit&quot;, data = list(y = iph$pH), A = list(1, 1, A12_5), effects = list( Intercept = rep(1, N), X = Xi, w = w.index)) m12_2i &lt;- inla(f2i, family = &quot;gaussian&quot;, data = inla.stack.data(StackFiti), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(StackFiti))) その結果、わずかながら2次の交互作用項を2つ含むモデル(m12_2f)が最もWAICとDICが低いことが分かった。 ## モデル比較 waic12_2 &lt;- c(m12_2f$waic$waic, m12_2g$waic$waic, m12_2h$waic$waic, m12_2i$waic$waic) dic12_2 &lt;- c(m12_2f$dic$dic, m12_2g$dic$dic, m12_2h$dic$dic, m12_2i$dic$dic) modelcomp12_2 &lt;- cbind(waic12_2, dic12_2) rownames(modelcomp12_2) &lt;- c(&quot;Full&quot;,&quot;-Alt.fFor &quot;, &quot;-SDI.fFor&quot;, &quot;no interaction&quot;) modelcomp12_2 ## waic12_2 dic12_2 ## Full 126.5112 123.0979 ## -Alt.fFor 130.7929 128.1620 ## -SDI.fFor 126.8899 123.4883 ## no interaction 133.8153 131.2625 11.15 Model validation 続いて、モデル診断を行う。 まず、残差と予測値を計算する。m12_2f$summary.fitted.valuesはデータ数210ではなく合計632行のデータを返すが、最初の210個が予測値である。残りの432個が何を示しているのかは後ほど触れる。 fitted &lt;- m12_2f$summary.fitted.values$mean[1:210] resid &lt;- iph$pH - fitted 残差と予測値、残差と共変量の関係を見ると、1つだけ外れ値があるものの、全体的なパターンはないように見える。 data.frame(fitted = fitted, resid = resid) %&gt;% ggplot(aes(x= fitted, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;Fitted values&quot;, y = &quot;Residuals&quot;) -&gt; p1 data.frame(SDI = iph$SDI, resid = resid) %&gt;% ggplot(aes(x= SDI, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;SDI&quot;, y = &quot;Residuals&quot;) -&gt; p2 data.frame(SDI = iph$logAlt, resid = resid) %&gt;% ggplot(aes(x= SDI, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;Log(Altitude)&quot;, y = &quot;Residuals&quot;) -&gt; p3 data.frame(forested = iph$fForested, resid = resid) %&gt;% ggplot(aes(x= forested, y = resid))+ geom_boxplot()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x= &quot;Forested&quot;, y = &quot;Residuals&quot;) -&gt; p4 (p1 + p2)/(p3+p4) 続いて、バリオグラムを確認する。空間的相関を考慮しなかった場合に比べると水平に近づいており、改善しているように見える。 vario_12_2f &lt;- data.frame(resid = resid, Easting.km = iph$Easting/1000, Northing.km = iph$Northing/1000) sp::coordinates(vario_12_2f) &lt;- c(&quot;Easting.km&quot;, &quot;Northing.km&quot;) vario_12_2f %&gt;% variogram(resid ~ Easting.km + Northing.km, data = ., ## 0が南北方向、90が東西方向 alpha = c(0, 90), cressie = TRUE, cutoff = 150, width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ dir.hor, labeller = as_labeller(c(&quot;0&quot; = &quot;North-South&quot;, &quot;90&quot; = &quot;East-West&quot;)), repeat.tick.labels = TRUE)+ labs(y = &quot;semivariogram&quot;) 11.16 Model interpretation 選ばれたモデルの結果は以下のとおりである。 m12_2f$summary.fixed %&gt;% print(digits = 2) ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## Intercept 8.114 0.2996 7.522 8.115 8.700 8.117 5.6e-09 ## Alt 0.162 0.1432 -0.119 0.163 0.443 0.163 6.5e-10 ## SDI -0.023 0.0022 -0.028 -0.023 -0.019 -0.023 2.5e-09 ## fFor 1.117 0.3971 0.336 1.117 1.895 1.118 6.2e-10 ## Alt.fFor -0.484 0.1912 -0.859 -0.484 -0.109 -0.484 6.7e-10 ## SDI.fFor -0.004 0.0041 -0.012 -0.004 0.004 -0.004 5.4e-10 inla.emarginal(function(x) 1/sqrt(x), m12_2f$marginals.hyperpar$`Precision for the Gaussian observations`) ## [1] 0.2900052 モデル式に当てはめると以下のようになる。 \\[ \\begin{aligned} &amp;pH_i \\sim N(\\mu_i, 0.29^2)\\\\ &amp;E(pH_i) = \\mu_i \\; and \\; var(pH_i) = 0.29^2\\\\ &amp;\\mu_i = \\begin{cases} 9.23 -0.027 \\times SDI_i + -0.321 \\times logAltitude_i + u_i &amp; \\rm{if \\; not \\; forested} \\\\ 8.12 -0.023 \\times SDI_i + 0.162 \\times logAltitude_i + u_i &amp; \\rm{if \\; forested}\\\\ \\end{cases} \\end{aligned} \\] INLAで時空間モデルの予測値とその95%確信区間を得るには、前章までとは少し違う工夫が必要がある。予測値が欲しい範囲の変数と応答変数がNAであるデータフレームを作るのは同様だが、それを”stack”オブジェクトにする必要がある。 newdata &lt;- crossing(logAlt = seq(min(iph$logAlt), max(iph$logAlt), length = 100), SDI = seq(min(iph$SDI), max(iph$SDI), length = 100), fForested = iph$fForested) Xmm &lt;- model.matrix(~ logAlt*fForested + SDI * fForested, data = newdata) Xp &lt;- data.frame(Alt = Xmm[,2], SDI = Xmm[,4], fFor = Xmm[,3], Alt.fFor = Xmm[,5], SDI.fFor = Xmm[,6]) StackCov &lt;- inla.stack( tag = &quot;Covariates&quot;, data = list(y = NA), A = list(1,1), effects = list( Intercept = rep(1, nrow(newdata)), Xp = Xp)) 作成した”stack”オブジェクトはもともとのオブジェクトに結合する。 All.stack &lt;- inla.stack(StackFitf, StackCov) その後、結合したものでモデルを実行する。その後は基本的に空間的相関を考慮しない場合と同じである。結果を図示したのが以下の図である。 f2fit &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.fFor + SDI.fFor + f(w, model = spde) m12_2fit &lt;- inla(f2fit, family = &quot;gaussian&quot;, data = inla.stack.data(All.stack), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(All.stack))) ## 何番目から何番目の値がnewdataの予測値か index.cov &lt;- inla.stack.index(All.stack, tag = &quot;Covariates&quot;)$data ## 予測値と95%確信区間 fit12_2 &lt;- bind_cols(newdata, m12_2fit$summary.fitted.values[index.cov, c(1,3,5)]) ## 図示 plot_ly(fit12_2 %&gt;% group_by(fForested), x = ~logAlt, y = ~SDI, z = ~mean, size = 2, type = &quot;surface&quot;, colors = c(&quot;black&quot;,&quot;grey&quot;), alpha = 0.2) %&gt;% add_markers(color = ~fForested) 続いて、地図上にランダム切片\\(u_i\\)を図示する。まずは、\\(u_i\\)を算出する。これは、式(11.2)より\\(\\bf{u} = \\bf{A} \\times \\bf{w}\\)であることを利用して簡単に求められる。 ## uの算出 w.pm &lt;- m12_2f$summary.random$w$mean u &lt;- as.matrix(A12_5) %*% w.pm ## 格子上にwkの値を投影 w.proj &lt;- inla.mesh.projector(mesh12_5) w.pm100_100 &lt;-inla.mesh.project(w.proj, w.pm) 続いて、求めた値を地図上に図示したものが図11.3である。 ## EastingとNorthingを緯度と経度に変換 sp_u &lt;- SpatialPointsDataFrame(coords = cbind(iph$Easting, iph$Northing), data = data.frame(u = u, ID = iph$ID, pH = iph$pH), proj4string = CRS(&quot;+init=epsg:29902&quot;)) sp_u_data &lt;- spTransform(sp_u, CRS(&quot;+init=epsg:4322&quot;)) ## アイルランドの地図をダウンロード Ireland &lt;- st_read(&quot;shpfile/IRL_adm0.shp&quot;) ## Reading layer `IRL_adm0&#39; from data source ## `C:\\Users\\Tsubasa Yamaguchi\\Desktop\\R_studies\\practice\\Spatial-temporal_analysis\\shpfile\\IRL_adm0.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 1 feature and 70 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -10.66305 ymin: 51.41958 xmax: -5.993611 ymax: 55.45042 ## Geodetic CRS: WGS 84 Ireland.sf &lt;- st_transform(Ireland, crs = 4322) ## 図示 st_as_sf(sp_u_data) %&gt;% ggplot()+ geom_sf(data = Ireland.sf, fill = &quot;darkgreen&quot;)+ geom_sf(aes(size = abs(u), color = u &lt;= 0, shape = u &lt;= 0), alpha = 0.7)+ scale_size(range = c(0.01,4))+ scale_shape_manual(values = c(17,16))+ scale_color_manual(values = c(&quot;yellow1&quot;,&quot;red3&quot;))+ theme_bw()+ labs(color = &quot;u &gt; 0&quot;, shape = &quot;u &gt; 0&quot;, size = &quot;abs(u)&quot;) 図11.3: Map of Ireland with estimated us. ランダムガウス場上に推定された\\(u_i\\)をプロットすると以下のようになる。 grid_w &lt;- expand.grid(x = w.proj$x, y = w.proj$y) %&gt;% mutate(w = as.vector(w.pm100_100)) df_u &lt;- data.frame(x = iph$Easting.km, y = iph$Northing.km, u = u) ggplot(grid_w %&gt;% drop_na(), aes(x = x, y = y))+ stat_contour(aes(z = w, color = ..level..), linewidth = 1)+ scale_color_gradient2(high = muted(&quot;green2&quot;), low = muted(&quot;red&quot;), mid = &quot;yellow&quot;, midpoint = 0)+ geom_point(data = df_u, aes(size = abs(u), shape = u &gt; 0), alpha = 0.7)+ scale_size(range = c(0.01,4))+ scale_shape_manual(values = c(17,16))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Easting(km)&quot;, y = &quot;Northing(km)&quot;) 11.17 Detailed information about the stack 以下では、どのように予測値を得ていたのかを解説する。 11.17.1 Stack for the fitted model again メッシュ(mesh12_5)は737個の頂点を持つので、A12_5は、\\(a_{ik}\\)を含む行列\\(\\bf{A}\\)である(式(11.2)参照)。 dim(A12_5) ## [1] 210 737 各行は各データに対応する。すなわち、A12_5[1,]は\\(a_{1k}\\)に対応する。前章(10)で見たように、もしデータのサンプリングポイント\\(i\\)(\\(s_i\\))が頂点\\(k\\)上にあれば\\(a_{ik} = 1\\)、なければ\\(a_{ik} = 0\\)である。また、もし\\(s_i\\)が三角形内にある場合はその三角形の頂点の\\(a_{ik}\\)には0から1の間の小数値が合計1になるように割り振られる。よって、\\(\\bf{A}\\)(A12_5)の各行の合計は1になる。 空間的相関を考慮したモデルの式は以下のように書ける。 \\[ \\begin{aligned} \\bf{\\mu} &amp;= \\rm{Intercept} + \\rm{Covariates} + \\rm{Spatial \\;random \\;effects}\\\\ &amp;= \\bf{A_1} \\times \\rm{Intercept} + \\bf{A_2} \\times \\rm{Covariates} + \\bf{A_3} \\times \\rm{Spatial \\;field} (\\bf{w})\\\\ &amp;= \\begin{pmatrix} \\bf{A_1} &amp; \\bf{A_2} &amp; \\bf{A_3} \\end{pmatrix} \\times \\begin{pmatrix} \\rm{Intercept}\\\\ \\rm{Covariates}\\\\ \\rm{Spatial field} (\\bf{w}) \\end{pmatrix} \\\\ &amp;= \\bf{A} \\times \\bf{Z} \\end{aligned} \\] ここで、\\(\\bf{A_1,A_2,A_3}\\)はそれぞれモデルを回すときにinla.stack関数のA =で指定したものである(今回はそれぞれ1, 1, A12_5)。\\(\\bf{A_1}\\)は全てが1の210行×1列の行列、\\(\\bf{A_2}\\)は210行×210列の単位行列である。行列\\[\\bf{A} = \\begin{pmatrix} \\bf{A_1} &amp; \\bf{A_2} &amp; \\bf{A_3} \\end{pmatrix}\\]は、以下のように求められる。 A &lt;- inla.stack.A(StackFitf) dim(A) ## [1] 210 422 ここには列数が\\(1 + 210 + 737 = 948\\)ではなく422列しかない。これは、INLAが\\(\\bf{A_3}\\)のうち合計が0である列を計算しないからである。以下で計算しているように列の合計が0より大きいものは211列なので、\\(1 + 210 + 211 = 422\\)列になるのである。 table(colSums(A12_5) &gt; 0) ## ## FALSE TRUE ## 526 211 11.17.2 Stack for the new covariate values 新しい共変量の値に対してモデルの予測値を得る場合には、前節(11.16)でやったように予測をしたい範囲の共変量を含むデータフレームを作成し、“stack”オブジェクトを作成する必要がある。このとき、応答変数はNAにする。ここで、A = list(1,1)とするのはモデルの予測には空間的相関を考慮する項\\(u_i\\)を含まないため、\\(\\bf{A_3}\\)が必要ないからである。 Xmm &lt;- model.matrix(~ logAlt*fForested + SDI * fForested, data = newdata) Xp &lt;- data.frame(Alt = Xmm[,2], SDI = Xmm[,4], fFor = Xmm[,3], Alt.fFor = Xmm[,5], SDI.fFor = Xmm[,6]) StackPred &lt;- inla.stack( tag = &quot;Predict&quot;, data = list(y = NA), A = list(1,1), effects = list( Intercept = rep(1, nrow(newdata)), Xp = Xp)) ここで、もともとモデルを実行するときに用いていた\\(\\bf{A}\\)を\\[\\bf{A^1} = \\begin{pmatrix} \\bf{A^1_1} &amp; \\bf{A^1_2} &amp; \\bf{A^1_3} \\end{pmatrix}\\]、予測に用いる\\(\\bf{A}\\)を\\[\\bf{A^2} = \\begin{pmatrix} \\bf{A^2_1} &amp; \\bf{A^2_2} \\end{pmatrix}\\]とする。このとき、モデルフィットのためのモデル式は以下のように書ける。 \\[ \\begin{aligned} \\bf{\\mu^1} &amp;= \\begin{pmatrix} \\bf{A^1_1} &amp; \\bf{A^1_2} &amp; \\bf{A^1_3} \\end{pmatrix} \\times \\begin{pmatrix} \\rm{Intercept}\\\\ \\rm{Covariates}\\\\ \\rm{Spatial field} (\\bf{w}) \\end{pmatrix} \\\\ &amp;= \\bf{A^1} \\times \\bf{Z^1} \\end{aligned} \\tag{11.4} \\] 一方、予測値を得るためのモデル式は以下のように書ける。 \\[ \\begin{aligned} \\bf{\\mu^2} &amp;= \\begin{pmatrix} \\bf{A^2_1} &amp; \\bf{A^2_2} \\end{pmatrix} \\times \\begin{pmatrix} \\rm{Intercept}\\\\ \\rm{Covariates}\\\\ \\end{pmatrix} \\\\ &amp;= \\bf{A^2} \\times \\bf{Z^2} \\end{aligned} \\tag{11.5} \\] newdataは20000行なので、\\(\\bf{A^2_1}\\)は20000行×1列、\\(\\bf{A^2_2}\\)は20000行×20000列である。よって、\\(\\bf{A^2}\\)は20000行×20001列になる。 dim(inla.stack.A(StackPred)) ## [1] 20000 20001 11.17.3 Combine the two stacks 続いて、モデルフィットのための”stack”(StackFitf)と予測のための”stack”(StackPred)を結合する。 All.stack &lt;- inla.stack(StackFitf, StackPred) このとき、式(11.4)と式(11.5)が結合され以下のように書ける。 \\[ \\begin{aligned} \\begin{pmatrix} \\mu^1 \\\\ \\mu^2 \\end{pmatrix} &amp;= \\begin{pmatrix} \\bf{A^1} &amp; 0 \\\\ 0 &amp; \\bf{A^2} \\end{pmatrix} \\times \\begin{pmatrix} \\bf{Z^1} \\\\ \\bf{Z^2} \\end{pmatrix} \\\\ &amp;= \\bf{A} \\times \\bf{Z} \\end{aligned} \\] よって、All.stackの行数はStackFitfとStackPredの行数を足し合わせたものになる。列数については、列数の合計から1を引いた値になっている(重複しているInterceptを除いている)。 dim(inla.stack.A(All.stack)) ## [1] 20210 20422 11.17.4 Run the model 最後に、結合した”stack”を用いてモデルを実行する。 f2fit &lt;- y ~ -1 + Intercept + Alt + SDI + fFor + Alt.fFor + SDI.fFor + f(w, model = spde) m12_2fit &lt;- inla(f2fit, family = &quot;gaussian&quot;, data = inla.stack.data(All.stack), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list(A = inla.stack.A(All.stack))) モデルの予測値は40632行ある。これは、summary.fitted.valuesが”stack”オブジェクト(All.stack)の全ての要素について予測値を算出するからである。40632はAll.stackの行数と列数を足したものである。 dim(m12_2fit$summary.fitted.values) ## [1] 40632 6 inla.stack.index関数を用いれば、何行目に目当ての予測値があるかを容易に知ることができる。実データについての予測値は以下のように抽出できる。 index.fit &lt;- inla.stack.index(All.stack, tag = &quot;Fit&quot;)$data fit12_2_raw &lt;- m12_2fit$summary.fitted.values[index.fit, c(1,3,5)] 新しい共変量の値に対してモデルの予測値を得る場合は以下のように抽出できる。 index.predict &lt;- inla.stack.index(All.stack, tag = &quot;Predict&quot;)$data fit12_2_predict &lt;- m12_2fit$summary.fitted.values[index.predict, c(1,3,5)] References "],["Chapter13.html", "12 Spatial Poisson models applied to plant diversity 12.1 Introduction 12.2 Data exploration 12.3 Model formulation 12.4 GLM results 12.5 Adding spatial correlation to the model 12.6 Simulating from the model 12.7 What to write in a paper", " 12 Spatial Poisson models applied to plant diversity 本章では、空間的相関を考慮したGLMの分析例を紹介する。 12.1 Introduction 本章では、気候及び地形がカナリア諸島にあるラ・パルマ島の植物種数、特に固有種数に与える影響を調べた Irl et al. (2015) のデータを用いる。島の890地点について多年生の維管束植物の有無(総数、総固有種数など)が測定されている。 12.2 Data exploration 12.2.1 Sampling locations データは以下の通り。データには緯度と経度が記録してあるが、これらはUTM形式なので実際の緯度と経度に直す必要がある。 nSIE: プロットごとの固有種数(= 応答変数) CR_CAN: カナリア諸島のclimate rarity indices CR_LP: ラ・パルマ島のclimate rarity indices INTRA_VAR: 年内の降水量のばらつき INTER_VAR: 年ごとの降水量のばらつき MAT: 年間平均気温 MAP: 年間平均降水量 RSI: 降水量の季節性指標 TCI: 地形指標 macro:マクロアスペクト(半径5km以内のグリッドセルあたりの平均アスペクト) lp &lt;- read_delim(&quot;data/LaPalma.txt&quot;) ## sfクラスに変換 lpcoords &lt;- st_as_sf(lp, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = &quot;+proj=utm +zone=28&quot;) ## 緯度経度に変換 lonlat &lt;- st_transform(lpcoords, crs = &quot;+proj=longlat&quot;) ## 元のデータフレームに緯度と経度を追加 lp %&gt;% mutate(lon = st_coordinates(lonlat)[,1], lat = st_coordinates(lonlat)[,2]) -&gt; lp datatable(lp, options = list(scrollX = 40), filter = &quot;top&quot;) 地図上にデータポイントをプロットすると以下のようになる。 lp_shp &lt;- st_read(&quot;shpfile/lapalma.shp&quot;) ## Reading layer `lapalma&#39; from data source ## `C:\\Users\\Tsubasa Yamaguchi\\Desktop\\R_studies\\practice\\Spatial-temporal_analysis\\shpfile\\lapalma.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 1 feature and 136 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 206384.5 ymin: 3150659 xmax: 233949.4 ymax: 3195713 ## Projected CRS: WGS 84 / UTM zone 28N lp_shp %&gt;% ggplot()+ geom_sf()+ geom_sf(data = lonlat, alpha = 0.5)+ theme_bw() 12.2.2 Outliers 外れ値がないかを確かめるためにdotplotを描いてみたところ、外れ値はなさそうだった。 lp %&gt;% select(CR_CAN:pAE, -SR, -nAE, -pSIE, -pAE) %&gt;% mutate(n = 1:n()) %&gt;% pivot_longer(1:16) %&gt;% ggplot(aes(x = value, y = n))+ geom_point(alpha = 0.6, shape = 1)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 0.8) 12.2.3 Collinearity 変数間に多重共線性がないかを確認するため、ポワソン分布のGLMを実行してVIFを確認してみる。その結果、MATとElevationがかなり高いVIFを持つことが分かった。 m13_vif &lt;- glm(nSIE ~ CR_CAN + CR_LP + Elevation + INTRA_VAR + INTER_VAR + MAT + MAP + RSI + ASR + Easterness + Age + Macro + Northerness + Slope + TCI, family = &quot;poisson&quot;, data = lp) check_collinearity(m13_vif) この2つを除いてもう一度VIFを計算したところ、以下のようになった。以後、最もVIFが高い変数を除いてモデルを回し、VIFを計算しなおすという作業を全ての変数のVIFが3を下回るまで繰り返す。まずMacroを取り除く。 m13_vif2 &lt;- glm(nSIE ~ CR_CAN + CR_LP + INTRA_VAR + INTER_VAR + MAP + RSI + ASR + Easterness + Age + Macro + Northerness + Slope + TCI, family = &quot;poisson&quot;, data = lp) check_collinearity(m13_vif2) 続いて、ASRのVIFが最も高くなったのでこれを取り除く。 m13_vif3 &lt;- glm(nSIE ~ CR_CAN + CR_LP + INTRA_VAR + INTER_VAR + MAP + RSI + ASR + Easterness + Age + Northerness + Slope + TCI, family = &quot;poisson&quot;, data = lp) check_collinearity(m13_vif3) 次に、RSIが最も高くなったのでこれを取り除く。 m13_vif4 &lt;- glm(nSIE ~ CR_CAN + CR_LP + INTRA_VAR + INTER_VAR + MAP + RSI + Easterness + Age + Northerness + Slope + TCI, family = &quot;poisson&quot;, data = lp) check_collinearity(m13_vif4) 最後に、INTRA_VARのみVIFが3を超えているのでこれを取り除く。 m13_vif5 &lt;- glm(nSIE ~ CR_CAN + CR_LP + INTRA_VAR + INTER_VAR + MAP + Easterness + Age + Northerness + Slope + TCI, family = &quot;poisson&quot;, data = lp) check_collinearity(m13_vif5) これで、VIFが3を超える変数はなくなった。よって、以下の変数を説明変数としてモデリングを行う。 m13_vif6 &lt;- glm(nSIE ~ CR_CAN + CR_LP + INTER_VAR + MAP + Easterness + Age + Northerness + Slope + TCI, family = &quot;poisson&quot;, data = lp) check_collinearity(m13_vif6) 12.2.4 Relationships 説明変数と応答変数(nSIE)との関連をプロットしたところ、強い関連はなさそうだ。いくつかの変数とは非線形な関係がありそう? lp %&gt;% select(CR_CAN, CR_LP, INTER_VAR, MAP, Easterness, Age, Northerness, Slope, TCI, nSIE) %&gt;% pivot_longer(1:9) %&gt;% ggplot(aes(x = value, y = nSIE))+ geom_point()+ geom_smooth(color = &quot;red4&quot;, fill = &quot;pink3&quot;)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 0.8) 12.2.5 Number of zeros 応答変数にゼロが多すぎると問題が生じることがあるが、本データにはそこまで多くのゼロはなく(9.55%)、問題はないと思われる。 mean(lp$nSIE == &quot;0&quot;) ## [1] 0.09550562 12.2.6 Conclusions data exploration 変数選択は本来はVIFを使うだけでなく、生物学的な知識も合わせて行った方がよい。しかし、ひとまず本章ではVIFのみに基づいて変数を選択した。変数に外れ値はなく、ゼロ過剰はなかった。また、説明変数と応答変数の間には明確な関連はなさそうだった。 説明変数はスケールを合わせるためにすべて標準化する。 lp %&gt;% mutate(crcan.std = scale(CR_CAN)[,1], crlp.std = scale(CR_LP)[,1], intervar.std = scale(INTER_VAR)[,1], map.std = scale(MAP)[,1], age.std = scale(Age)[,1], slope.std = scale(Slope)[,1], tci.std = scale(TCI)[,1]) -&gt; lp 12.3 Model formulation まず、空間的な相関を考慮しないポワソンGLMを実行し、問題がないかを確認する。モデル式は以下の通り。なお、切片と回帰係数は省略している。 \\[ \\begin{aligned} &amp;nSIE_i \\sim P(\\mu_i)\\\\ &amp;E(nSIE_i) = \\mu_i \\; and \\; var(nSIE_i) = \\mu_i \\\\ &amp;log(\\mu_i) = crcan + crlp + interval + map + age + slope + tci \\end{aligned} \\] 12.4 GLM results それでは、INLAでモデルを実行する。 m13_1 &lt;-inla(nSIE ~ crcan.std + crlp.std + intervar.std + map.std + age.std + slope.std + tci.std + Easterness + Northerness, family = &quot;poisson&quot;, control.predictor = list(compute = TRUE), control.compute = list(config = TRUE), data = lp) まず、過分散の有無を確認するため分散パラメータを算出する(第9.1.3.1節参照)。分散パラメータは0.876…であり、過分散にはなっていないことが分かる(むしろ過少分散?)。ひとまず、ここでは過少分散を無視してポワソン分布で分析を続ける。 mu &lt;- m13_1$summary.fitted.values$mean E1 &lt;- (lp$nSIE - mu)/sqrt(mu) N &lt;- nrow(lp) p &lt;- length(m13_1$names.fixed) phi &lt;- sum(E1^2)/(N-p) phi ## [1] 0.8759609 続いて、ポワソン残差と説明変数の関係をプロットしたところ、明確に非線形のパターンはないように見える。 lp %&gt;% mutate(resid = E1) %&gt;% select(CR_CAN, CR_LP, INTER_VAR, MAP, Easterness, Age, Northerness, Slope, TCI, resid) %&gt;% pivot_longer(1:9) %&gt;% ggplot(aes(x = value, y = resid))+ geom_point(shape = 1)+ geom_smooth(color = &quot;red4&quot;, fill = &quot;pink3&quot;)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 0.8) 最後に、ピアソン残差に空間的な相関があるかを確かめるためバリアグラムを描く。バリオグラムは明確に2.5kmくらいまで空間的相関がありそうなことを示している。 lp %&gt;% mutate(X.km = lp$Longitude/1000, Y.km = lp$Latitude/1000) -&gt; lp vario13_1 &lt;- data.frame(resid = E1, lon = lp$X.km, lat = lp$Y.km) sp::coordinates(vario13_1) &lt;- c(&quot;lon&quot;, &quot;lat&quot;) vario13_1 %&gt;% variogram(resid ~ 1, data = ., cressie = TRUE, ## 距離が150km以下のデータのみ使用 cutoff = 10, ## 各距離範囲カテゴリの範囲 width = 0.2) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point()+ theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,1))+ geom_smooth(color = &quot;black&quot;)+ labs(y = &quot;semivariogram&quot;) 12.5 Adding spatial correlation to the model 12.5.1 Model formulation そこで、空間的相関を考慮したモデルを実行する。モデル式は以下のとおりである。空間相関を考慮するのでEasternessとNorthernessは説明変数から除く。 \\[ \\begin{aligned} &amp;nSIE_i \\sim P(\\mu_i)\\\\ &amp;E(nSIE_i) = \\mu_i \\; and \\; var(nSIE_i) = \\mu_i \\\\ &amp;log(\\mu_i) = crcan + crlp + interval + map + age + slope + tci + u_i \\end{aligned} \\] 12.5.2 Mesh メッシュの適切なサイズを検討するため、各サンプリングポイント間の距離とその累積割合をプロットした。ほとんど(約70%)のポイントは20km以下しか離れていない。 dist_lp &lt;- dist(cbind(lp$X.km, lp$Y.km)) %&gt;% as.matrix() diag(dist_lp) &lt;- NA dist_lp.vec &lt;- as.vector(dist_lp) %&gt;% na.omit() data.frame(dist = dist_lp.vec) %&gt;% ggplot(aes(x = dist))+ geom_histogram(alpha = 0, color = &quot;black&quot;, binwidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;A&quot;, x = &quot;Distances between sites&quot;, y = &quot;Frequency&quot;) -&gt; p1 data.frame(x = sort(dist_lp.vec), y = 1:length(dist_lp.vec)/length(dist_lp.vec)) %&gt;% ggplot(aes(x =x, y = y))+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;B&quot;, x = &quot;Distances between sites&quot;, y = &quot;Cumlutive proportion&quot;) -&gt; p2 p1 + p2 図12.1: A: Histogram of distances between the 890 sites on La Palma. B: Cumulative proportion of distances versus distance. 以上から、本分析では以下のメッシュを作成した。本分析の場合、海上に植物が生育することはないので、メッシュを内側と外側に分けない。 Loc13_2 &lt;- cbind(lp$X.km, lp$Y.km) bound13_2 &lt;- inla.nonconvex.hull(Loc13_2) mesh13_2 &lt;- inla.mesh.2d(loc = Loc13_2, boundary = bound13_2, max.edge = c(1.5)) plot(mesh13_2, main = &quot;&quot;, asp=1) メッシュには3304個の頂点が含まれる。 mesh13_2$n ## [1] 3304 しかし、このメッシュには島外の海の領域が含まれてしまっている。そのため、島の輪郭の外にメッシュが存在しないようにする。 まず、島のshpファイルを読み込み、データフレームに変換する。 lp.utm &lt;- readOGR(dsn = &quot;shpfile/lapalma.shp&quot;) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;C:\\Users\\Tsubasa Yamaguchi\\Desktop\\R_studies\\practice\\Spatial-temporal_analysis\\shpfile\\lapalma.shp&quot;, layer: &quot;lapalma&quot; ## with 1 features ## It has 136 fields ## dfに変換 lp_df &lt;- fortify(lp.utm) %&gt;% mutate(X.km = long/1000, Y.km = lat/1000) データフレームの緯度と経度は島の輪郭を表している。これをcoastlineというオブジェクトに格納する。 lp_df %&gt;% ggplot(aes(x = X.km, y = Y.km))+ geom_point()+ theme_bw()+ theme(aspect.ratio = 1.4) coastline &lt;- lp_df[,c(&quot;X.km&quot;, &quot;Y.km&quot;, &quot;order&quot;)] 輪郭の座標は反時計回りでないといけないので、緯度と経度の順番を逆にする必要がある。 coastline_rev &lt;- coastline %&gt;% arrange(desc(order)) %&gt;% select(-order) coastline &lt;- coastline %&gt;% select(-order) 以下のようにして島の輪郭をメッシュの輪郭とするメッシュを作成する。 mesh13_2b &lt;- inla.mesh.2d(loc.domain = coastline, max.edge = 1.5, boundary = inla.mesh.segment(coastline_rev)) 作成されたメッシュは以下の通り。 plot(mesh13_2b) points(x = lp$X.km, y = lp$Y.km, col = 1, pch = 16, cex = 0.5) 頂点の数は1192個である。 mesh13_2b$n ## [1] 1192 なお、輪郭が時計回りのままだとメッシュが島の外側に作られてしまう。 mesh13_2c &lt;- inla.mesh.2d(loc.domain = coastline, max.edge = 1.5, boundary = inla.mesh.segment(coastline)) plot(mesh13_2c) points(x = lp$X.km, y = lp$Y.km, col = 1, pch = 16, cex = 0.5) 12.5.3 Projector matrix 続いて、\\(a_{ik}\\)を定義する。前章までで学んだように、\\(a_{ik}\\)はランダム\\(w_k\\)とランダム切片\\(u_i\\)を結びつけるものである。 \\[ u_i = \\Sigma_{k=1}^{1192} a_{ik} \\times w_k \\tag{10.7} \\] メッシュmesh13_2bの\\(a_k\\)は以下のように計算できる。\\(a_{ik}\\)を含む行列\\(\\bf{A}\\)は890行×1192列である。 A13_2 &lt;- inla.spde.make.A(mesh13_2b, loc = Loc13_2) dim(A13_2) ## [1] 890 1192 12.5.4 SPDE SPDEを定義する。 spde13_2 &lt;- inla.spde2.matern(mesh = mesh13_2b, alpha = 2) 12.5.5 Spatial field ランダム場\\(w_k\\)を定義する。 w.index13_2 &lt;- inla.spde.make.index(name = &quot;w&quot;, n.spde = spde13_2$n.spde, n.group = 1, n.repl = 1) 12.5.6 Stack stackを定義する。まずは\\(\\bf{X}\\)を準備する。今回は前章と違いInterceptをXの中に入れる。 N &lt;- nrow(lp) X13_2 &lt;- data.frame(Intercept = rep(1,N), crcan.std = lp$crcan.std, crlp.std = lp$crlp.std, intervar.std = lp$intervar.std, map.std = lp$map.std, age.std = lp$age.std, slope.std = lp$slope.std, tci.std = lp$tci.std) X13_2 &lt;- as.data.frame(X13_2) それでは、stackを定義する。 stack13_2 &lt;- inla.stack(tag = &quot;Fit&quot;, data = list(y = lp$nSIE), A = list(A13_2, 1), effects = list(w = w.index13_2, X = X13_2)) 12.5.7 Formula 以下で、空間的相関を含むモデルと含まないモデルを両方実行する。 ## 空間相関なし f13_2a &lt;- y ~ -1 + Intercept + crcan.std + crlp.std + intervar.std + map.std + age.std + slope.std + tci.std ## 空間相関なし f13_2b &lt;- y ~ -1 + Intercept + crcan.std + crlp.std + intervar.std + map.std + age.std + slope.std + tci.std + f(w, model = spde13_2) 12.5.8 Run R-INLA それではモデルを実行する。 m13_2a &lt;- inla(f13_2a, family = &quot;poisson&quot;, data = inla.stack.data(stack13_2), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list( A = inla.stack.A(stack13_2))) m13_2b &lt;- inla(f13_2b, family = &quot;poisson&quot;, data = inla.stack.data(stack13_2), control.compute = list(dic = TRUE, waic = TRUE), control.predictor = list( A = inla.stack.A(stack13_2))) DICとWAICを用いてモデル比較を行うと、空間相関を考慮した方がはるかにいいことが分かる。 waic13_2 &lt;- c(m13_2a$waic$waic, m13_2b$waic$waic) dic13_2 &lt;- c(m13_2a$dic$dic, m13_2b$dic$dic) modelcomp13_2 &lt;- cbind(waic13_2, dic13_2) rownames(modelcomp13_2) &lt;- c(&quot;Poisson GLM&quot;, &quot;Poisson GLM + SPDE&quot;) modelcomp13_2 ## waic13_2 dic13_2 ## Poisson GLM 3044.033 3044.927 ## Poisson GLM + SPDE 2974.355 2994.560 12.5.9 Inspect results それでは、推定された結果の比較を行う。それぞれのモデルの固定効果の事後平均と95%確信区間を図示したのが図12.2である。いずれのパラメータも、空間相関を考慮したモデルの方が95%確信区間が大きくなっている。このことは、空間相関を無視して分析を行うと誤った結論を導いてしまうことを示している。 m13_2a$summary.fixed %&gt;% rownames_to_column(var = &quot;Parameter&quot;) %&gt;% mutate(model = &quot;m13_2a&quot;) %&gt;% bind_rows(m13_2b$summary.fixed %&gt;% rownames_to_column(var = &quot;Parameter&quot;) %&gt;% mutate(model = &quot;m13_2b&quot;)) %&gt;% ggplot(aes(x = model, y = mean))+ geom_point(size = 1.5)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ geom_errorbar(aes(ymin = `0.025quant`, ymax = `0.975quant`), width = 0.2)+ facet_rep_wrap(~Parameter, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;&quot;) 図12.2: Results of the Poisson GLM witho ut spatial correlation and the model with spatial correlation. 続いて、それぞれのモデルのバリオグラムを描いて空間相関の問題が解決されているか検討する。まず、各モデルの予測値とピアソン残差を計算する。 ## μの予測値が含まれている範囲を計算 index &lt;- inla.stack.index(stack13_2, tag = &quot;Fit&quot;)$data mu13_2a &lt;- m13_2a$summary.fitted.values[index, &quot;mean&quot;] mu13_2b &lt;- m13_2b$summary.fitted.values[index, &quot;mean&quot;] E13_2a &lt;- (lp$nSIE - mu13_2a)/sqrt(mu13_2a) E13_2b &lt;- (lp$nSIE - mu13_2b)/sqrt(mu13_2b) 各モデルのバリオグラムをプロットしたのが以下の図12.3である。空間相関を考慮したモデルの方が空間相関は弱まっているものの、まだ少しだけ残っている。 ## 空間相関なし resid13_2a &lt;- data.frame(resid = E13_2a, lon = lp$X.km, lat = lp$Y.km) sp::coordinates(resid13_2a) &lt;- c(&quot;lon&quot;, &quot;lat&quot;) vario13_2a &lt;- variogram(resid ~ 1, data = resid13_2a, cressie = TRUE, cutoff = 10, width = 0.2) %&gt;% mutate(model = &quot;GLM&quot;) ## 空間相関あり resid13_2b &lt;- data.frame(resid = E13_2b, lon = lp$X.km, lat = lp$Y.km) sp::coordinates(resid13_2b) &lt;- c(&quot;lon&quot;, &quot;lat&quot;) vario13_2b &lt;- variogram(resid ~ 1, data = resid13_2b, cressie = TRUE, cutoff = 10, width = 0.2) %&gt;% mutate(model = &quot;Spatial GLM&quot;) ## 図示 vario13_2a %&gt;% bind_rows(vario13_2b) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point()+ theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,1))+ geom_smooth(color = &quot;black&quot;)+ facet_rep_wrap(~ model, repeat.tick.labels = TRUE)+ labs(y = &quot;semivariogram&quot;) 図12.3: Sample-variograms of the Pearson residuals for the Poisson GLM (left panel) and the model with spatial correlation (right panel). 12.5.9.1 Plotting interpolated wk 次に、推定されたランダム場\\(w_k\\)の事後中央値と標準偏差を地図上にプロットする。まず推定された\\(w_k\\)を取り出す。 w.pm &lt;- m13_2b$summary.random$w$mean w.sd &lt;- m13_2b$summary.random$w$sd 次にこれを地図上に作図するためのグリッドを作成してその上に\\(w_k\\)の値を対応させる。このグリッドは100×100である。 wproj &lt;- inla.mesh.projector(mesh13_2b) w.pm100_100 &lt;- inla.mesh.project(wproj, w.pm) w.sd100_100 &lt;- inla.mesh.project(wproj, w.sd) 最後に、これを作図する。うまく空間的相関を表せていそう。標準偏差はほとんどが0.2くらいでばらつきが小さい。 expand.grid(X.km = wproj$x, Y.km = wproj$y) %&gt;% mutate(w.pm = as.vector(w.pm100_100), w.sd = as.vector(w.sd100_100)) -&gt; w_df w_df %&gt;% drop_na() %&gt;% pivot_longer(3:4) %&gt;% ggplot(aes(x = X.km, y = Y.km))+ geom_raster(aes(fill = value))+ theme_bw() + scale_fill_gradientn(colors = rainbow(30, alpha = 0.5))+ facet_rep_wrap(~ name) 12.5.9.2 Plotting the random intercepts ui 続いて、ランダム切片\\(u_i\\)を地図上にプロットする。\\(u_i\\)を得る方法はいくつかある。一つは前章(11.16)でやったように\\(\\bf{u} = \\bf{A} \\times \\bf{w}\\)であることを利用して手動で計算する方法である。もう一つは以下のようにINLAの関数を利用する方法である。どちらもまったく同じ値が得られる。 u.proj &lt;- inla.mesh.projector(mesh13_2b, loc = Loc13_2) u.pm &lt;- inla.mesh.project(u.proj, m13_2b$summary.random$w$mean) それでは地図上に作図する。\\(w_k\\)が負のところからは負の\\(u_i\\)が、\\(w_k\\)が正のところからは正の\\(u_i\\)が得られていることが分かる。 data.frame(X.km = lp$X.km, Y.km = lp$Y.km, u = u.pm) %&gt;% replace_na(list(u = 0)) %&gt;% ggplot(aes(x = X.km, y = Y.km))+ geom_polygon(data = lp_df, fill = NA, color = &quot;black&quot;, linewidth = 1)+ geom_tile(data = w_df %&gt;% drop_na(), aes(fill = w.pm))+ geom_point(aes(shape = u &gt; 0))+ scale_shape_manual(values = c(1,16))+ theme_bw() + coord_fixed(ratio = 1)+ scale_fill_gradient2(high = muted(&quot;red&quot;), low = muted(&quot;yellow&quot;), mid = &quot;white&quot;, midpoint = 0) 図12.4: Ma p of La Palma with posterior mean values of the spatial random effects u i, and the spatial random field w k. The closed circles represent positive u i values and the open circles are negative u is. 最後に、得られたパラメータからマテルン関数をプロットする。SPDEの結果を得るにはinla.spde2.result関数を用いる。\\(\\kappa, \\sigma_u\\)とレンジの事後平均は以下の通り。レンジはおよそ2.37kmだった。 spfi.w &lt;- inla.spde2.result(inla = m13_2b, name = &quot;w&quot;, spde = spde13_2, do_transfer = TRUE) kappa &lt;- inla.emarginal(function(x) x, spfi.w$marginals.kappa[[1]]) sigmau &lt;- inla.emarginal(function(x) sqrt(x), spfi.w$marginals.variance.nominal[[1]]) range &lt;- inla.emarginal(function(x) x, spfi.w$marginals.range.nominal[[1]]) c(kappa, sigmau, range) ## [1] 1.3384210 0.2835554 2.3743703 これらの値からMatern関数を描画すると以下のようになる。 D &lt;- as.vector(dist(mesh13_2b$loc[,1:2])) d.vec &lt;- seq(0, max(D), length = 100) corM &lt;- (kappa*d.vec)*besselK(kappa*d.vec,1) corM[1] &lt;- 1 data.frame(Distance = d.vec, Correlation = corM) %&gt;% ggplot(aes(x = Distance, y = Correlation))+ geom_line()+ geom_vline(xintercept = range, linetype = &quot;dashed&quot;)+ geom_hline(yintercept = 0.1, linetype = &quot;dashed&quot;)+ coord_cartesian(xlim = c(0,11))+ theme_bw()+ theme(aspect.ratio = 1) 12.6 Simulating from the model 最後に、モデルがデータによく当てはまっているかを確認するため、モデルからデータをシミュレートし、それが実際のデータに合っているかを検討する。モデルからデータをシミュレートするにはcontrol.compute = list(config = TRUE)とする必要がある。 m13_2c &lt;- inla(f13_2b, family = &quot;poisson&quot;, data = inla.stack.data(stack13_2), control.compute = list(config = TRUE), control.predictor = list( A = inla.stack.A(stack13_2))) 続いて、モデルの事後同時分布から各パラメータの値をサンプリングする(第7.5.5.2節を参照)。ここでは試しに1つのみサンプリングする。 set.seed(1234) sim_test &lt;- inla.posterior.sample(n = 1, result = m13_2c) 得られたオブジェクトには、サンプリングされた各データポイントの平均\\(\\mu_i\\)の値(APredictor)や\\(w_k\\)(w)、そして回帰係数などが含まれている。 sim_test[[1]]$latent %&gt;% datatable() サンプリングされた固定効果のパラメータは以下のとおりである。つまり、3634から3641行目までがこれらのパラメータの値がある行である。 sim_test[[1]]$latent %&gt;% data.frame() %&gt;% rownames_to_column(var = &quot;Par&quot;) %&gt;% mutate(n = 1:n()) %&gt;% rename(value = 2) %&gt;% filter(str_detect(Par, c(&quot;Intercept|crcan.st|crlp.std|intervar.std|map.std|age.std|slope.std|tci.std&quot;))) サンプリングされた\\(w_k\\)は以下の通り。2422から3633行目までがこれらのパラメータの値がある行である。 sim_test[[1]]$latent %&gt;% data.frame() %&gt;% rownames_to_column(var = &quot;Par&quot;) %&gt;% mutate(n = 1:n()) %&gt;% rename(value = 2) %&gt;% filter(str_detect(Par, c(&quot;w&quot;))) %&gt;% datatable() %&gt;% formatRound(2, digits = 3) よって、事後同時分布からサンプリングされた値を用いて計算した各ポイント(\\(s_i\\))の平均値\\(\\mu_i\\)の値は以下のように計算できる(\\(log(\\mu_i) = \\bf{X} \\times \\bf{\\beta} + A \\times w\\)より)。 ## 固定効果 beta &lt;- sim_test[[1]]$latent[3634:3641] ## wk w &lt;- sim_test[[1]]$latent[2442:3633] ## muの計算 mu_sim &lt;- exp(as.matrix(X13_2) %*% beta + as.matrix(A13_2) %*% w) なお、inla.posterior.sample(n = 1, result = m13_2c)で得られたオブジェクトの最初の890行はこうした計算をしなくても\\(log(\\mu_i)\\)の値を返してくれる。以下より全く同じ値が得られていることが分かる。 data.frame(mu = mu_sim, mu2 = exp(sim_test[[1]]$latent[1:890])) %&gt;% datatable() %&gt;% formatRound(1:2, digits = 3) 事後同時分布からのサンプリングによって得られた\\(\\mu_i\\)を用いてデータをシミュレートすると、得られる値の分布は以下のようになる。 y_sim &lt;- rpois(n = 890, lambda = mu_sim) data.frame(x = y_sim) %&gt;% ggplot()+ geom_histogram(aes(x = x), size = 0.2)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(0,12,1)) それでは、これと同じことを1000回繰り返して得られた分布と実際のデータの分布を比較することで、モデルがデータによく当てはまっているかを検討しよう。以下に、1000回事後同時分布からサンプリングを行ってシミュレーションをしたときに得られた平均分布と実際のデータの分布を同じ図に示した。 モデルからシミュレートされた値は実データに比べてゼロが多く1が少ないことが分かる。また、実データは9以上のデータがないのに対してシミュレーションでは9以上のデータがある。 post_mu &lt;- matrix(ncol = 1000, nrow = nrow(lp)) y_sim &lt;- matrix(ncol = 1000, nrow = nrow(lp)) ### 1000回シミュレーションを行う。 for(i in 1:1000){ sim &lt;- inla.posterior.sample(n = 1, result = m13_2c) post_mu[ ,i] &lt;- exp(sim[[1]]$latent[1:890]) y_sim[,i] &lt;- rpois(n = 890, lambda = post_mu[,i]) } ### 集計 y_sim %&gt;% data.frame() %&gt;% pivot_longer(1:1000) %&gt;% group_by(value, name) %&gt;% summarise(n = n()) %&gt;% ungroup() %&gt;% group_by(value) %&gt;% summarise(freq = mean(n)) %&gt;% ungroup() %&gt;% mutate(type = &quot;Simulated&quot;) %&gt;% rename(nSIE = value) -&gt; freq_sim lp %&gt;% group_by(nSIE) %&gt;% summarise(freq = n()) %&gt;% ungroup() %&gt;% mutate(type = &quot;Real&quot;)-&gt; freq_data freq_sim %&gt;% bind_rows(freq_data) %&gt;% ggplot(aes(x = nSIE, y = freq))+ geom_col(aes(fill = type), position = position_dodge2(preserve = &quot;single&quot;))+ theme_bw()+ theme(aspect.ratio = 0.8)+ scale_x_continuous(breaks = seq(0,23,1))+ labs(y = &quot;Frequencies&quot;) 12.7 What to write in a paper モデルではまだ残差に空間的な相関が残っていた。これについてさらに詳しく調べるため、バリオグラムを4方向に分割してみた(図12.5)。その結果、北東方向のバリオグラムは他の方角のものよりも強い空間相関を示しているように見える。これは、大きな火山が二つある島の地理的な特徴を反映しているのだろう。 vario13_2b &lt;- variogram(resid ~ 1, data = resid13_2b, cressie = TRUE, cutoff = 10, width = 0.2, alpha = c(0, 45, 90, 135)) %&gt;% mutate(dir = as.factor(dir.hor)) vario13_2b %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point()+ theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,1))+ geom_smooth(color = &quot;black&quot;)+ facet_rep_wrap(~ dir.hor, repeat.tick.labels = TRUE)+ labs(y = &quot;semivariogram&quot;) 図12.5: Sample variogram of the Pearson residuals obtained by the model in Equation (13.2). The panels with the labels ‘0’, ‘45’, ‘90’, and ‘135’ represent the sample variograms in northern, northeastern, eastern, and southeastern directions respectively. This is the same as 180, 225, 270,and 315 degrees respectively. このように、方角によって空間相関のパターンが違うことをanisotropic(異方性)があるという。INLAにはこうした異方性を考慮してMatern関数のパラメータ推定を行うことができる方法も存在する(Lindgren and Rue 2015)。 References "],["Chapter14.html", "13 Time-series analysis in R-INLA 13.1 Simulation study 13.2 Trends in migration dates of sockeye salmon 13.3 Trends in polar bear movements", " 13 Time-series analysis in R-INLA 本章では、INLAで扱える時系列相関を考慮したモデルについて解説する。時系列分析についてより詳しい解説が必要な場合は、他の書籍を参照されたし(e.g., 馬場 2018, 2019; Ravishanker et al. 2022)。 13.1 Simulation study 以下では、シミュレーションデータを用いて話を進める。\\(Y_t\\)を時系列データとし、以下のモデル式をもとに得られるとする。 \\[ \\begin{aligned} &amp;Y_t = \\rm{Intercept} + \\rm{Covariates_i} + \\rm{Trend_t} + \\epsilon_t \\\\ &amp;\\epsilon_t \\sim N(0, \\sigma^2_{\\epsilon}) \\end{aligned} \\] ここでトレンド項(\\(\\rm{Trend_t}\\))が\\(Times \\times \\beta\\)のように表せるとすれば、これは通常の線形回帰モデルである。しかしこの場合、時間的な疑似相関が生じてしまう。この問題を解決するため、いわゆるランダムウォークが用いられる。もっとも単純なランダムウォークモデルは以下のように書ける。10 \\[ \\begin{aligned} &amp;Y_t = \\rm{Intercept} + \\rm{Covariates_i} + \\mu_t + \\epsilon_t \\\\ &amp;\\mu_t = \\mu_{t-1} + v_t\\\\ &amp;\\epsilon_t \\sim N(0, \\sigma^2_{\\epsilon}) \\; and \\; v_t \\sim N(0, \\sigma^2_v) \\end{aligned} \\] このモデルでは、互いに独立な残差\\(\\epsilon_t\\)と\\(v_t\\)がある。以下、これらについて理解するために\\(\\sigma_{\\epsilon}\\)と\\(\\sigma_{v}\\)に様々な値を当てはめたときにシミュレートされる\\(Y_t\\)を図示したのが図13.1である。1行目の3つは\\(\\sigma_{\\epsilon} = 1,\\sigma_v = 1\\)\\(、2行目の3つは\\)\\(\\sigma_{\\epsilon} = 1,\\sigma_v = 0.1\\)\\(、3行目の3つは\\)\\(\\sigma_{\\epsilon} = 5, \\sigma_v = 1\\)\\(、4行目の3つは\\)\\(\\sigma_{\\epsilon} = 1, \\sigma_v = 5\\)\\(、5行目の3つは\\)\\(\\sigma_{\\epsilon} = 3, \\sigma_v = 3\\)である。なお、線は\\(\\mu_t\\)を、点は\\(Y_t\\)を表す。 sigma_e &lt;- rep(c(1,1,5,1,3), each = 3) sigma_v &lt;- rep(c(1, 0.1, 1,5,3), each = 3) set.seed(123) tmax &lt;- 100 Intercept &lt;- 3.2 y &lt;- matrix(ncol = 15, nrow = tmax) mu &lt;- matrix(ncol = 15, nrow = tmax) mu[1, 1:15] &lt;- rnorm(n = 15, mean = 0, sd = 1) y[1, 1:15] &lt;- Intercept + mu[1,1:15] + rnorm(n = 15, mean = 0, sd = sigma_e) for(j in seq_along(sigma_e)){ for(i in 2:100){ mu[i,j] &lt;- mu[i-1,j] + rnorm(n = 1, 0, sigma_v[j]) y[i, j] &lt;- Intercept + mu[i,j] + rnorm(n = 1, 0, sigma_e[j]) } } y %&gt;% data.frame() %&gt;% mutate(time = 1:n()) %&gt;% pivot_longer(1:15) %&gt;% mutate(name = as.numeric(str_replace_all(name, &quot;X&quot;,&quot;&quot;))) %&gt;% ggplot(aes(x = time, y = value))+ geom_point(size = 0.5)+ geom_line(data = mu %&gt;% data.frame() %&gt;% mutate(time = 1:n()) %&gt;% pivot_longer(1:15) %&gt;% mutate(name = as.numeric(str_replace_all(name, &quot;X&quot;,&quot;&quot;))), aes(y = value + Intercept), linewidth = 0.8)+ facet_rep_wrap(~name, scales = &quot;free&quot;, repeat.tick.labels = TRUE, ncol = 3)+ theme_bw()+ theme(aspect.ratio = 0.7)+ labs(y = &quot;Simulated data&quot;) 図13.1: Examples of simulated data sets with different random walk trends. Each of the three panels on the same row represents a different simulation from the same model. The number above a panel is the simulation number. In simulations 1–3 (top row) we used σ ε = 1 and σ v = 1; in simulations 4–6 (second row) we used σ ε = 1 and σ v = 0.1; in simulations 7–9 we used σ ε = 5 and σ v = 1; in simulations 10–12 we used σ ε = 1 and σ v = 5; and in simulations 13–15 we used σ ε = 3 and σ v = 3. この図からは、\\(\\sigma_v\\)が小さいとトレンド項(\\(\\mu_t\\))の変動も小さく、なめらかであることが分かる(e.g., 2行目)。反対に、\\(\\sigma_v\\)が大きいと\\(\\mu_t\\)の変動が大きくなる。一方で、\\(\\sigma_{\\epsilon}\\)は大きいほど\\(Y_t\\)がトレンド項\\(\\mu_t\\)の周りで大きくばらつく。ランダムウォークについてさらに詳しい解説は Durbin and Koopman (2012) や 馬場 (2018) 、馬場 (2019) などを参照。 13.2 Trends in migration dates of sockeye salmon 13.2.1 Applying a random walk trend model 以下では、ベニザケの回遊日を研究した Crozier et al. (2011) のデータを用いる。 salmon &lt;- read_csv(&quot;data/sockeye.csv&quot;) datatable(salmon, options = list(scrollX = 30), filter = &quot;top&quot;) 図13.2は年ごとの回遊日の中央値をプロットしたものである。 salmon %&gt;% ggplot(aes(x = Year, y = MigDay))+ geom_point()+ geom_line()+ theme_bw()+ theme(aspect.ratio = 0.8)+ labs(y = &quot;Migration day&quot;) 図13.2: Time-series plot of (median) arrival day versus year. リサーチクエスチョンは、このデータにトレンドが存在するかである。そこで、以下のランダムウォークモデルを適用する。 \\[ \\begin{aligned} &amp;MigDay_t = \\rm{Intercept} + \\mu_t + \\epsilon_t \\\\ &amp;\\mu_t = \\mu_{t-1} + v_t\\\\ &amp;\\epsilon_t \\sim N(0, \\sigma^2_{\\epsilon}) \\; and \\; v_t \\sim N(0, \\sigma^2_v) \\end{aligned} \\tag{13.1} \\] INLAでは以下のようにモデルを実行できる。 m14_1 &lt;- inla(MigDay ~ f(Year, model = &quot;rw1&quot;), control.compute = list(dic = TRUE), control.predictor = list(compute = TRUE), family = &quot;gaussian&quot;, data = salmon) モデルの推定結果は以下のように求められる。 summary(m14_1) ## ## Call: ## c(&quot;inla.core(formula = formula, family = family, contrasts = contrasts, ## &quot;, &quot; data = data, quantiles = quantiles, E = E, offset = offset, &quot;, &quot; ## scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, ## &quot;, &quot; lp.scale = lp.scale, link.covariates = link.covariates, verbose = ## verbose, &quot;, &quot; lincomb = lincomb, selection = selection, control.compute ## = control.compute, &quot;, &quot; control.predictor = control.predictor, ## control.family = control.family, &quot;, &quot; control.inla = control.inla, ## control.fixed = control.fixed, &quot;, &quot; control.mode = control.mode, ## control.expert = control.expert, &quot;, &quot; control.hazard = control.hazard, ## control.lincomb = control.lincomb, &quot;, &quot; control.update = ## control.update, control.lp.scale = control.lp.scale, &quot;, &quot; ## control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, ## &quot;, &quot; inla.call = inla.call, inla.arg = inla.arg, num.threads = ## num.threads, &quot;, &quot; blas.num.threads = blas.num.threads, keep = keep, ## working.directory = working.directory, &quot;, &quot; silent = silent, inla.mode ## = inla.mode, safe = FALSE, debug = debug, &quot;, &quot; .parent.frame = ## .parent.frame)&quot;) ## Time used: ## Pre = 0.669, Running = 0.533, Post = 0.0676, Total = 1.27 ## Fixed effects: ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## (Intercept) 181.279 0.423 180.447 181.279 182.11 181.279 0 ## ## Random effects: ## Name Model ## Year RW1 model ## ## Model hyperparameters: ## mean sd 0.025quant 0.5quant ## Precision for the Gaussian observations 0.095 0.019 0.064 0.093 ## Precision for Year 3.790 2.685 0.633 3.158 ## 0.975quant mode ## Precision for the Gaussian observations 0.137 0.09 ## Precision for Year 10.634 1.79 ## ## Deviance Information Criterion (DIC) ...............: 326.14 ## Deviance Information Criterion (DIC, saturated) ....: 69.42 ## Effective number of parameters .....................: 6.69 ## ## Marginal log-Likelihood: -187.05 ## is computed ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also &#39;control.compute=list(return.marginals.predictor=TRUE)&#39;) トレンド項\\(\\mu_t\\)は時間とともに変化するランダム効果であり、その情報は以下で確認できる。 m14_1$summary.random$Year 図示すると以下のようになる。 m14_1$summary.random$Year %&gt;% rename(Year = ID) %&gt;% ggplot(aes(x = Year, y = mean))+ geom_line()+ geom_ribbon(aes(ymax = `0.025quant`, ymin = `0.975quant`), alpha = 0, color = &quot;black&quot;, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Random walk trend&quot;) 切片も足した予測値は以下のように求められる。 m14_1$summary.fitted.values %&gt;% bind_cols(salmon) %&gt;% ggplot(aes(x = Year, y = mean))+ geom_line()+ geom_ribbon(aes(ymax = `0.025quant`, ymin = `0.975quant`), alpha = 0, color = &quot;black&quot;, linetype = &quot;dashed&quot;)+ geom_point(aes(y = MigDay), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Observed and fitted values&quot;) 13.2.2 Posterior distribution of sigmas INLAは精度\\(\\tau = 1/\\sigma^2\\)を推定するので、\\(\\sigma_{\\epsilon}\\)と\\(\\sigma_v\\)の事後分布を求めるためには以下のような変換が必要である。それぞれの事後平均は以下のように求められる。 tau_eps &lt;- m14_1$marginals.hyperpar$`Precision for the Gaussian observations` tau_v &lt;- m14_1$marginals.hyperpar$`Precision for Year` fun &lt;- function(x){1/sqrt(x)} sigma_eps &lt;- inla.emarginal(fun, tau_eps) sigma_v &lt;- inla.emarginal(fun, tau_v) c(sigma_eps, sigma_v) ## [1] 3.2863230 0.6197087 事後分布は以下のように書ける。 pd_sigma_eps &lt;- inla.tmarginal(fun, tau_eps) pd_sigma_v &lt;- inla.tmarginal(fun, tau_v) pd_sigma_eps %&gt;% data.frame() %&gt;% mutate(par = &quot;sigma_eps&quot;) %&gt;% bind_rows(pd_sigma_v %&gt;% data.frame() %&gt;% mutate(par = &quot;sigma_v&quot;)) %&gt;% ggplot(aes(x = x, y = y))+ geom_line()+ facet_rep_wrap(~par, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ labs(x = &quot;&quot;)+ theme_bw()+ theme(aspect.ratio = 1) 13.2.3 Covariates and trends 式(13.1)のモデルは以下のように説明変数を加えて簡単に拡張できる。ここでは、気温(\\(Temp_t\\))を加える。 \\[ \\begin{aligned} &amp;MigDay_t = \\rm{Intercept} + Temp_t \\times \\beta + \\mu_t + \\epsilon_t \\\\ &amp;\\mu_t = \\mu_{t-1} + v_t\\\\ &amp;\\epsilon_t \\sim N(0, \\sigma^2_{\\epsilon}) \\; and \\; v_t \\sim N(0, \\sigma^2_v) \\end{aligned} \\tag{13.2} \\] このモデルは以下のように実行できる。 f14_2 &lt;- MigDay ~ Temp + f(Year, model = &quot;rw1&quot;) m14_2 &lt;- inla(f14_2, control.compute = list(dic = TRUE), control.predictor = list(compute = TRUE), family = &quot;gaussian&quot;, data = salmon) 先ほどのモデルと比べると、気温を共変量に加えたモデルの方がDICが低い。 c(m14_1$dic$dic, m14_2$dic$dic) ## [1] 326.1440 321.0941 また、気温にかかる係数の95%確信区間は0を含まないので、応答変数に重要な影響を与えていることが示唆される。 m14_2$summary.fixed 13.2.4 Making the trend smoother \\(\\sigma_v\\)の事前分布を変えたとき、トレンド項\\(\\mu_t\\)の事後分布は大きな影響を受ける。以下、このことをシミュレーションによって確認する。 13.2.4.1 Changing the values of the gamma prior INLAでは\\(\\tau_v = 1/\\sigma_v^2\\)の事前分布はデフォルトでは\\(Gamma(1, 0.00001)\\)になっている(第8章参照)。しかし、個の分布が最善かには議論がある。第8章では、 事前分布に\\(Gamma(1, 0.5)\\)を用いたモデルも実行した。この事前分布は、 Carroll et al. (2015) によって推奨されているものである。この事前分布の下では、\\(\\sigma_v\\)はおよそ0から5までの値をとる。 INLAでは、以下のようにしてこの事前分布によるモデルを実行できる。 f14_3 &lt;- MigDay ~ Temp + f(Year, model = &quot;rw1&quot;, hyper = list(theta = list(prior = &quot;loggamma&quot;, param = c(1,0.5)))) m14_3 &lt;- inla(f14_3, control.compute = list(dic = TRUE), control.predictor = list(compute = TRUE), family = &quot;gaussian&quot;, data = salmon) Blangiardo and Cameletti (2015) は、\\(\\sigma_v\\)がとりうる範囲について事前に知識があれば、それをもとに事前分布のパラメータを検討することができることを示している。例えば、仮に\\(\\sigma_v\\)が0.3から0.7の範囲をとりうると分かっているとしよう。このとき、シミュレーションによって\\(\\sigma_v\\)を10000個生成する。 set.seed(1234) sim.sigma_v &lt;- runif(n = 10000, 0.3,0.7) このとき、\\(\\tau_v\\)の分布は以下のようになる。 sim.tau_v &lt;- 1/sim.sigma_v^2 data.frame(x = sim.tau_v) %&gt;% ggplot(aes(x = x))+ geom_density()+ theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(xlim = c(1,12)) ガンマ分布はshape(\\(a\\))とscale(\\(b\\))の2つのパラメータによって決まるが、これらはガンマ分布の期待値\\(E(X)\\)と分散\\(var(X)\\)を用いて以下のように表せる。 \\[ \\begin{aligned} &amp;a = E(X)^2/var(X)\\\\ &amp;b = a/E(X) \\end{aligned} \\] よって、\\(\\tau_v\\)がガンマ分布に従うとしたらパラメータ\\(a,b\\)は以下の値になる。 a &lt;- mean(sim.tau_v)^2/var(sim.tau_v) b &lt;- a/mean(sim.tau_v) c(a, b) ## [1] 3.9710889 0.8359842 これらのパラメータを持つガンマ分布を実際の\\(\\tau_v\\)の分布と一緒に描くと以下のようになる。おおよそ一致していることが見て取れる。 gamma &lt;- rgamma(n =10000, shape = a, scale = b) data.frame(x = c(sim.tau_v, gamma), type = rep(c(&quot;tau&quot;,&quot;gamma&quot;), each = 10000)) %&gt;% ggplot(aes(x = x, group = type))+ geom_density(aes(linetype = type))+ scale_linetype_manual(values = c(&quot;dashed&quot;,&quot;solid&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(xlim = c(0,12)) 13.2.4.2 changing the gamma prior to the PC prior Simpson et al. (2014) はPenalized Complexity (PC) 事前分布というものを導入している。この事前分布では、1つのパラメータを用いて事前分布の強弱を表現できる。例えば\\(\\sigma_v\\)のPC事前分布を考えるとき、以下の式に用いる\\(U\\)を決める必要がある。\\(\\alpha\\)には0.05を用いる。 \\[ Prob(\\sigma_v &gt; U) = \\alpha \\] 例えば\\(U = 100\\)とするとき、\\(\\sigma_v\\)が100以上の大きな値をとる確率は非常に小さいということを示す。このとき、事前分布はほとんど情報を持っていない。一方で、\\(U = 0.1\\)とするならば、\\(\\sigma_v\\)は高い確率で0から0.1までの値をとることになり、事前分布は情報があるとみなせる。 以下では、様々な\\(U\\)を定めたときの\\(\\tau_v\\)の分布を描いたものである。密度の算出については Simpson et al. (2014) を参照。\\(U\\)が大きいほど\\(\\sigma_v\\)がとりうる範囲も大きくなるので、逆に\\(\\tau_v\\)は非常に狭い分布になる。逆もしかりである。 U &lt;- c(0.1, 0.5, 1, 2, 5) alpha &lt;- 0.05 DensTau &lt;- matrix(nrow = 100, ncol = 5) for (i in 1:5){ lambda &lt;- - log(alpha) / U[i] tau.v &lt;- seq(0.001, 12, length = 100) DensTau[,i] &lt;- (lambda / 2) * tau.v ^(-3/2) * exp(-lambda*tau.v^(-0.5)) } data.frame(x = tau.v, y = as.vector(DensTau), U = rep(U, each = 100)) %&gt;% mutate(U = str_c(&quot;U = &quot;,U)) %&gt;% ggplot(aes(x = x, y = y))+ geom_line()+ facet_rep_wrap(~U, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Density&quot;, x = expression(tau[v])) INKAでは以下のようにPC事前分布を用いた分析ができる。以下では、\\(U\\)が6つの値(\\(0.01, 0.05, 0.1, 0.5, 1, 5\\))をとるときそれぞれのモデルを実行している。 U &lt;- c(0.01, 0.05, 0.1, 0.5, 1, 5) keys &lt;- paste0(&quot;m14_4_&quot;, 1:6) for(i in 1:6){ hyper.prec &lt;- list(theta = list(prior = &quot;pc.prec&quot;, param = c(U[[i]], 0.05))) f14_4 &lt;- MigDay ~ f(Year, model = &quot;rw1&quot;, hyper = hyper.prec) m14_4 &lt;- inla(f14_4, control.compute = list(dic = TRUE), control.predictor = list(compute = TRUE), family = &quot;gaussian&quot;, data = salmon) assign(keys[i], m14_4) } \\(U\\)の値によってモデルの予測値(\\(\\rm{Intercept + \\mu_t}\\))がどう変わるかを示したのが図13.3である。\\(U\\)の値が小さいと\\(\\sigma_v\\)も0に近い値しか取らないので、予測値がほぼ変動しないことが分かる。一方で、\\(U\\)が一定以上大きければ結果はあまり変わらない。 m14_4_1$summary.fitted.values %&gt;% bind_rows(m14_4_2$summary.fitted.values) %&gt;% bind_rows(m14_4_3$summary.fitted.values) %&gt;% bind_rows(m14_4_4$summary.fitted.values) %&gt;% bind_rows(m14_4_5$summary.fitted.values) %&gt;% bind_rows(m14_4_6$summary.fitted.values) %&gt;% mutate(Year = rep(salmon$Year, times = 6)) %&gt;% mutate(U = rep(str_c(&quot;U = &quot;, U), each = 61)) %&gt;% ggplot(aes(x = Year, y = mean))+ geom_line()+ geom_ribbon(aes(ymax = `0.025quant`, ymin = `0.975quant`), alpha = 0.5, color = &quot;black&quot;, linetype = &quot;dashed&quot;)+ geom_point(aes(y = MigDay), shape = 1, data = salmon)+ facet_rep_wrap(~U, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Migration date&quot;) 図13.3: Fitted values for the rw1 model applied on the salmon arrival dates data. A PC prior was used for the precision parameter τ v of the variance of the random walk. Each panel corresponds to a different value of U. 13.2.4.3 Changing the random walk model: rw2 INLAにはこれまで用いてきたランダムウォークモデルrw1に加えてもう一つのランダムウォークモデルrw2``がある。これは、以下のように書ける[^foot11]。rw2`モデルではこれまで用いていたランダムモデルよりも滑らかな予測値が得られる。 \\[ \\begin{aligned} &amp;(\\mu_t - \\mu_{t-1}) - (\\mu_{t-1} - \\mu_{t-2}) = v_t \\\\ &amp;v_t \\sim N(0,\\sigma^2_v) \\end{aligned} \\] これは、\\(\\phi_t = \\mu_t - \\mu_{t-1}\\)と書くとき、以下のように書き換えられる。 \\[ \\begin{aligned} &amp;\\phi_t - \\phi_{t-1} = v_t \\\\ &amp;v_t \\sim N(0,\\sigma^2_v) \\end{aligned} \\] 13.3 Trends in polar bear movements 以下では、シロクマの自発的あるいは受動的な移動を分析した (Mauritzen2003?) のデータを用いる。1988年から1999年の間に、86頭のオトナのメスの位置情報がテレメトリーによって記録された。テレメトリーは6日ごとに最大3年間位置情報を記録した。記録は2つの場所(スバールバル諸島とバレンツ海)で行われている。 References "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] parallel graphics grDevices utils datasets stats methods ## [8] base ## ## other attached packages: ## [1] rgdal_1.6-7 ggmap_3.0.2 plotly_4.10.1 ## [4] viridis_0.6.4 car_3.1-2 carData_3.0-5 ## [7] posterior_1.4.1 fields_15.2 viridisLite_0.4.2 ## [10] spam_2.9-1 lemon_0.4.6 ggsci_2.9 ## [13] kableExtra_1.3.4 DT_0.27 patchwork_1.1.2 ## [16] ggrepel_0.9.2 GGally_2.1.2 ggnewscale_0.4.9 ## [19] geoR_1.9-2 gt_0.9.0 bayesplot_1.10.0 ## [22] ggeffects_1.1.4 cmdstanr_0.5.3 rstan_2.26.23 ## [25] StanHeaders_2.26.28 brms_2.18.0 Rcpp_1.0.11 ## [28] gstat_2.1-1 gamm4_0.2-6 lme4_1.1-34 ## [31] mgcv_1.8-41 nlme_3.1-160 INLA_23.04.24 ## [34] foreach_1.5.2 Matrix_1.6-1 NipponMap_0.2 ## [37] sf_1.0-14 sp_1.5-1 fontregisterer_0.3 ## [40] systemfonts_1.0.4 extrafont_0.18 data.table_1.14.6 ## [43] see_0.7.5.5 report_0.5.7.4 parameters_0.20.3 ## [46] performance_0.10.3 modelbased_0.8.6.3 insight_0.19.1.4 ## [49] effectsize_0.8.3.6 datawizard_0.7.1.1 correlation_0.8.4 ## [52] bayestestR_0.13.1 easystats_0.6.0.8 scales_1.2.1 ## [55] lubridate_1.9.2 forcats_1.0.0 stringr_1.5.0 ## [58] dplyr_1.1.2 purrr_1.0.2 readr_2.1.4 ## [61] tidyr_1.3.0 tibble_3.2.1 ggplot2_3.4.3 ## [64] tidyverse_2.0.0 MASS_7.3-58.1 knitr_1.44 ## ## loaded via a namespace (and not attached): ## [1] utf8_1.2.2 tidyselect_1.2.0 htmlwidgets_1.6.2 ## [4] grid_4.2.2 munsell_0.5.0 codetools_0.2-18 ## [7] units_0.8-1 miniUI_0.1.1.1 withr_2.5.0 ## [10] Brobdingnag_1.2-9 colorspace_2.0-3 rstudioapi_0.15.0 ## [13] stats4_4.2.2 Rttf2pt1_1.3.12 labeling_0.4.3 ## [16] emmeans_1.8.8 RgoogleMaps_1.4.5.3 splancs_2.01-44 ## [19] bit64_4.0.5 farver_2.1.1 bridgesampling_1.1-2 ## [22] coda_0.19-4 vctrs_0.6.3 generics_0.1.3 ## [25] TH.data_1.1-2 xfun_0.39 timechange_0.1.1 ## [28] R6_2.5.1 markdown_1.8 bitops_1.0-7 ## [31] cachem_1.0.6 reshape_0.8.9 vroom_1.6.0 ## [34] promises_1.2.0.1 multcomp_1.4-25 gtable_0.3.4 ## [37] processx_3.8.0 sandwich_3.0-2 MatrixModels_0.5-2 ## [40] rlang_1.1.1 splines_4.2.2 lazyeval_0.2.2 ## [43] extrafontdb_1.0 checkmate_2.1.0 inline_0.3.19 ## [46] yaml_2.3.7 reshape2_1.4.4 abind_1.4-5 ## [49] threejs_0.3.3 crosstalk_1.2.0 backports_1.4.1 ## [52] httpuv_1.6.7 tensorA_0.36.2 tools_4.2.2 ## [55] tcltk_4.2.2 bookdown_0.35 ellipsis_0.3.2 ## [58] jquerylib_0.1.4 RColorBrewer_1.1-3 proxy_0.4-27 ## [61] plyr_1.8.8 base64enc_0.1-3 classInt_0.4-8 ## [64] ps_1.7.2 prettyunits_1.1.1 zoo_1.8-11 ## [67] magrittr_2.0.3 spacetime_1.3-0 colourpicker_1.3.0 ## [70] mvtnorm_1.1-3 matrixStats_0.63.0 archive_1.1.5 ## [73] hms_1.1.3 shinyjs_2.1.0 mime_0.12 ## [76] evaluate_0.21 xtable_1.8-4 shinystan_2.6.0 ## [79] jpeg_0.1-10 gridExtra_2.3 rstantools_2.3.1.1 ## [82] compiler_4.2.2 maps_3.4.1 KernSmooth_2.23-20 ## [85] crayon_1.5.2 minqa_1.2.5 htmltools_0.5.4 ## [88] later_1.3.0 tzdb_0.3.0 RcppParallel_5.1.6 ## [91] DBI_1.1.3 boot_1.3-28 cli_3.6.1 ## [94] dotCall64_1.0-2 igraph_1.3.5 pkgconfig_2.0.3 ## [97] xml2_1.3.5 svglite_2.1.1 dygraphs_1.1.1.6 ## [100] QuickJSR_1.0.5 bslib_0.5.1 webshot_0.5.5 ## [103] estimability_1.4.1 rvest_1.0.3 distributional_0.3.2 ## [106] callr_3.7.3 digest_0.6.31 rmarkdown_2.24 ## [109] intervals_0.15.4 Deriv_4.1.3 shiny_1.7.5 ## [112] gtools_3.9.4 nloptr_2.0.3 lifecycle_1.0.3 ## [115] jsonlite_1.8.4 fansi_1.0.3 pillar_1.9.0 ## [118] lattice_0.20-45 loo_2.6.0 httr_1.4.7 ## [121] fastmap_1.1.1 pkgbuild_1.4.2 survival_3.5-5 ## [124] glue_1.6.2 xts_0.12.2 FNN_1.1.3.2 ## [127] png_0.1-8 shinythemes_1.2.0 iterators_1.0.14 ## [130] bit_4.0.5 class_7.3-20 stringi_1.7.12 ## [133] sass_0.4.5 e1071_1.7-12 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
