[["index.html", "Introduction to spatial-temporal data anlysis using R 本稿の目的", " Introduction to spatial-temporal data anlysis using R Tsubasa Yamaguchi 2023-09-15 本稿の目的 本稿は、時空間相関を考慮したGLM/GLMMをRで実装する方法を解説する。 生態学のデータでは、データに非独立性が存在することが多くある(第1章)。多くの統計分析はデータが互いに独立であることを仮定しているので、こうした非独立性を考慮せずにを行ってしまうと誤った結論を導いてしまうことになりかねない。本稿では、特に時間的・空間的な相関があることでデータに非独立性がある場合に、どのようにそれに対処するべきかを解説する。本稿では、特にGLMやGLMM(Zuur et al. 2013)による分析を扱う。 本稿は主に Alain Zuurによる”Zuur, A. F. (2017). Beginner’s Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-Inla: Using Glm and Glmm Volume I”(Zuur 2017)を基に執筆している。本書はなるべく数学的な説明を省きつつ、実際の生態学のデータを用いて時空間を考慮したGLM/GLMMについて間接している本である。 その他には、以下の本も参考にした。 Mixed effects models and extensions in ecology with R (Zuur 2009) Rで始める地理空間データの統計解析入門 (村上 2022) Rとstanではじめるベイズ統計モデリングによるデータ分析入門 (馬場 2019) 時系列分析と状態空間モデルの基礎 : RとStanで学ぶ理論と実装 (馬場 2018) References "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham and Grolemund 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al. 2021) 出版社サイト 使用するパッケージは以下のとおりである。 ## データハンドリング library(knitr) library(MASS) library(tidyverse) library(scales) library(easystats) library(data.table) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) ## 地理データ library(sp) library(sf) library(NipponMap) ## モデリング library(INLA) library(mgcv) library(gamm4) library(nlme) library(gstat) library(brms) library(rstan) library(cmdstanr) library(ggeffects) ## グラフや表関連 library(bayesplot) library(gt) library(geoR) library(ggnewscale) library(GGally) library(ggrepel) library(patchwork) library(DT) library(kableExtra) library(ggsci) library(lemon) References "],["Chapter2.html", "1 Recognizing statistical dependency 1.1 Pseudoreplication 1.2 Linear regression applied to spatial data 1.3 GAM applied to temporal data", " 1 Recognizing statistical dependency 1.1 Pseudoreplication 1.1.1 疑似反復とは 疑似反復(pseudoreplication)とは、応答変数のデータが独立ではないにもかかわらず、統計解析にそのことが考慮されていないことを指す。多くの統計解析は全てのデータが独立であることを仮定しているので、もし疑似反復が生じている状態で分析を行うと正しい結果が得られないことが多い。 疑似反復の典型的な例としては、同じ個体から複数のデータが得られている場合が挙げられる。例えば、ある治療薬の効果を調べる場合、各患者について治療前のデータと治療薬を飲んだ後のデータを収集する。もし100人分データを収集するとすれば200個のデータが集まるが、これらのデータが独立であると考えることはできない。なぜなら、同じ患者のデータはその患者特有の属性など(年齢、性別、あるいは観測できない要因など)によって他の患者のデータよりも類似している可能性が高くなるからである。もし独立であると仮定して分析を行うと、実際よりもデータの標準誤差が小さく推定されてしまい、第一種の過誤を犯しやすくなってしまう。 他にも、例えば10個の植木鉢にそれぞれ5個ずつ種子を植えて、その成長度合いを調べる場合を考えてみよう。このとき、合計50個のデータが得られるが、同じ植木鉢に植えられた種子のデータを独立であると考えることはできない。なぜなら、同じ植木鉢の種子はその植木鉢特有の属性(土中の栄養分、日照度合い、あるいは観測できない要因など)によって、他の植木鉢の種子のデータよりも類似している可能性が高くなるからである。 こうした疑似反復に対処するためのアプローチは、混合モデルと呼ばれるものを適用することである(Zuur et al. 2013)。 1.1.2 時空間的な疑似反復 上記のような疑似反復の他にも、時間的あるいは空間的な疑似反復が生じることがある。例えば、あるニホンザルの群れで発情しているメスの数を毎日記録するとしよう。このとき、時間的に近い日のデータ同士はそうでないデータ同士よりも類似する確率が高い。なぜなら、ある日発情していたメスは、その次の日も発情している可能性が高いからである。 図1.1は実際に宮城県金華山島で収集された発情メス数のデータである。実際に、近い日は類似した値をとることが多いことが分かる。このように、時系列データは互いに独立していないことが多い。こうした時間的な疑似相関を考慮せずに分析を行ってしまう(e.g., 毎日の発情メス数が気温によって変わるかを調べるなど)と、誤った結論を導いてしまいかねない。 daily_data &lt;- read_csv(&quot;data/daily_data_2021.csv&quot;) daily_data %&gt;% filter(duration &gt;= 300) %&gt;% ggplot(aes(x = date))+ geom_line(aes(y = no_est))+ scale_x_date(date_breaks = &quot;1 week&quot;)+ scale_y_continuous(breaks = seq(0,16,2))+ theme_bw(base_size=15)+ theme(axis.text.x = element_text(angle=30, hjust=1), axis.title.y = element_text(angle = 0, vjust = 0.5), aspect.ratio=0.5, legend.position = c(0.2,0.9), legend.text = element_text(size=10.5, family = &quot;Yu Mincho&quot;), axis.text = element_text(family = &quot;Times New Roman&quot;))+ labs(x = &quot;&quot;, y = &quot;発\\n情\\nメ\\nス\\n数&quot;)+ guides(linetype = guide_legend(title=NULL)) 図1.1: 2021年の金華山島B1群における各観察日の発情メス数 地理空間データについても同様のことがいえる。例えば、日本の各都道府県における納豆の消費量について分析するとする(データはこちらから)。このとき、各都道府県のデータを独立と考えることはできない。なぜなら、地理的に近い都道府県は食文化や気候などが類似しており、納豆の消費量も類似している可能性が高くなるからである。 実際、地図上に納豆消費量を図示すると(図1.2)、地理的に近い県は納豆の消費量も類似していることが分かる。このように、空間的データについてもデータ同士に非独立性が生じやすい。 natto &lt;- read_csv(&quot;data/natto.csv&quot;) gyuniku &lt;- read_csv(&quot;data/gyuniku.csv&quot;) shp &lt;- system.file(&quot;shapes/jpn.shp&quot;, package = &quot;NipponMap&quot;)[1] pref &lt;- read_sf(shp) %&gt;% rename(prefecture = name) natto %&gt;% left_join(gyuniku) %&gt;% left_join(pref) -&gt; japan_data japan_data %&gt;% filter(prefecture != &quot;Okinawa&quot;) %&gt;% ggplot()+ geom_sf(aes(geometry = geometry, fill = natto))+ theme_void()+ theme(aspect.ratio = 1)+ scale_fill_gradient2(high = muted(&quot;blue&quot;), low = muted(&quot;red&quot;), mid = &quot;white&quot;, midpoint = 3700)+ labs(fill = &quot;納豆消費量(円)&quot;) 図1.2: 各都道府県の納豆消費量(円) こうした空間的な疑似反復を考慮せずに分析を行ってしまうと、誤った結論を導いてしまうことになる。例えば、各都道府県の納豆消費量と牛肉消費量が関連しているかを分析するとしよう。図1.3は両者の関連をプロットしたものであるが、プロットだけを見ると両社は強い負の相関を持つように見える(実際、相関係数は-0.737。しかし、先ほど見たように各都道府県のデータは独立ではないので、空間的な非独立性を考慮した分析を行わなければいけない。空間的相関を考慮した分析を行うと、両者の関連はなくなる(こちらを参照)。 japan_data %&gt;% ggplot(aes(x = gyuniku, y = natto))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;納豆消費量(円)&quot;, x = &quot;牛肉消費量(g)&quot;) 図1.3: 各都道府県の納豆消費量と牛肉消費量 1.2 Linear regression applied to spatial data 本節では、Cruikshanks et al. (2006) のデータを用いる。この研究では、アイルランドの257の川において、川のpHがSDI(Sodium Dominance Index; 陽イオン中のナトリウムイオン)と関連しているかを、緯度(Altitude)やその場所が森林化されているか(Forested)も考慮したうえで調べている。 1.2.1 Visualization データは以下の通り。 iph &lt;- read_delim(&quot;data/Irishph.txt&quot;) %&gt;% mutate(fForested = ifelse(Forested == &quot;1&quot;, &quot;yes&quot;, &quot;no&quot;)) %&gt;% data.frame() datatable(iph, options = list(scrollX = 20), filter = &quot;top&quot;) 各説明変数との関連は以下の通り。 iph %&gt;% dplyr::select(Altitude, pH, fForested, SDI) %&gt;% pivot_longer(cols = c(Altitude, SDI)) %&gt;% ggplot(aes(x = value, y = pH))+ geom_point(aes(color = fForested))+ geom_smooth(aes(color = fForested), method = &quot;lm&quot;)+ facet_rep_wrap(~ name, scales = &quot;free_x&quot;, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Covariates&quot;) 1.2.2 Dependency 以下の線形モデルを適用するとする。 \\[ \\begin{aligned} pH_i &amp;\\sim N(0,\\sigma^2)\\\\ \\mu_i &amp;= \\beta_1 + \\beta_2 \\times SDI_i\\\\ \\end{aligned} \\] 結果を図示すると以下のようになる。 m2_1 &lt;- lm(pH ~ SDI, data = iph) 濃く塗りつぶした部分が95%信頼区間、薄く塗りつぶした部分が95%予測区間である。 ggpredict(m2_1, terms = &quot;SDI[7:72,by=0.1]&quot;, interval = &quot;prediction&quot;) %&gt;% data.frame() %&gt;% mutate(type = &quot;prediction&quot;) %&gt;% bind_rows(ggpredict(m2_1, terms = &quot;SDI[7:72,by=0.1]&quot;, interval = &quot;confidence&quot;) %&gt;% data.frame() %&gt;% mutate(type = &quot;confidence&quot;)) %&gt;% rename(SDI = x) %&gt;% ggplot(aes(x = SDI, y = predicted))+ geom_ribbon(aes(ymin = conf.high, ymax = conf.low, fill = type), alpha = 0.5)+ scale_fill_grey()+ geom_line()+ geom_point(data = iph, aes(y = pH), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1) 1.2.3 Fit the model 次に、全部の交互作用を含むモデルを考える。 iph %&gt;% mutate(logAltitude = log(Altitude,10)) -&gt; iph m2_2 &lt;- lm(pH ~ SDI*fForested*logAltitude, data = iph) 結果は以下の通り。 summary(m2_2) ## ## Call: ## lm(formula = pH ~ SDI * fForested * logAltitude, data = iph) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.94554 -0.18644 -0.01226 0.21667 1.13820 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.250624 0.765918 10.772 &lt;2e-16 *** ## SDI -0.028011 0.017190 -1.630 0.105 ## fForestedyes 1.794536 2.070682 0.867 0.387 ## logAltitude 0.106199 0.390728 0.272 0.786 ## SDI:fForestedyes -0.008168 0.037112 -0.220 0.826 ## SDI:logAltitude 0.001764 0.008614 0.205 0.838 ## fForestedyes:logAltitude -0.885493 1.012152 -0.875 0.383 ## SDI:fForestedyes:logAltitude 0.003573 0.017939 0.199 0.842 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3756 on 202 degrees of freedom ## Multiple R-squared: 0.5675, Adjusted R-squared: 0.5525 ## F-statistic: 37.86 on 7 and 202 DF, p-value: &lt; 2.2e-16 あまりに煩雑なのでAICによるモデル選択を行う。 stepAIC(m2_2) ## Start: AIC=-403.47 ## pH ~ SDI * fForested * logAltitude ## ## Df Sum of Sq RSS AIC ## - SDI:fForested:logAltitude 1 0.0055954 28.498 -405.43 ## &lt;none&gt; 28.492 -403.47 ## ## Step: AIC=-405.43 ## pH ~ SDI + fForested + logAltitude + SDI:fForested + SDI:logAltitude + ## fForested:logAltitude ## ## Df Sum of Sq RSS AIC ## - SDI:fForested 1 0.00454 28.503 -407.39 ## - SDI:logAltitude 1 0.01654 28.515 -407.31 ## &lt;none&gt; 28.498 -405.43 ## - fForested:logAltitude 1 1.01027 29.508 -400.11 ## ## Step: AIC=-407.39 ## pH ~ SDI + fForested + logAltitude + SDI:logAltitude + fForested:logAltitude ## ## Df Sum of Sq RSS AIC ## - SDI:logAltitude 1 0.01443 28.517 -409.29 ## &lt;none&gt; 28.503 -407.39 ## - fForested:logAltitude 1 1.08368 29.586 -401.56 ## ## Step: AIC=-409.29 ## pH ~ SDI + fForested + logAltitude + fForested:logAltitude ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 28.517 -409.29 ## - fForested:logAltitude 1 1.2837 29.801 -402.04 ## - SDI 1 29.3674 57.884 -262.62 ## ## Call: ## lm(formula = pH ~ SDI + fForested + logAltitude + fForested:logAltitude, ## data = iph) ## ## Coefficients: ## (Intercept) SDI fForestedyes ## 8.10382 -0.02461 1.29402 ## logAltitude fForestedyes:logAltitude ## 0.18292 -0.65962 AICが最小のモデルは以下の通り。 m2_3 &lt;- lm(pH ~ SDI + logAltitude*fForested, data = iph) 1.2.4 Model validation 1.2.4.1 Check homogeinity and model misfit モデル診断を行う。標準化残差と予測値、各共変量の関係は特にパターンが見られず、問題ないよう。 resid &lt;- rstandard(m2_3) data.frame(resid = resid, fitted = predict(m2_3)) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) iph %&gt;% mutate(resid = resid) %&gt;% select(resid, SDI, logAltitude) %&gt;% pivot_longer(cols = c(SDI, logAltitude)) %&gt;% ggplot(aes(x = value, y = resid))+ geom_point(shape = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ labs(x = &quot;&quot;) iph %&gt;% mutate(resid = resid) %&gt;% select(resid, fForested) %&gt;% ggplot(aes(x = fForested, y = resid))+ geom_boxplot()+ theme_bw()+ theme(aspect.ratio = 1) 1.2.5 Check spatial dependence 地理的空間上に残差を図示してもパターンがあるかはわかりにくい。 iph %&gt;% mutate(resid = resid) %&gt;% ggplot(aes(x = Easting, y = Northing))+ geom_point(shape = 21, aes(fill = resid &gt;= 0, size = abs(resid)))+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ theme_bw()+ theme(aspect.ratio = 1) 図1.4: Residuals plotted versus spatial position. The width of a point is proportional to the (absolute) value of a residual. Filled circles are positive residuals and open circles are negative residuals. It would be useful to add the contour lines of the Irish borders. そこで、バリオグラムを作成する。 バリオグラムではまず、データ間の距離がある特定の範囲内にあるデータのペアを抽出する。例えば、図1.5は10kmずつに区切った範囲内にある2つのデータをつないだものである。そのうえで、ある距離範囲カテゴリ(e.g., 10km &lt; dist &lt; 20km)において各データペアの残差の差の二乗を平均したものを算出する。これを全距離範囲カテゴリについて行い、それを図示したものをバリオグラムという。なお、各範囲カテゴリには、少なくとも100ペアくらいはあった方がよい。 crossing(ID1 = iph$ID, ID2 = iph$ID) %&gt;% left_join(iph %&gt;% select(ID,Easting, Northing), by = c(&quot;ID1&quot; = &quot;ID&quot;)) %&gt;% rename(Easting1 = Easting, Northing1 = Northing) %&gt;% left_join(iph %&gt;% select(ID,Easting, Northing), by = c(&quot;ID2&quot; = &quot;ID&quot;)) %&gt;% rename(Easting2 = Easting, Northing2 = Northing) %&gt;% filter(ID1 != ID2) %&gt;% mutate(dist = sqrt((Easting1 - Easting2)^2 + (Northing1 - Northing2)^2)/1000) %&gt;% mutate(cat = ifelse(dist &lt; 10, &quot;Distances &lt; 10 km&quot;, ifelse(dist &lt; 20, &quot;10 km &lt; Distances &lt; 20 km&quot;, ifelse(dist &lt; 30, &quot;20 km &lt; Distances &lt; 30 km&quot;, ifelse(dist &lt; 40, &quot;30 km &lt; Distances &lt; 40 km&quot;, &quot;NA&quot;))))) %&gt;% mutate(cat2 = ifelse(dist &lt; 40, 1, ifelse(dist &lt; 30, 2, ifelse(dist &lt; 20, 3, ifelse(dist &lt; 10, 4, &quot;NA&quot;))))) %&gt;% filter(cat != &quot;NA&quot;) %&gt;% mutate(cat = fct_relevel(cat, &quot;Distances &lt; 10 km&quot;)) %&gt;% ggplot()+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;1&quot;))+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;2&quot;))+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;3&quot;))+ geom_segment(aes(x = Easting1, xend = Easting2, y = Northing1, yend = Northing2), data = . %&gt;% filter(cat2 == &quot;4&quot;))+ facet_rep_wrap(~cat, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Easting&quot;, y = &quot;Northing&quot;) 図1.5: Each panel shows c ombinations of any two sampling locations with distances of certain threshold values. もしデータに空間的な相関がないのであれば、距離の範囲カテゴリに関わらずデータペアの残差の差の平均は一定になるはずである(= バリオグラムはx軸と平行になる)。一方で、例えば空間的に近いデータほど似た残差をとるのであれば、近い距離範囲カテゴリではデータペアの残差の差の平均が小さくなる。 Rでは以下のように実行できる。cressie = TRUEとすることで推定がより頑強になり、外れ値の影響を小さくすることができる。npは各距離範囲カテゴリのデータ数を、distはそれぞれの距離カテゴリーにおけるデータ間の平均距離、gammaは計算されたバリオグラムの値を表す。明らかにプロットは一定の値をとっておらず、強い空間相関があることが予想される(図1.6)。 vario_2_3 &lt;- data.frame(resid = rstandard(m2_3), Easting.km = iph$Easting/1000, Northing.km = iph$Northing/1000) sp::coordinates(vario_2_3) &lt;- c(&quot;Easting.km&quot;, &quot;Northing.km&quot;) vario_2_3 %&gt;% variogram(resid ~ 1, data = ., cressie = TRUE, ## 距離が150km以下のデータのみ使用 cutoff = 150, ## 各距離範囲カテゴリの範囲 width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;semivariogram&quot;) 図1.6: m2_3のバリオグラム 南北方向と東西方向の距離を分けて調べることもできる。特に東西方向では明確にバリオグラムが水平ではなく、空間的な独立性がないことが分かる。 vario_2_3 %&gt;% variogram(resid ~ Easting.km + Northing.km, data = ., ## 0が南北方向、90が東西方向 alpha = c(0, 90), cressie = TRUE, cutoff = 150, width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ dir.hor, labeller = as_labeller(c(&quot;0&quot; = &quot;North-South&quot;, &quot;90&quot; = &quot;East-West&quot;)))+ labs(y = &quot;semivariogram&quot;) 1.3 GAM applied to temporal data 1.3.1 Subnivium temperature data 本節では、 Petty et al. (2015) のデータを用いる。この論文では雪下と地面の間の環境(subnivium)の温度を調べている。積雪量が温度に与える影響を、米ウィスコンシン州の3か所の3つの異なる環境(tall grass prailies, deciduous, coniferous)で検討している。 2013年12月から2014年3月における、日ごとの平均温度が記録されている。各環境に4つずつデータロガーが置かれている。そのため、\\(3 \\times 4 = 12\\)個の時系列データがある。 sn &lt;- read_csv(&quot;data/Snow.csv&quot;) %&gt;% mutate(date = as_datetime(str_c(Year,Month, Day, sep = &quot;-&quot;))) %&gt;% mutate(date_num = as.numeric((date - min(date))/(3600*24)) + 1) datatable(sn, options = list(scrollX = 20), filter = &quot;top&quot;) 論文に倣い、2013年12月5日から2014年3月3日までのデータを用いる(4 &lt;= date_num &lt;= 92)。 sn2 &lt;- sn %&gt;% filter(date_num &gt;= 4 &amp; date_num &lt;= 92) 各環境における温度の変化は以下の通り。 sn2 %&gt;% ggplot(aes(x = date_num, y = Temp))+ geom_line(aes(linetype = Logger))+ facet_rep_wrap(~Type)+ theme_bw()+ theme(aspect.ratio = 1.2) 1.3.2 Sources of dependency 同じ環境のロガーはそれぞれ10mしか離れていないので、同じ日におけるこれらのロガーのデータは独立ではない。また、同じロガーのデータについても、時間的な相関があると考えられる(t-1日目の温度とt日目の温度が独立とは考えにくい)。各環境間は距離が離れているので、独立性があると仮定してよさそう。 以下では、こうした非独立性を考慮せずに分析をした場合にどのような問題がが生じるかを見ていく。 1.3.3 The model 以下のGAMMを適用する(回帰係数は省略している)。ロガーIDをランダム切片として入れている。環境ごとにsmootherを推定する。\\(t\\)は経過日数(date_num)、\\(i\\)はロガーのidを表す。 \\[ \\begin{aligned} T_{it} &amp;\\sim N(\\mu_t, \\sigma^2)\\\\ \\mu_{it} &amp;= \\alpha + f_j(date\\_num_t) + Type_i + a_i\\\\ a_i &amp;\\sim N(0, \\sigma_{Logger}^2) \\end{aligned} (\\#eq:m2.4) \\] Rでは以下のように実行する。 m2_4 &lt;- gamm(Temp ~ s(date_num, by = Type) + Type, random = list(Logger =~ 1), data = sn2 %&gt;% mutate(Type = as.factor(Type))) 結果は以下の通り。 summary(m2_4$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Temp ~ s(date_num, by = Type) + Type ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.7363 0.1796 -9.670 &lt;2e-16 *** ## TypeDeciduous -0.1378 0.2574 -0.535 0.5927 ## TypePrairie 0.5000 0.2551 1.960 0.0503 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(date_num):TypeConiferous 8.658 8.658 36.21 &lt;2e-16 *** ## s(date_num):TypeDeciduous 8.205 8.205 62.67 &lt;2e-16 *** ## s(date_num):TypePrairie 8.229 8.229 37.69 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.548 ## Scale est. = 1.0144 n = 921 summary(m2_4$lme) ## Linear mixed-effects model fit by maximum likelihood ## Data: strip.offset(mf) ## AIC BIC logLik ## 2787.212 2840.292 -1382.606 ## ## Random effects: ## Formula: ~Xr - 1 | g ## Structure: pdIdnot ## Xr1 Xr2 Xr3 Xr4 Xr5 Xr6 Xr7 Xr8 ## StdDev: 20.28316 20.28316 20.28316 20.28316 20.28316 20.28316 20.28316 20.28316 ## ## Formula: ~Xr.0 - 1 | g.0 %in% g ## Structure: pdIdnot ## Xr.01 Xr.02 Xr.03 Xr.04 Xr.05 Xr.06 Xr.07 Xr.08 ## StdDev: 16.03337 16.03337 16.03337 16.03337 16.03337 16.03337 16.03337 16.03337 ## ## Formula: ~Xr.1 - 1 | g.1 %in% g.0 %in% g ## Structure: pdIdnot ## Xr.11 Xr.12 Xr.13 Xr.14 Xr.15 Xr.16 Xr.17 Xr.18 ## StdDev: 14.19846 14.19846 14.19846 14.19846 14.19846 14.19846 14.19846 14.19846 ## ## Formula: ~1 | Logger %in% g.1 %in% g.0 %in% g ## (Intercept) Residual ## StdDev: 0.3414393 1.007198 ## ## Fixed effects: y ~ X - 1 ## Value Std.Error DF t-value p-value ## X(Intercept) -1.736302 0.1798447 906 -9.654451 0.0000 ## XTypeDeciduous -0.137767 0.2578500 9 -0.534292 0.6061 ## XTypePrairie 0.499994 0.2555270 9 1.956717 0.0821 ## Xs(date_num):TypeConiferousFx1 -1.238174 1.0476349 906 -1.181875 0.2376 ## Xs(date_num):TypeDeciduousFx1 3.652453 1.4161295 906 2.579180 0.0101 ## Xs(date_num):TypePrairieFx1 0.042635 1.1659387 906 0.036567 0.9708 ## Correlation: ## X(Int) XTypDc XTypPr X(_):TC X(_):TD ## XTypeDeciduous -0.697 ## XTypePrairie -0.704 0.491 ## Xs(date_num):TypeConiferousFx1 -0.001 0.001 0.001 ## Xs(date_num):TypeDeciduousFx1 0.000 0.004 0.000 0.000 ## Xs(date_num):TypePrairieFx1 0.000 0.000 0.001 0.000 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.0136973 -0.4288093 0.0765251 0.5515962 3.2003331 ## ## Number of Observations: 921 ## Number of Groups: ## g g.0 %in% g ## 1 1 ## g.1 %in% g.0 %in% g Logger %in% g.1 %in% g.0 %in% g ## 1 12 1.3.4 Model validation ロガーごとの標準化残差を時系列的に図示したのが下図である。ここからパターンを読み取るのは難しい。 sn2 %&gt;% mutate(resid = resid(m2_4$lme, type = &quot;n&quot;)) %&gt;% ggplot(aes(x = date_num, y = resid))+ geom_point()+ geom_smooth(color = &quot;grey23&quot;)+ facet_rep_wrap(~Logger, scales = &quot;free_y&quot;) 時系列相関があるかを調べるためには、自己相関関数(acf)を描くことが有効である。自己相関関数は、k時点前のデータとの相関をkの関数としてあらわしたものである。 以下で、ロガーごとに時系列相関を算出する。 sn2 %&gt;% mutate(resid = resid(m2_4$lme, type = &quot;n&quot;)) %&gt;% group_by(Logger) %&gt;% arrange(date_num, .by_group = TRUE) -&gt; sn3 Loggerid &lt;- unique(sn3$Logger) all.out &lt;- NULL for(i in seq_along(Loggerid)){ data &lt;- sn3 %&gt;% filter(Logger == Loggerid[i]) ## 各ロガーについて時系列相関を算出 out.acf &lt;- acf(data$resid, lag.max = 15, plot = FALSE) ## 出力をデータフレームに out.df &lt;- data.frame(Timelag = out.acf$lag, Acf = out.acf$acf, SE = qnorm(0.975)/sqrt(out.acf$n.used), ID = Loggerid[i]) ## 全て結合 all.out &lt;- bind_rows(all.out, out.df) } 図示したのが下図である。グレーの塗りつぶしは95%信頼区間を表している。図から、全てのロガーにおいて1時点前のデータとの相関が高いことが示唆される。これは、残差に時系列相関があることを示しており、これを考慮したモデルを作成する必要性を示唆している。 all.out %&gt;% ggplot(aes(x = Timelag, y = 0))+ geom_segment(aes(xend = Timelag, yend = Acf))+ geom_ribbon(aes(ymax = SE, ymin = -SE), alpha = 0.3)+ theme_bw()+ theme(aspect.ratio = 0.8)+ facet_rep_wrap(~ID, repeat.tick.labels = TRUE)+ labs(y = &quot;Auto-correlation&quot;) acfの代わりにバリオグラムを用いることもできる。これは、時間間隔が一定でない場合などに有効である。これについては後でもう一度触れる。 References "],["Chapter3.html", "2 Time series and GLS 2.1 Ospreys 2.2 Covariance and correlation coefficients 2.3 Linear regression models 2.4 Focusing on the residual covariance matrix 2.5 Dependency and the covariance matrix 2.6 Dealing with temporal dependency 2.7 Multiple time series", " 2 Time series and GLS 本章では、時系列データに対して用いることができる回帰モデルについて解説する。 2.1 Ospreys Steidl et al. (1991) は、ミサゴの卵の厚さが殺虫剤の崩壊産物(DDD)によって変わるかを調べ、有意な関連を見つけた。本節ではこのデータを用いる。 osp &lt;- read_csv(&quot;data/Ospreys.csv&quot;) datatable(osp, options = list(scrollX = 20), filter = &quot;top&quot;) 2.2 Covariance and correlation coefficients DDDと卵の殻の厚さの関連は以下の通り。 osp %&gt;% ggplot(aes(x = DDD, y = THICK))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio=1) 相関係数は-0.42である。 cor(osp$THICK, osp$DDD) ## [1] -0.4195692 2.3 Linear regression models 以下のモデルを考える。 \\[ \\begin{aligned} Thichness_i &amp;= \\beta_1 + \\beta_2 \\times DDD_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] Rでは以下のように実行する。 m3_1 &lt;- lm(THICK ~ DDD, data = osp) 2.4 Focusing on the residual covariance matrix 残差\\(\\epsilon_i\\)は行列式で以下のように書ける。なお、\\(\\bf{I}\\)は単位行列である。 \\[ \\bf{\\epsilon} \\sim N(0, \\bf{\\sigma^2} \\times \\mathbf{I}) \\] より一般的に、残差\\(\\epsilon_i\\)は以下のように書ける。\\(\\bf{\\Sigma}\\)は分散共分散行列と呼ばれる。 \\[ \\bf{\\epsilon} \\sim N(0, \\bf{\\Sigma}) \\] 通常の線形回帰モデルでは、\\(\\bf{\\Sigma}\\)は以下のようになる。ここで、\\(sigma^2\\)に単位行列を書けるということは、残差間が独立であることを仮定していることになる。例えば、1行2列目は\\(\\epsilon_1\\)と\\(\\epsilon_2\\)の共分散を表すが、単位行列ではこれが0になる。同様に、単位行列は対角成分以外が全て0になるので、異なる残差同士の共分散が全て0になると仮定していることになる。 \\[ \\bf{\\Sigma} = \\sigma^2 \\times \\mathbf{I} \\] より一般的には、分散共分散行列\\(\\bf{\\Sigma}\\)は以下のように書ける。これは対称行列である。\\(\\phi_{i,j}\\)は\\(\\epsilon_i\\)と\\(\\epsilon_j\\)の共分散である。通常の回帰分析ではこれらが全て0と仮定された。共分散が０以外の値をとる場合、異なる残差は独立ではなくなる。 \\[ \\bf{\\Sigma} = \\begin{pmatrix} \\sigma^2 &amp; \\phi_{1,2} &amp; \\phi_{1,3} &amp; \\phi_{1,4} &amp; \\cdots &amp;\\phi_{1,25} \\\\ &amp; \\sigma^2 &amp; \\phi_{2,3} &amp; \\phi_{2,4} &amp; \\cdots&amp; \\phi_{2,25}\\\\ &amp; &amp; \\sigma^2 &amp; \\phi_{3,4} &amp; \\cdots &amp; \\phi_{3,25} \\\\ &amp; &amp; &amp; \\sigma^2 &amp; \\ddots &amp; \\vdots \\\\ &amp; &amp; &amp; &amp; \\sigma^2 &amp; \\phi_{24,25}\\\\ &amp; &amp; &amp; &amp; &amp; \\sigma^2 \\end{pmatrix} \\tag{2.1} \\] 2.5 Dependency and the covariance matrix ここで、回帰モデルにおける分散共分散行列の役割について理解するためにシミュレーションを行う。変数\\(z_1\\)と\\(z_2\\)が以下に従って1000個ずつ得られるとする。 \\[ \\begin{aligned} z_1 &amp;\\sim N(10,1)\\\\ z_2 &amp;\\sim N(15,1) \\end{aligned} \\] Rでは以下のように得る。 set.seed(1234) z1 &lt;- rnorm(1000, 10, 1) z2 &lt;- rnorm(1000, 15, 1) MASSパッケージのmvrnorm関数を用い、多変量正規分布から同様に値を行列として得ることもできる。 sigma &lt;- diag(2) Z &lt;- mvrnorm(1000, mu = c(10, 15), Sigma = sigma) %&gt;% data.frame() %&gt;% rename(z1 = 1, z2 = 2) datatable(Z) このとき、\\(z_1\\)と\\(z_2\\)は行列を用いると以下のように多変量正規分布から得られていると書くことができる。これは、平均がそれぞれ10と15で、分散共分散行列\\(\\bf{\\Sigma}\\)が単位行列の多変量正規分布から値が得られたことを示す。 \\[ \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = N \\Bigl( \\begin{pmatrix} 10 \\\\ 15 \\end{pmatrix}, \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ \\end{pmatrix} \\Bigl) \\] 得られたデータをプロットして分かるように、分散共分散行列が単位行列であり、\\(z_1\\)と\\(z_2\\)の間の共分散はゼロとなっているため、これらに相関が全くないことが分かる。 Z %&gt;% ggplot(aes(x = z1, y = z2))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1) 今度は、\\(z_1\\)と\\(z_2\\)が正の相関を持つような場合を考える。このようなときは、以下のように\\(\\bf{\\Sigma}\\)の\\(\\phi\\)成分を0でなく正の値にしてやればよい(ここでは0.9)。分散を1にしているので、この値はそのまま相関係数になる。 sigma &lt;- diag(2) sigma[1,2] &lt;- 0.9 sigma[2,1] &lt;- 0.9 sigma ## [,1] [,2] ## [1,] 1.0 0.9 ## [2,] 0.9 1.0 実際に得られた値をプロットしても、\\(z_1\\)と\\(z_2\\)が強い相関を持つことが分かる。このように、\\(\\bf{Sigma}\\)の非対角成分に0以外の値を割り当てることで、多変量正規分布から得られる値が非独立であることを表現できる。 Z &lt;- mvrnorm(1000, mu = c(10, 15), Sigma = sigma) %&gt;% data.frame() %&gt;% rename(z1 = 1, z2 = 2) Z %&gt;% ggplot(aes(x = z1, y = z2))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1) 2.6 Dealing with temporal dependency 同様に、時系列データに対しても、残差の分散共分散行列の非対角成分\\(\\phi_{i,j}\\)を0以外の値にすることで、データの非独立性に対処することができる。そのような方法の一つがGLS(Generalized least square)と呼ばれる方法である。 2.6.1 Adelie penguins ここでは、 Barbraud and Weimerskirch (2006) が南極の海鳥が到着する日と産卵日について調査したデータを用いる。ここでは、特に産卵日について着目する。 データは以下の通り。各年について1つのデータがある。 bird &lt;- read_csv(&quot;data/Phenology_Data_Antarcticbirds_AFZ1.csv&quot;) datatable(bird, options = list(scrollX = 20), filter = &quot;top&quot;) 分析では、海氷面積によって産卵日に違いが出るかを調べる。海氷面積の直接的なデータはないので、その近似として海中のメタルスルホン酸(MSA: 海氷が多いと多くなる)を用いる。 産卵日の年変動と、MSAと産卵日の関係は以下のようになる。 bird %&gt;% ggplot(aes(x = Year, y = LayingAP))+ geom_line()+ geom_point()+ theme_bw()+ theme(aspect.ratio = 0.7)+ labs(y = &quot;Laying date&quot;) -&gt; p1 bird %&gt;% ggplot(aes(x = MSA, y = LayingAP))+ geom_point(shape = 1, size = 2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Laying date&quot;) -&gt; p2 p1 + p2 2.6.2 Do we have dependency? 産卵日に影響する様々な要因(成熟したメスの数、病気の流行、ホルモンレベル)などは年ごとに独立ではなく、t年のデータがt+1年のデータに影響を及ぼしていると考えられる。よって、各年の産卵日は独立ではないと考えられる。 2.6.3 Formulation of the linear regression model まずは時系列を考慮しない通常の線形回帰モデルを適用する。モデル式は以下の通り。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 2.6.4 Application of the linear regression model Rでは以下のように実行する。ここでは、nlmeパッケージのgls関数を用いる(もちろん、lm関数でも実行できる)。 m3_2a &lt;- gls(LayingAP ~ MSA, data = bird, na.action = na.omit) 結果は以下の通り。MSAの効果は弱いことが分かる。 summary(m3_2a) ## Generalized least squares fit by REML ## Model: LayingAP ~ MSA ## Data: bird ## AIC BIC logLik ## 139.7118 144.0137 -66.85588 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 247.91825 1.25111 198.15867 0.0000 ## MSA -33.01513 16.42976 -2.00947 0.0533 ## ## Correlation: ## (Intr) ## MSA -0.956 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -1.5831272 -0.5845941 -0.1200808 0.5813974 1.9238887 ## ## Residual standard error: 2.111689 ## Degrees of freedom: 33 total; 31 residual モデルの標準化残差と予測値、MSAとの関連をプロットしたのが以下の図である。数字は観察年の下２桁を表す。明確なパターンは見当たらない。しかし、よく見てみると観察年が近いと似た残差をとる傾向があるように思える。例えば、60年代のデータは全て残差が負の値になっている。 data.frame(resid = resid(m3_2a, type = &quot;n&quot;), Year = bird %&gt;% drop_na(LayingAP, MSA) %&gt;% .$Year, fitted = predict(m3_2a), MSA = bird %&gt;% drop_na(LayingAP, MSA) %&gt;% .$Year) %&gt;% mutate(Year2 = str_sub(Year, 3,4)) -&gt; fitted_m3_2a fitted_m3_2a %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1, size = 2)+ geom_text_repel(aes(label = Year2))+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw(base_size = 14)+ theme(aspect.ratio = 1) -&gt; p1 fitted_m3_2a %&gt;% ggplot(aes(x = MSA, y = resid))+ geom_point(shape = 1, size = 2)+ geom_text_repel(aes(label = Year2))+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw(base_size = 14)+ theme(aspect.ratio = 1) -&gt; p2 p1 + p2 自己相関関数をプロットしてみると、あまり明確にはわからないが有意に自己相関が高いところがあることが分かる。 resid &lt;- rep(NA, nrow(bird)) i &lt;- !is.na(bird$LayingAP) &amp; !is.na(bird$MSA) resid[i] &lt;- resid(m3_2a, type = &quot;n&quot;) acf &lt;- acf(resid, lag.max = 20, na.action = na.pass, plot = FALSE) data.frame(lag = 0:20, acf = acf$acf, SE = qnorm(0.975)/sqrt(acf$n.used)) %&gt;% ggplot(aes(x = lag, y = 0))+ geom_segment(aes(xend = lag, yend = acf))+ geom_hline(aes(yintercept = -SE), linetype = &quot;dashed&quot;, color = &quot;navy&quot;)+ geom_hline(aes(yintercept = SE), linetype = &quot;dashed&quot;, color = &quot;navy&quot;)+ theme_bw()+ labs(y = &quot;acf&quot;)+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(0,20,1)) 欠損値が多いので、バリオグラムで見た方が適切かもしれない。バリオグラムは以下のようになる。バリオグラムは水平にならず、やはり残差に時間的な相関があることが示唆される。 vario_3_2a &lt;- data.frame(resid = resid, Year = bird$Year, zero = 0) %&gt;% drop_na() sp::coordinates(vario_3_2a) &lt;- c(&quot;Year&quot;, &quot;zero&quot;) vario_3_2a %&gt;% variogram(resid ~ 1, data = ., cutoff = 9, width = 1) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_line()+ geom_point(size = 3, shape = 21, fill = &quot;black&quot;, color = &quot;white&quot;, stroke = 2)+ theme_bw(base_size = 14)+ theme(aspect.ratio = 1)+ labs(y = &quot;semivariogram&quot;, x = &quot;Time lag&quot;)+ coord_cartesian(ylim = c(0,1.4))+ scale_x_continuous(breaks = seq(1,9,1))+ scale_y_continuous(breaks = seq(0,1.4,0.2)) こうした時系列相関が問題になりうるかを判断するためには、時系列相関を考慮したモデルを作成し、それを考慮しないモデルと比較する必要がある。 2.6.5 Formulation of the GLS model 通常の回帰モデルでは異なる残差同士が独立(相関が0)なので、以下のように書くことができる。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2)\\\\ cor(\\epsilon_t, \\epsilon_s) &amp;= \\begin{cases} 0 \\; \\bf{if} \\;t \\neq s \\\\ 1 \\; \\bf{if} \\;t = s \\end{cases} \\end{aligned} \\] これまでに見てきたように、時系列相関を考慮するためには異なる残差同士の相関が0でないと仮定すればよい。これは、以下のように書ける。なお、\\(h()\\)は残差同士の相関を決める関数で\\(\\phi\\)はその関数におけるパラメータである。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2)\\\\ cor(\\epsilon_t, \\epsilon_s) &amp;= h(\\phi, \\epsilon_t, \\epsilon_s) \\end{aligned} \\] 時系列相関を考慮したモデルでは、この\\(h()\\)に様々な関数を想定することで、データの非独立性に対応する。最も一般的なものは、AR1過程と呼ばれるもので、以下のように書ける。なお、\\(\\phi\\)は0から1の値をとる。 \\[ \\begin{aligned} \\epsilon_t &amp;= \\phi \\times \\epsilon_{t-1} + \\nu_t \\\\ \\nu_t &amp;\\sim N(0, \\sigma_\\nu^2) \\end{aligned} \\] 関数\\(h()\\)は以下のように書ける。このとき、残差は定常性を持つといわれる。これは、残差の共分散は時間差のみに依存しているということである。 \\[ h(\\phi, \\epsilon_t, \\epsilon_s) = \\phi^{|t-s|} \\] AR1で残差の分散共分散行列\\(\\bf{\\Sigma}\\)は以下のように書ける。行列中のパラメータは$$1つなので、これさえ推定できれば良い。 \\[ \\bf{\\Sigma} = cov(\\bf{\\epsilon}) = \\frac{\\sigma_{\\nu}^2}{1-\\phi^2} \\times \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi^2 &amp; \\phi^3 &amp; \\cdots &amp; \\phi^{54} \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi^2 &amp; \\ddots &amp; \\vdots\\\\ \\phi^2 &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^3 \\\\ \\phi^3 &amp; \\phi^2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^2 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi^{54} &amp; \\cdots &amp; \\phi^2 &amp; \\phi^2 &amp; \\phi &amp; 1 \\end{pmatrix} \\] 相関行列は以下のように書ける。 \\[ cor(\\bf{\\epsilon}) = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi^2 &amp; \\phi^3 &amp; \\cdots &amp; \\phi^{54} \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi^2 &amp; \\ddots &amp; \\vdots\\\\ \\phi^2 &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^3 \\\\ \\phi^3 &amp; \\phi^2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^2 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi^{54} &amp; \\cdots &amp; \\phi^3 &amp; \\phi^2 &amp; \\phi &amp; 1 \\end{pmatrix} \\] AR1では、回帰係数の推定値とその分散共分散行列は以下のようになる。 \\[ \\begin{aligned} \\bf{\\hat{\\beta}} &amp;= (\\bf{X^t} \\times \\bf{\\Sigma^{-1}} \\times \\bf{X})^{-1} \\times \\bf{X^t} \\times \\bf{\\Sigma^{-1}} \\times \\bf{y}\\\\ cov(\\hat{\\beta}) &amp;= (\\bf{X^t} \\times \\bf{\\Sigma^{-1}} \\times \\bf{X})^{-1} \\end{aligned} \\] AR1過程モデルの代わりに、残差が他の相関構造をもつものを仮定することもできる。例えば、交換可能(exchangable)な相関を持つ場合、相関行列は以下のように書ける。これは、時間差に依らず全ての異なる残差が同じ相関\\(\\phi\\)を持つことを仮定している。これは、短い時系列を持つデータに対しては有効である場合がある。 \\[ cor(\\bf{\\epsilon}) = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\cdots &amp; \\phi \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi &amp; \\ddots &amp; \\vdots\\\\ \\phi &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi\\\\ \\phi &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi\\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi &amp; \\cdots &amp; \\phi &amp; \\phi &amp; \\phi &amp; 1 \\\\ \\end{pmatrix} \\] 2.6.6 Implementation using the gls function AR1モデルのGLSのモデル式を書くと以下のようになる。 \\[ \\begin{aligned} LD_t &amp;= \\beta_1 + \\beta_2 \\times MSA_t + \\epsilon_t \\\\ \\epsilon_t &amp;\\sim N(0,\\sigma^2)\\\\ cor(\\epsilon_t, \\epsilon_s) &amp;= \\phi^{|t-s|} \\end{aligned} \\] Rでは以下のように実行できる。gls関数では、correlation =オプションで様々な残差の相関構造をモデリングできる。例えば、交換可能な相関の場合は、correlation = corCompSymm()とする。 m3_2b &lt;- gls(LayingAP ~ MSA, correlation = corAR1(form = ~Year), data = bird, na.action = na.omit) 結果は以下の通り。推定された\\(phi\\)は0.523である。驚くべきことに、時系列相関を考慮しない場合にはMSAの係数が負の値だったのに対して、今回は正の値になっている。 summary(m3_2b) ## Generalized least squares fit by REML ## Model: LayingAP ~ MSA ## Data: bird ## AIC BIC logLik ## 138.8594 144.5953 -65.42968 ## ## Correlation Structure: ARMA(1,0) ## Formula: ~Year ## Parameter estimate(s): ## Phi1 ## 0.5236874 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 244.57591 1.443356 169.44949 0.000 ## MSA 10.33068 17.311974 0.59674 0.555 ## ## Correlation: ## (Intr) ## MSA -0.896 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -1.5300255 -0.6243847 -0.0438220 0.7957452 2.0484887 ## ## Residual standard error: 2.345265 ## Degrees of freedom: 33 total; 31 residual モデルの予測値を図示したのが下図である。AR1モデルでは傾きが正になり、MSAと産卵日の関連はより小さなものと推定されている。 nd &lt;- data.frame(MSA =seq(0.03,0.14,length = 100)) data.frame(m3_2a = predict(m3_2a, newdata = nd), m3_2b = predict(m3_2b, newdata = nd), MSA = nd$MSA) %&gt;% pivot_longer(cols = 1:2, names_to = &quot;model&quot;, values_to = &quot;fitted&quot;) %&gt;% ggplot(aes(x = MSA, y = fitted))+ geom_line(aes(color = model), linewidth = 1)+ geom_text(aes(label = str_sub(bird$Year, 3,4), y = LayingAP), data = bird)+ theme_bw()+ theme(aspect.ratio = 0.9)+ scale_color_nejm()+ labs(y = &quot;Laying date&quot;) AICを比較しても、AR1モデルの方がわずかに予測がよいことが分かる。 AIC(m3_2a, m3_2b) 2.7 Multiple time series 第1.3節でみた積雪量と雪下温度の関連を調べた Petty et al. (2015) のデータについてもう一度考える。式@ref(eq:m2.4)のモデルでは、各時系列の残差が自己相関を持っていた。そこで、以下のモデルを考える(回帰係数は省略)。 \\[ \\begin{aligned} &amp;T_{it} = \\alpha + f_j(date\\_num_t) + Type_i + a_i + \\epsilon_{it}\\\\ &amp;a_i \\sim N(0, \\sigma_{Logger}^2)\\\\ &amp;\\epsilon_{it} \\sim N(0, \\sigma^2)\\\\ &amp;cor(\\epsilon_{it}, \\epsilon_{is}) = \\phi^{|t-s|} \\end{aligned} (\\#eq:m3.3) \\] Rでは、以下のように実行できる。ランダム切片を含む場合、自己相関は自動的にそれぞれのロガーに対して適用されるため、correlation = corAR1(form =~date_num)としても同じ結果が得られる。Rのgamm関数では全てのロガーについて同じ\\(\\phi\\)しか推定できない。 m3_3 &lt;- gamm(Temp ~ s(date_num, by = Type) + Type, random = list(Logger =~ 1), correlation = corAR1(form = ~date_num|Logger), data = sn2 %&gt;% mutate(Type = as.factor(Type))) 例えば、ロガー1の残差の相関行列は以下のように書ける。 \\[ \\bf{\\Sigma_1} = cor \\begin{pmatrix} \\epsilon_{1,1}\\\\ \\epsilon_{1,2}\\\\ \\vdots\\\\ \\epsilon_{1,88}\\\\ \\epsilon_{1,89} \\end{pmatrix} = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi^2 &amp; \\phi^3 &amp; \\cdots &amp; \\phi^{89} \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi^2 &amp; \\ddots &amp; \\vdots\\\\ \\phi^2 &amp; \\phi &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^3 \\\\ \\phi^3 &amp; \\phi^2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\phi^2 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi^{89} &amp; \\cdots &amp; \\phi^3 &amp; \\phi^2 &amp; \\phi &amp; 1 \\end{pmatrix} \\] gamm関数で推定した場合、全てのロガーで同じ\\(\\phi\\)が推定されるので、どのロガーの残差の相関行列も\\(\\bf{\\Sigma_1}\\)となる。よって、すべてのロガーの残差の相関行列は以下のように書ける。対角成分以外が0なのは、異なるロガーの残差の相関は0である(= 独立である)ことを表している。 \\[ \\begin{aligned} cor \\begin{pmatrix} \\begin{pmatrix} \\epsilon_{1,1}\\\\ \\vdots\\\\ \\epsilon_{1,89} \\end{pmatrix}\\\\ \\begin{pmatrix} \\epsilon_{2,1}\\\\ \\vdots\\\\ \\epsilon_{2,89} \\end{pmatrix}\\\\ \\vdots \\\\ \\begin{pmatrix} \\epsilon_{12,1}\\\\ \\vdots\\\\ \\epsilon_{12,89} \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} \\bf{\\Sigma_1} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\bf{\\Sigma_2} &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\bf{\\Sigma_{12}} \\\\ \\end{pmatrix} = \\begin{pmatrix} \\bf{\\Sigma_1} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\bf{\\Sigma_1} &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\bf{\\Sigma_{1}} \\\\ \\end{pmatrix} \\end{aligned} \\] 結果は以下の通り。\\(\\phi\\)は0.504と推定されている。 summary(m3_3$lme) ## Linear mixed-effects model fit by maximum likelihood ## Data: strip.offset(mf) ## AIC BIC logLik ## 2587.526 2645.432 -1281.763 ## ## Random effects: ## Formula: ~Xr - 1 | g ## Structure: pdIdnot ## Xr1 Xr2 Xr3 Xr4 Xr5 Xr6 Xr7 Xr8 ## StdDev: 16.80172 16.80172 16.80172 16.80172 16.80172 16.80172 16.80172 16.80172 ## ## Formula: ~Xr.0 - 1 | g.0 %in% g ## Structure: pdIdnot ## Xr.01 Xr.02 Xr.03 Xr.04 Xr.05 Xr.06 Xr.07 Xr.08 ## StdDev: 12.99064 12.99064 12.99064 12.99064 12.99064 12.99064 12.99064 12.99064 ## ## Formula: ~Xr.1 - 1 | g.1 %in% g.0 %in% g ## Structure: pdIdnot ## Xr.11 Xr.12 Xr.13 Xr.14 Xr.15 Xr.16 Xr.17 Xr.18 ## StdDev: 10.23867 10.23867 10.23867 10.23867 10.23867 10.23867 10.23867 10.23867 ## ## Formula: ~1 | Logger %in% g.1 %in% g.0 %in% g ## (Intercept) Residual ## StdDev: 0.2900993 1.070964 ## ## Correlation Structure: ARMA(1,0) ## Formula: ~date_num | g/g.0/g.1/Logger ## Parameter estimate(s): ## Phi1 ## 0.5039287 ## Fixed effects: y ~ X - 1 ## Value Std.Error DF t-value p-value ## X(Intercept) -1.7091286 0.1769862 906 -9.656845 0.0000 ## XTypeDeciduous -0.1055758 0.2601888 9 -0.405766 0.6944 ## XTypePrairie 0.5034402 0.2537067 9 1.984339 0.0785 ## Xs(date_num):TypeConiferousFx1 -1.2565046 1.4583432 906 -0.861597 0.3891 ## Xs(date_num):TypeDeciduousFx1 3.0138336 1.7648757 906 1.707675 0.0880 ## Xs(date_num):TypePrairieFx1 0.4391241 1.4170564 906 0.309885 0.7567 ## Correlation: ## X(Int) XTypDc XTypPr X(_):TC X(_):TD ## XTypeDeciduous -0.680 ## XTypePrairie -0.698 0.475 ## Xs(date_num):TypeConiferousFx1 0.006 -0.004 -0.004 ## Xs(date_num):TypeDeciduousFx1 0.000 -0.004 0.000 0.000 ## Xs(date_num):TypePrairieFx1 0.000 0.000 0.001 0.000 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.4057668 -0.4121370 0.1026576 0.5351727 2.4662264 ## ## Number of Observations: 921 ## Number of Groups: ## g g.0 %in% g ## 1 1 ## g.1 %in% g.0 %in% g Logger %in% g.1 %in% g.0 %in% g ## 1 12 最後に、モデルの残差の自己相関関数(acf)を図示する。 sn2 %&gt;% mutate(resid = resid(m3_3$lme, type = &quot;n&quot;)) %&gt;% group_by(Logger) %&gt;% arrange(date_num, .by_group = TRUE) -&gt; sn3 Loggerid &lt;- unique(sn3$Logger) all.out &lt;- NULL for(i in seq_along(Loggerid)){ data &lt;- sn3 %&gt;% filter(Logger == Loggerid[i]) ## 各ロガーについて時系列相関を算出 out.acf &lt;- acf(data$resid, lag.max = 15, plot = FALSE) ## 出力をデータフレームに out.df &lt;- data.frame(Timelag = out.acf$lag, Acf = out.acf$acf, SE = qnorm(0.975)/sqrt(out.acf$n.used), ID = Loggerid[i]) ## 全て結合 all.out &lt;- bind_rows(all.out, out.df) } 図示したのが下図である。図からは、依然として多くのロガーでは時系列相関があることが分かる。よって、単にAR1モデルを適用するだけでは問題は解決できていない。 all.out %&gt;% ggplot(aes(x = Timelag, y = 0))+ geom_segment(aes(xend = Timelag, yend = Acf))+ geom_ribbon(aes(ymax = SE, ymin = -SE), alpha = 0.3)+ theme_bw()+ theme(aspect.ratio = 0.8)+ facet_rep_wrap(~ID, repeat.tick.labels = TRUE)+ labs(y = &quot;Auto-correlation&quot;) また、他の問題としてGAMMに時間のsmootherとAR1過程の両方が含まれている場合、これらが競合してしまう場合があることもある。この場合、どちらかのみを適用した方がよい。 References "],["Chapter4.html", "3 Spatial data and GLS 3.1 Variogram models for spatial dependency 3.2 Application on the Irish pH data 3.3 Matern correlation function", " 3 Spatial data and GLS 本章では、今度は空間的相関を持つデータにGLSを適用する。 3.1 Variogram models for spatial dependency 時系列データに対しては、異なる残差間の相関を以下のような関数\\(h()\\)で定義した。 \\[ h(\\phi, \\epsilon_t, \\epsilon_ss) = \\phi^{|t-s|} \\] しかし、空間データに対して全く同じことをすることはできない。その代わり、残差のバリオグラムの形に応じて数学的モデルを選択し、それを用いて残差の分散共分散行列\\(\\bf{\\Sigma}\\)を計算することになる。nlmeパッケージには、corExp、corSpher、corLin、corGaus、corRatioなど、残差の空間的なパターンをモデリングするための様々なモデルがある(これらは、カーネルとも呼ばれる)。それぞれのモデルは2つのパラメータを持つ。詳細な数学的表現については、?corClassesでヘルプを参照するか、 Dale and Fortin (2014) や 村上 (2022) を参照。 例えば、指数バリオグラム(corExp)は以下のように定義される。なお、\\(s\\)は2地点間の距離、\\(\\phi\\)はレンジ(range)と呼ばれるパラメータであり、自己相関がなくなるまでの距離を表す。 \\[ h(s, \\phi) = 1 - e^{-\\frac{s}{\\phi}} \\] 同様に、球形(corSpher)は以下のように定義される。 \\[ \\begin{aligned} h(s, \\phi) = \\begin{cases} 1 - \\frac{3}{2}\\frac{s}{\\phi} + \\frac{3}{2}(\\frac{s}{\\phi})^3 \\;\\; &amp;if \\; 0 \\le s &lt; \\phi \\\\ 0 \\;\\; &amp;if \\; \\phi &lt; s \\end{cases} \\end{aligned} \\] また、ガウス型(corGaus)は以下のように定義される。 \\[ h(s, \\phi) = exp \\Bigl( -\\bigl( \\frac{s}{\\phi} \\bigl)^2 \\Bigl) \\] これらのモデルは距離が0のときバリオグラムの値も0になってしまうため、距離が0のときのバリオグラムの値を指定することができる(= ナゲット効果)。 様々なモデルのバリオグラムを図示したのが以下である。 #corExp mydata &lt;- data.frame(D = seq(0,1,by = 0.1)) cprExp &lt;- NULL phi_exp = c(0.2, 0.3, 0.5) nugget = 0.2 for(i in seq_along(phi_exp)){ corExp(c(phi_exp[i],nugget), form = ~ mydata$D, ## ナゲット効果 nugget = T,) %&gt;% Initialize(,data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_exp[i], type = &quot;Exponential&quot;) -&gt; vario.out cprExp &lt;- bind_rows(cprExp, vario.out) } #CorSpher cprSph &lt;- NULL phi_sph = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_sph)){ corSpher(c(phi_sph[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_sph[i], type = &quot;Spherical&quot;) -&gt; vario.out cprSph &lt;- bind_rows(cprSph, vario.out) } #CorGaus cprGaus &lt;- NULL phi_gaus = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_gaus)){ corGaus(c(phi_gaus[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_gaus[i], type = &quot;Gaussian&quot;) -&gt; vario.out cprGaus &lt;- bind_rows(cprGaus, vario.out) } #CorRatio cprRatio &lt;- NULL phi_ratio = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_ratio)){ corGaus(c(phi_ratio[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_ratio[i], type = &quot;Ratio&quot;) -&gt; vario.out cprRatio &lt;- bind_rows(cprRatio, vario.out) } #CorLin cprLin &lt;- NULL phi_lin = c(0.3, 0.5, 0.8) nagget = 0.3 for(i in seq_along(phi_lin)){ corGaus(c(phi_lin[i], nugget) , form = ~ mydata$D, nugget = T) %&gt;% Initialize(, data=mydata) %&gt;% Variogram() %&gt;% mutate(phi = phi_lin[i], type = &quot;Lin&quot;) -&gt; vario.out cprLin &lt;- bind_rows(cprLin, vario.out) } ## 図示 bind_rows(cprExp, cprGaus, cprSph, cprRatio, cprLin) %&gt;% mutate(phi = as.factor(phi)) %&gt;% ggplot(aes(x = dist, y = variog))+ geom_line(aes(group = phi))+ facet_rep_wrap(~type, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1) 分析は以下の5ステップで行う。 空間的相関を考慮せずにモデリングを行う。 1のモデルの残差のバリオグラムを書く。 バリオグラムの形を基に、どのバリオグラムモデルを適用するか決める。 バリオグラムモデルを含み、空間的相関を考慮したモデリングを行う。 4のモデルが問題ないかをチェックする。 3.2 Application on the Irish pH data 本節では、第1.2節で分析したアイルランドの河川のpHを調べたデータを再び用いる。空間的相関を考慮しない通常の線形回帰については第1.2節ですでに実行しているため、これに関する説明は省略する(step1とstep2)。図1.6からどのバリオグラムモデルが適切かを判断することが難しいため、可能なバリオグラムモデルを全て当てはめる。 iph %&gt;% mutate(Xkm = Easting/1000, Ykm = Northing/1000) -&gt; iph m4_1 &lt;- gls(pH ~ SDI + logAltitude*fForested, data = iph, method = &quot;REML&quot;) ## 指数モデル m4_1_exp &lt;- update(m4_1, correlation =corExp(form = ~ Xkm + Ykm, nugget = TRUE)) ## Linモデル m4_1_lin &lt;- update(m4_1, correlation =corLin(form = ~ Xkm + Ykm, nugget = TRUE)) ## Gausモデル m4_1_gau &lt;- update(m4_1, correlation =corGaus(form = ~ Xkm + Ykm, nugget = TRUE)) ## 球形モデル m4_1_sph &lt;- update(m4_1, correlation =corSpher(form = ~ Xkm + Ykm, nugget = TRUE)) ## Ratioモデル m4_1_rat &lt;- update(m4_1, correlation =corRatio(form = ~ Xkm + Ykm, nugget = TRUE)) 各モデルのAICを比較すると指数モデル(m4_1_exp)と比率モデル(m4_1_rat)が最もAICが低い。しかし、その他の空間的相関を考慮したモデルはむしろAICが高くなっていることが分かる。このことは、これらのモデルで推定されたレンジ(\\(\\phi\\))の値が0に近いことを示している。 AIC(m4_1, m4_1_exp, m4_1_gau, m4_1_lin, m4_1_rat, m4_1_sph) 実際、時数モデルと比率モデル以外はレンジの推定値がほとんど0になっていることが分かる。 bind_rows(coef(m4_1_exp$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_lin$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_gau$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_sph$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_rat$modelStruct$corStruct, unconstrained = FALSE)) %&gt;% mutate(model = c(&quot;Exp&quot;,&quot;Lin&quot;,&quot;Gaussian&quot;,&quot;Spherical&quot;,&quot;Ratio&quot;)) %&gt;% select(model, everything()) これは、gls関数ではレンジphiを推定する際に、指定しなければ最短の距離の90%の値をアルゴリズムの初期値として使用するために生じている。この問題を回避するためには、以下のようにvalue =で初期値を指定する必要がある。ここでは、レンジに50、ナゲットに0.1を割り当てている(Linモデルだけ収束しなかったので、レンジの初期値に25を割り当てている)。 ## 指数モデル m4_1_exp2 &lt;- update(m4_1, correlation =corExp(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) ## Linモデル m4_1_lin2 &lt;- update(m4_1, correlation =corLin(form = ~ Xkm + Ykm, nugget = TRUE, value = c(25, 0.1))) ## Gausモデル m4_1_gau2 &lt;- update(m4_1, correlation =corGaus(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) ## 球形モデル m4_1_sph2 &lt;- update(m4_1, correlation =corSpher(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) ## Ratioモデル m4_1_rat2 &lt;- update(m4_1, correlation =corRatio(form = ~ Xkm + Ykm, nugget = TRUE, value = c(50, 0.1))) 新しいモデルでは、レンジの推定値が0に近くなくなっている。 bind_rows(coef(m4_1_exp2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_lin2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_gau2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_sph2$modelStruct$corStruct, unconstrained = FALSE), coef(m4_1_rat2$modelStruct$corStruct, unconstrained = FALSE)) %&gt;% mutate(model = c(&quot;Exp&quot;,&quot;Lin&quot;,&quot;Gaussian&quot;,&quot;Spherical&quot;,&quot;Ratio&quot;)) %&gt;% select(model, everything()) これらのモデルのAICを比較すると、相関構造としてcorLinを持つモデルが最もAICが低いことが分かった。 AIC(m4_1, m4_1_exp2, m4_1_gau2, m4_1_lin2, m4_1_rat2, m4_1_sph2) このモデルの結果は以下の通り。 summary(m4_1_lin2) ## Generalized least squares fit by REML ## Model: pH ~ SDI + logAltitude * fForested ## Data: iph ## AIC BIC logLik ## 169.5945 196.1786 -76.79724 ## ## Correlation Structure: Linear spatial correlation ## Formula: ~Xkm + Ykm ## Parameter estimate(s): ## range nugget ## 67.2152946 0.5228704 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 8.175531 0.2766976 29.546811 0.0000 ## SDI -0.023739 0.0019874 -11.944746 0.0000 ## logAltitude 0.154131 0.1397899 1.102593 0.2715 ## fForestedyes 1.036179 0.3841835 2.697093 0.0076 ## logAltitude:fForestedyes -0.539765 0.1816375 -2.971661 0.0033 ## ## Correlation: ## (Intr) SDI lgAltt fFrstd ## SDI -0.061 ## logAltitude -0.931 -0.213 ## fForestedyes -0.380 -0.020 0.380 ## logAltitude:fForestedyes 0.411 -0.016 -0.406 -0.989 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -5.1573493 -0.5666860 -0.1527922 0.4324576 2.7694846 ## ## Residual standard error: 0.392704 ## Degrees of freedom: 210 total; 205 residual 空間相関を考慮しないモデル(m4_1)と比較すると、推定値が少し変化しているようだ。95%信頼区間は一般的に空間的相関を考慮すれば大きくなるが、今回はあまり変わっていないように見える。 compare_parameters(m4_1, m4_1_lin2) バリオグラムを描画すると、まだ空間的相関が少しありそう? vario_4_1 &lt;- data.frame(resid = resid(m4_1_lin2, type = &quot;n&quot;), Xkm = iph$Xkm, Ykm = iph$Ykm) sp::coordinates(vario_4_1) &lt;- c(&quot;Xkm&quot;, &quot;Ykm&quot;) vario_4_1 %&gt;% variogram(resid ~ Xkm + Ykm, data = ., ## 0が南北方向、90が東西方向 alpha = c(0, 90), cressie = TRUE, cutoff = 150, width = 10) %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~ dir.hor, labeller = as_labeller(c(&quot;0&quot; = &quot;North-South&quot;, &quot;90&quot; = &quot;East-West&quot;)))+ labs(y = &quot;semivariogram&quot;) 3.3 Matern correlation function Matern相関関数は以下のように書ける。なお、\\(s_i\\)と\\(s_j\\)はデータ\\(i\\)と\\(j\\)の空間的な場所を、\\(K_V\\)は第2種ベッセル関数を、\\(||s_i - s_j||\\)はデータ\\(i\\)と\\(j\\)のユークリッド距離を表す(ベッセル関数については高度な数学が必要のため、理解しなくていい)。\\(\\kappa\\)はAR1過程モデルの\\(\\phi\\)やバリオグラムモデルのレンジに相当するものである。\\(\\Gamma()\\)はガンマ関数である。 \\[ cor_{Matern}(s_i, s_j) = \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\times (\\kappa \\times ||s_i - s_j||)^\\nu \\times K_\\nu(\\kappa \\times ||s_i - s_j||) \\] Matern相関関数を図示したのが図3.1である。AR1過程やバリオグラムモデルのように、空間的に近いデータ同士の相関は高く、空間的に離れるほど相関が低くなっていくことが分かる。Matern関数はglsには実装されていないが、のちに学ぶINLAパッケージには実装されている。 library(fields) crossing(kappa = c(0.02,0.07,0.2), distance = seq(0,100,length =100)) %&gt;% mutate(correlation = ifelse(distance != 0, (kappa * distance) * besselK(kappa * distance, 1), 1)) %&gt;% mutate(kappa = as.factor(kappa)) %&gt;% ggplot(aes(x = distance, y = correlation))+ geom_line(aes(linetype = kappa))+ theme_bw()+ theme(aspect.ratio = 1) 図3.1: Matern関数 References "],["Chapter5.html", "4 Linear mixed-effects models and dependency 4.1 White Storks 4.2 Considering the data (wrongly) as one-way nested 4.3 Fitting the one-way nested model using lmer 4.4 Model validation 4.5 Sketching the fitted value 4.6 Considering the data (correctly) as two-way nested 4.7 Differences with the AR1 process approach", " 4 Linear mixed-effects models and dependency 本節では、混合モデルがどのようにデータの非独立性に対処しているのかを見ていく。 4.1 White Storks ここでは、シュバシコウの成長に影響を与える要因を調べた Bouriach et al. (2015) の研究データを用いる。あるコロニー内の多くの巣から、各巣内の複数の雛のデータが複数回ずつにわたって最大生後54日まで収集されている。 ws &lt;- read_csv(&quot;data/whitestork.csv&quot;) datatable(ws, options = list(scrollX = 20), filter = &quot;top&quot;) 雛の成長度合いは、くちばし長で評価されている。図4.1は年齢とくちばし長の関連を図示したものである。 ws %&gt;% ggplot(aes(x = age, y = beak))+ geom_point(shape =1, size = 1.5)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Beak length&quot;, x = &quot;Age&quot;) 図4.1: Scatterplot of beak length (mm) of White Stork chicks versus age (in days). 4.2 Considering the data (wrongly) as one-way nested まず、以下のモデルを考える(回帰係数は省略している)。BLはくちばし長、Ageは日齢、Chickは雛のID、Nestはそのデータが得られた巣のIDを表す。 \\[ \\begin{aligned} BL_i &amp;= Intercept + Age_i + Nest_i + Chick_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] このモデルには2つの大きな問題がある。 巣IDと雛IDは多いので、モデルで膨大なパラメータを推定することになる。 同じ雛/巣から複数のデータが収集されており、疑似反復が生じている。 この問題を解決する方法として、巣ごとの平均をとることができるがサンプルサイズが著しく減少する。また、巣ごとの平均くちばし長というのは生物学的に見て意味のあるものだとは思えない。混合mドエルはこれらの問題を解決する。 4.2.1 model formulation まずは、以下の混合モデルを考える。このモデルは、雛IDについてはひとまず無視し、巣IDをランダム切片として含めている。なお、\\(i\\)は巣IDを表し、\\(j = 1,2,3,\\dots,n_i\\)は巣ごとのデータ数を表す。ここでは、\\(a_i\\)と\\(\\epsilon_{ij}\\)は独立であると仮定されている。 \\[ \\begin{aligned} BL_{ij} &amp;= Intercept + Age_{ij} + a_i + \\epsilon_{ij} \\\\ a_i &amp;\\sim N(0, \\sigma_{nest}^2)\\\\ \\epsilon_{ij} &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] このモデルは、以下のようにも書ける。 \\[ \\begin{aligned} BL_{ij} &amp;= N(\\mu_{ij}, \\sigma^2)\\\\ E(BL_{ij}) &amp;= \\mu_{ij} \\;\\; and \\;\\; var(BL_{ij}) = \\sigma^2 \\\\ \\mu_{ij} &amp;= Intercept + Age_{ij} + a_i \\\\ a_i &amp;\\sim N(0, \\sigma_{nest}^2)\\\\ \\end{aligned} \\tag{4.1} \\] 生態学では、一元配置入れ子モデル(one-way nested model)の線形混合効果モデルと呼ばれる。それでは、混合モデルはどのようにデータの非独立性に対応しているのだろうか。 同じ巣の雛同士は、同じ親に育てられ、生息環境が同じであり、遺伝的にも類似している。よって、同じ巣の雛のくちばし長は独立ではなく、他の巣の雛のくちばし長よりも類似していると考えられる。 同じ巣の雛のくちばし長同士の相関は、この混合モデルでは以下のように書ける。これは級内相関係数(inter class correlation: ICC)とも呼ばれる。なお、このモデルでは異なる巣の雛のくちばし長同士の相関は0であると仮定される。混合モデルでは、このように巣内のデータの非独立性が考慮される。 \\[ cor(BL_{ij}, BL_{ik}) = \\phi = \\frac{\\sigma_{nest}^2}{\\sigma_{nest}^2 + \\sigma^2} \\tag{4.2} \\] 巣1(データ数が6)のデータの相関行列は以下のように書ける。 \\[ \\bf{\\Sigma_1} = cor \\begin{pmatrix} BL_{1,1}\\\\ BL_{1,2}\\\\ BL_{1,3}\\\\ BL_{1,4}\\\\ BL_{1,5}\\\\ BL_{1,6}\\\\ \\end{pmatrix} = \\begin{pmatrix} 1 &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi \\\\ \\phi &amp; 1 &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi \\\\ \\phi &amp; \\phi &amp; 1 &amp; \\phi &amp; \\phi &amp; \\phi \\\\ \\phi &amp; \\phi &amp; \\phi &amp; 1 &amp; \\phi &amp; \\phi \\\\ \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; 1 &amp; \\phi \\\\ \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; \\phi &amp; 1 \\\\ \\end{pmatrix} \\] 他の巣についても同じように書ける(データ数に応じて行列数が変わるだけである)。よって、全ての巣のデータの相関係数は以下のように書ける。なお、\\(n_1, n_2, \\dots, n_{73}\\)は各巣のデータ数である。以上で見たように、同じ巣のデータ同士の相関は\\(\\phi\\)、異なる巣のデータ同士の相関は0であると仮定される。 \\[ \\begin{aligned} cor \\begin{pmatrix} \\begin{pmatrix} BL_{1,1}\\\\ \\vdots\\\\ BL_{1,n_1} \\end{pmatrix}\\\\ \\begin{pmatrix} BL_{2,1}\\\\ \\vdots\\\\ BL_{2,n_2} \\end{pmatrix}\\\\ \\vdots \\\\ \\begin{pmatrix} BL_{73,1}\\\\ \\vdots\\\\ BL_{73,n_{73}} \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} \\bf{\\Sigma_1} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\bf{\\Sigma_2} &amp; \\cdots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\bf{\\Sigma_{73}} \\\\ \\end{pmatrix} \\end{aligned} \\] なお、式(4.2)は一つのランダム切片を持つ線形混合モデルについてのみ当てはまる。一般化線形混合モデル(GLMM)や2つ以上のランダム切片/ランダム傾きをもつ線形混合モデルについては異なる表現が用いられる。 混合モデルはGLSと同様にデータ間の相関をモデルに組み込むことによって、データの非独立性に対処している。なお、ランダム切片の分散\\(\\sigma_{nest}^2\\)について正確な推定を行うためには、少なくとも5以上のクラスター(今回の場合は巣ID)がなくてはならない。 4.3 Fitting the one-way nested model using lmer それでは、モデル(4.1)をRで実行する。ここでは、lme4パッケージのlmer関数を用いる。分析には2012年のデータのみを用いる。 ws2 &lt;- drop_na(ws, beak, age, nest, chick) %&gt;% mutate(fnest = as.factor(nest), fchick = as.factor(chick)) %&gt;% filter(year == &quot;2012&quot;) %&gt;% data.frame() m5_1 &lt;- lmer(beak ~ age + (1|fnest), data = ws2) 結果は以下の通り。 summary(m5_1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: beak ~ age + (1 | fnest) ## Data: ws2 ## ## REML criterion at convergence: 10234.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.9103 -0.5406 -0.0259 0.5768 6.3796 ## ## Random effects: ## Groups Name Variance Std.Dev. ## fnest (Intercept) 57.23 7.565 ## Residual 62.50 7.905 ## Number of obs: 1438, groups: fnest, 73 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 44.4417 0.9651 46.05 ## age 2.9925 0.0169 177.08 ## ## Correlation of Fixed Effects: ## (Intr) ## age -0.301 モデルの結果から、モデル式は以下のように推定されたことが分かる。2行目から\\(a_i\\)を除いた\\(\\mu_{ij} = 44.44 + 2.99\\times Age_{ij}\\)の部分はモデルのfixed partと呼ばれ、平均的な巣におけるくちばし長の期待値を表す(ランダム切片を含まないので)。 \\[ \\begin{aligned} BL_{ij} &amp;= N(\\mu_{ij}, 7.90^2)\\\\ \\mu_{ij} &amp;= 44.44 + 2.99\\times Age_{ij} + a_i \\\\ a_i &amp;\\sim N(0, 7.56^2)\\\\ \\end{aligned} \\] 級内相関\\(\\phi\\)は以下のように求められる。 \\[ \\phi = \\frac{7.56^2}{7.56^2 + 7.90^2} = 0.49 \\] Rでは以下のように求める。よって、同じ巣内のデータ同士の相関は0.47と推定されたことが分かる。 sigma_ranef &lt;- VarCorr(m5_1) %&gt;% as.data.frame() %&gt;% .[1,5] sigma_ranef^2/(sigma_ranef^2 + sigma(m5_1)^2) ## [1] 0.4780135 fixed partの予測値と95%信頼区間を表したのが図4.2である。 nd5_1 &lt;- data.frame(age = seq(min(ws2$age), max(ws2$age), by = 1)) ## 説明変数を含む行列 X &lt;- model.matrix(~age, data = nd5_1) ## 予測値と95％信頼区間の算出 fitted5_1 &lt;- nd5_1 %&gt;% ## 予測値はbeta × Xで求まる mutate(fitted = X %*% fixef(m5_1) %&gt;% .[,1]) %&gt;% ## 予測値のseは以下の通り mutate(se = sqrt(diag(X %*% vcov(m5_1) %*% t(X)))) %&gt;% mutate(ci.low = fitted - 1.96*se, ci.high = fitted + 1.96*se) fitted5_1 %&gt;% ggplot(aes(x = age, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = ci.low, ymax = ci.high), alpha = 0.2)+ geom_point(data = ws2, aes(y = beak), shape =1, size = 1.5)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Beak length&quot;, x = &quot;Age&quot;) 図4.2: Fixed part of the linear mixed-effects model. The shaded area is a 95% confidence interval for the mean. 4.4 Model validation このモデルはまだ性別の効果を考慮していない他、雛IDの非独立性についても考慮していない。よって、ここではモデル診断は行わない。 4.5 Sketching the fitted value それぞれの巣について推定された\\(a_i\\)は以下の通り。これは、モデルのrandom partと呼ばれる。 ranef(m5_1) %&gt;% data.frame() %&gt;% rename(estimated = condval, sd = condsd) %&gt;% mutate_if(is.numeric, ~round(., 2)) %&gt;% datatable() fixed partとrandom partを足した各巣の予測値を示したのが図4.3である。なお、赤い線は図4.2で示したfixed partのみの直線を示している。それぞれの直線は、ここランダム効果の分だけ上/下にシフトしている。 predict(m5_1) %&gt;% data.frame() %&gt;% rename(predicted = 1) %&gt;% bind_cols(ws2) %&gt;% ggplot(aes(x = age))+ geom_line(aes(y = predicted, group = fnest))+ geom_point(aes(y = beak), shape = 1,size =1.5)+ geom_line(data= fitted5_1, aes(y = fitted), color = &quot;red3&quot;, linewidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Beak length&quot;, x = &quot;Age&quot;) 図4.3: Fixed part plus the random effects for the linear mixed-effects model. 4.6 Considering the data (correctly) as two-way nested さて、それでは次に雛IDも考慮したモデルを考える。データでは同じ雛から複数のデータが収集されており、ここでも疑似反復が生じているからである。同じ雛から得られたデータは、同じ巣の他の雛のデータよりも類似していると考えられる。 以下のようなモデルを考える。このようなモデルは、two-way nested linear mixed-effects modelと呼ばれる。なお、\\(i\\)は巣IDを、\\(j\\)は巣ごとの雛IDを、\\(k\\)は巣\\(i\\)における\\(j\\)番目の雛の\\(k\\)個目のデータであることを表す。 \\[ \\begin{aligned} BL_{ijk} &amp;= N(\\mu_{ijk}, \\sigma^2)\\\\ E(BL_{ijk}) &amp;= \\mu_{ijk} \\;\\; and \\;\\; var(BL_{ijk}) = \\sigma^2 \\\\ \\mu_{ijk} &amp;= Intercept + Age_{ijk} + a_i + b_{ij} \\\\ a_i &amp;\\sim N(0, \\sigma_{nest}^2)\\\\ b_{ij} &amp;\\sim N(0, \\sigma_{chick}^2)\\\\ \\end{aligned} \\tag{4.3} \\] このモデルでは、同じ巣内の異なるデータ間に相関があり、かつ同じ雛の異なるデータ間にも相関があることを仮定している。なお、異なる巣のデータ間は独立だと仮定されている。 同じ巣内の同じ雛のデータ間の相関は以下の式で与えられる。 \\[ \\phi_{chick} = \\frac{\\sigma_{nest}^2 + \\sigma_{chick}^2}{\\sigma_{nest}^2 + \\sigma_{chick}^2 + \\sigma^2} \\] また、同じ巣内の異なる雛間のデータの相関は以下の式で表せられる。 \\[ \\phi_{nest} = \\frac{\\sigma_{nest}^2}{\\sigma_{nest}^2 + \\sigma_{chick}^2 + \\sigma^2} \\] このモデルは、Rで以下のように実行できる。 m5_2 &lt;- lmer(beak ~ age + (1|fnest/fchick), data = ws2) 結果は以下の通り。 summary(m5_2) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: beak ~ age + (1 | fnest/fchick) ## Data: ws2 ## ## REML criterion at convergence: 9932.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.3657 -0.5617 -0.0678 0.5513 6.9810 ## ## Random effects: ## Groups Name Variance Std.Dev. ## fchick:fnest (Intercept) 29.70 5.449 ## fnest (Intercept) 47.81 6.915 ## Residual 40.81 6.388 ## Number of obs: 1438, groups: fchick:fnest, 262; fnest, 73 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 44.41110 0.93656 47.42 ## age 2.97532 0.01406 211.63 ## ## Correlation of Fixed Effects: ## (Intr) ## age -0.245 iccはそれぞれ\\(phi_{chick} = 0.66\\)、\\(phi_{nest} = 0.40\\)と推定された。 sigma_chick &lt;- VarCorr(m5_2) %&gt;% as.data.frame() %&gt;% .[1,5] sigma_nest &lt;- VarCorr(m5_2) %&gt;% as.data.frame() %&gt;% .[2,5] sigma &lt;- sigma(m5_2) ## phi_nest sigma_nest^2/(sigma^2 + sigma_chick^2 + sigma_nest^2) ## [1] 0.4040858 ## phi_chick (sigma_nest^2+sigma_chick^2)/(sigma^2 + sigma_chick^2 + sigma_nest^2) ## [1] 0.6550681 モデルの結果を図示したのが図4.4である。黒い線はモデルの fixed partの予測値を、赤い点線は巣6(Ap2)の予測値(\\(\\mu_{ijk} + a_i\\))を示している。また、2本の赤い直線は巣6の雛2頭の予測値(\\(\\mu_{ijk} + a_i + b_{ij}\\))を、赤い点はその2頭のデータを示している。これを見ると、2頭の雛の予測値は巣の予測値から近いことが分かる。これは、雛IDのランダム切片よりも巣IDのランダム切片の方が予測値への影響が大きいことを示している。\\(\\phi_{chick}\\)と\\(\\phi_{nest}\\)の値が近いほどこのことがいえる。 re_Ap2 &lt;- ranef(m5_2)$fnest[6,1] fitted5_2_fixed &lt;- ggpredict(m5_2, terms = &quot;age[1:54,by=0.1]&quot;, type = &quot;fixed&quot;) %&gt;% rename(age = x) %&gt;% mutate(fitted_Ap2 = predicted + re_Ap2) fitted5_2 &lt;- predict(m5_2) %&gt;% data.frame() %&gt;% bind_cols(ws2) %&gt;% rename(fitted = 1) fitted5_2_fixed %&gt;% ggplot(aes(x = age, y = predicted))+ geom_line(linewidth = 1)+ geom_line(aes(y = fitted_Ap2), data = . %&gt;% filter(age &gt;= 6 &amp; age &lt;= 29), linewidth = 0.8, color = &quot;red3&quot;, linetype = &quot;dashed&quot;)+ geom_line(data = fitted5_2 %&gt;% filter(fnest== &quot;Ap2&quot;), aes(y = fitted, group = fchick), color = &quot;red3&quot;, linewidth = 1)+ geom_point(data = ws2, aes(y = beak), shape = 1, size = 1) + geom_point(data = ws2 %&gt;% filter(fnest == &quot;Ap2&quot;), aes(y = beak, shape = fchick), size = 4, color = &quot;red3&quot;)+ scale_shape_manual(values = c(16,18))+ theme_bw()+ theme(aspect.ratio = 1) 図4.4: Fitted values due to the fixed part, fixed part + the random intercept Nest, and fixed part + the random intercept Nest + the random intercept Chick. one-way nested model とtwo-way nested model を比較するとパラメータの推定値と標準偏差がわずかに違う。AICを用いてどちらが良いかを調べることもできるが、疑似反復が解消されているtwo-way nested modelを選ぶべきである。 compare_parameters(m5_1, m5_2, select = &quot;{estimate}&lt;br&gt;({se})|{p}&quot;) %&gt;% data.frame() %&gt;% mutate_if(is.numeric, ~round(.,2)) %&gt;% select(1,4,5,12,13) 4.7 Differences with the AR1 process approach 第2章で見たような残差AR1過程モデルは残差に時間的な相関があると仮定して疑似反復に対処したが、必ずしも応答変数に時間的相関を仮定したわけではなかった。一方で、混合モデルは応答変数に従属構造があることを考慮して疑似反復に対処している。 References "],["Chapter6.html", "5 Modelling space explicitly 5.1 Model formulation 5.2 Covariance matrix of the spatial random effect 5.3 Spatial-temporal correlation", " 5 Modelling space explicitly 本章では、混合モデルのように残差ではなく応答変数に直接従属構造を仮定して空間的相関に対処する方法を見ていく。ただし、通常の混合モデルのランダム切片が正規分布からそれぞれ独立に得られると仮定する一方で、今回はランダム切片が空間的相関を持つことを仮定してモデリングを行う。こうしたモデルの実装を頻度論的な手法で行うことは難しいため、実際のモデリングは次章でベイズ統計について学んでから行う。 5.1 Model formulation ここでは、前章と同じくシュバシコウのデータ(Bouriach et al. 2015)を用いて話を進める。 まず通常の線形回帰モデルから始めよう。巣IDや雛IDの効果について無視したとき、以下のように書ける。\\(i\\)はデータの番号を表し、全部で1438ある。 \\[ \\begin{aligned} BL_i &amp;= \\alpha + Age_i \\times \\beta + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルは以下のようにも書ける。なお、\\(z_i = (1, Age_i)\\)である。1列目の1は切片を表している。\\(\\bf{\\beta} = \\begin{pmatrix} \\alpha\\\\ \\beta \\end{pmatrix}\\)である。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{5.1} \\] 式(5.1)は単純な線形回帰モデルであり、残差はそれぞれ正規分布から独立に得られると仮定されている。\\(\\bf{\\epsilon} = (\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_{1438})\\)とするとき、\\(\\bf{\\epsilon} \\sim N(0,\\bf{\\Sigma})\\)と書ける。なお、\\(\\bf{\\Sigma}\\)は\\(\\bf{I}\\)を単位行列とするとき\\(\\sigma^2 \\times \\bf{I}\\)と書ける。第2で見たように、このとき\\(\\bf{\\Sigma}\\)は対角成分以外が0の行列なので、残差同士の相関は0であると仮定されている。 そこで、空間的な相関に対処するために式(5.1)に空間的相関を表す要素を付け足す。本書では、これを\\(u_i\\)と表す。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + u_i + \\epsilon_i\\\\ epsilon_i &amp;\\sim N(0,\\sigma^2)\\\\\\ \\end{aligned} \\tag{5.2} \\] ここで、\\(u_i\\)は平均が0で、分散共分散行列が\\(\\bf{\\Omega}\\)に従う正規分布から得られると考える。ただし、\\(\\bf{\\Omega}\\)は通常のランダム切片のように対角行列(対角成分以外が0の行列)ではなく、空間相関を考慮している。 よって、このモデルは以下のように書ける。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + u_i + \\epsilon_i\\\\ \\bf{\\epsilon} &amp;\\sim N(0,\\sigma^2 \\times \\bf{I})\\\\ \\bf{u} &amp;\\sim N(0, \\bf{\\Omega}) \\end{aligned} \\tag{5.3} \\] 5.2 Covariance matrix of the spatial random effect \\(\\bf{\\Omega}\\)の成分全てを推定するのは非常に難しい。今回のように1438個のデータがあるのであれば、\\(1438 \\times 1437 \\times 1/2 = 1033203\\)このパラメータを推定してければいけなくなる。そこで、第2章(AR1過程)や第3章(バリオグラムモデル)でやったように、推定するパラメータを減らすために何らかの数理モデルを用いる。 ここでは、第3.3節で導入したMatern相関関数を用いる。この関数では、2つのパラメータさえ推定すればよい。 5.2.1 Simulation study 以下では、Matern関数がどのように\\(\\bf{\\Omega}\\)を決定するかをシミュレーションを用いて説明する。 以下のように、5つの場所をランダムに定める(図5.1)。 set.seed(123) Xloc &lt;- runif(5, 0, 1) Yloc &lt;- runif(5, 0, 1) Loc &lt;- cbind(Xloc, Yloc) Loc %&gt;% data.frame() %&gt;% mutate(n = 1:n()) %&gt;% ggplot(aes(x = Xloc, y = Yloc))+ geom_text(aes(label = n))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;X coordinates&quot;, y = &quot;Y coordinates&quot;)+ scale_x_continuous(breaks = seq(0.3,1,0.1))+ scale_y_continuous(breaks = seq(0,1,0.2)) 図5.1: Position of five sampling locations in our simulation study. ここで、それぞれの場所で雛のくちばし長のデータを収集したとする。式(5.2)より、5つのランダム切片\\(u_1, u_2, \\dots, u_5\\)を推定する必要がある。\\(u_i\\)は平均が0、分散共分散行列が\\(\\bf{\\Omega}\\)の正規分布から得られるとする。\\(\\bf{\\Omega}\\)は以下で与えられるとする。 \\[ \\bf{\\Omega} = \\sigma_u^2 \\times \\begin{pmatrix} 1 &amp; \\omega_{12} &amp; \\omega_{13} &amp; \\omega_{14} &amp; \\omega_{15} \\\\ &amp; 1 &amp; \\omega_{23} &amp; \\omega_{24} &amp; \\omega_{25} \\\\ &amp; &amp; 1 &amp; \\omega_{34} &amp; \\omega_{35} \\\\ &amp; &amp; &amp; 1 &amp; \\omega_{45} \\\\ &amp; &amp; &amp; &amp; 1 \\end{pmatrix} \\] ここで、行列の各要素はMatern関数によって定まるとする。第3.3節で見たように、Matern関数は距離と2つの未知のパラメータで定まる関数である。よって、この2つのパラメータが定まれば全ての\\(\\omega\\)が定まる。 \\[ \\omega_{ij} = cov(u_i,u_j) = \\sigma_u^2 \\times \\rm{Matern \\; correlation \\; sites \\; i \\; and\\;j} \\tag{5.4} \\] それでは、以下で実際にパラメータを定めて\\(\\omega_{ij}\\)を計算してみよう。まず、データ間の距離を算出する。 Dist &lt;- dist(Loc) %&gt;% as.matrix() Dist ## 1 2 3 4 5 ## 1 0.0000000 0.69540037 0.8555197 0.78132050 0.7715140 ## 2 0.6954004 0.00000000 0.5259413 0.09754322 0.1681197 ## 3 0.8555197 0.52594131 0.0000000 0.58393877 0.6873190 ## 4 0.7813205 0.09754322 0.5839388 0.00000000 0.1108665 ## 5 0.7715140 0.16811974 0.6873190 0.11086647 0.0000000 次にMatern関数のパラメータを定める。ここでは、\\(\\kappa = 4, \\nu = 1\\)とする。また、\\(\\sigma_u\\)も1とする。 kappa &lt;- 5 nu &lt;- 1 sigma_u &lt;- 1 式(5.4)より、\\(\\omega_{ij}\\)は以下のように求まる。 d.vec &lt;- as.vector(Dist) cor.M &lt;- sigma_u * (2^(1-nu))/gamma(nu) * (kappa * d.vec)^nu * besselK(kappa*d.vec, nu) \\(\\omega_{ij}\\)と距離の関係を図示すると以下のようになる。ここからわかるように、距離が近いほど共分散\\(\\omega_{ij}\\)が大きくなっている。 data.frame(dist = d.vec, omega = cor.M) %&gt;% drop_na() %&gt;% ggplot(aes(x = dist, y = omega))+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Distance&quot;, y = &quot;Covariance&quot;) 行列\\(\\bf{\\Omega}\\)は以下の通り。図5.1と見比べると、実際に距離が近いデータほど値が高くなっていることが分かる(e.g., 2と4、4と5)。 omega &lt;- matrix(cor.M, ncol = 5, nrow = 5) diag(omega) &lt;- 1 colnames(omega) &lt;- 1:5 rownames(omega) &lt;- 1:5 omega %&gt;% kable(digits = 3, align = &quot;c&quot;, caption = &quot;Ω&quot;) %&gt;% kable_styling(font_size = 15, full_width = FALSE) 表5.1: Ω 1 2 3 4 5 1.000 0.079 0.039 0.054 0.057 0.079 1.000 0.166 0.834 0.671 0.039 0.166 1.000 0.129 0.082 0.054 0.834 0.129 1.000 0.803 0.057 0.671 0.082 0.803 1.000 以上をまとめると、以下のようになる。 データ間の空間的相関を決める分散共分散行列\\(\\bf{\\Omega}\\)をMatern関数を用いて定義する。 Matern関数では、距離が近いほど\\(\\bf{\\Omega}\\)の行列成分\\(\\omega\\)の値が大きくなり、ひいては\\(u_i\\)の値が近くなっていく。 第??章以降では、INLAというパッケージを用いて式(5.2)をモデリングしていく。 5.3 Spatial-temporal correlation ここまで時系列相関と空間相関について別々に扱ってきたが、現実のデータではどちらもが同時に存在することが多々ある。例えば、シュバシコウのデータ(Bouriach et al. 2015)では様々な巣において4年間にわたるデータが収集された。 以下では、再びシュバシコウのデータを用いて空間モデルを時空間モデル(spatial-temporal model)に拡張していく。\\(BL_{it}\\)を場所\\(i\\)、時間\\(t\\)におけるくちばし長、\\(Z_i = (1, Age_{it})\\)とするとき、以下のようにモデルを拡張する。 \\[ \\begin{aligned} BL_i &amp;= z_i \\times \\bf{\\beta} + w_{it} + \\epsilon_i\\\\ epsilon_i &amp;\\sim N(0,\\sigma^2)\\\\\\ \\end{aligned} \\tag{5.5} \\] なお、\\(w_{it}\\)は時系列相関を考慮するため以下のように定式化する。\\(\\phi\\)は-1から1までの値をとるパラメータである。\\(w_{it}\\)は\\(\\phi\\)が大きいほど1時点前の\\(w_{i,t-1}\\)と類似する。 \\[ w_{it} = \\phi \\times w_{i, t-1} + u_{it} \\] 5.3.1 Simulation study (continued) \\(u_{it}\\)は空間相関を表す項で、第5.2と同様に平均0, 分散共分散行列が\\(\\bf{\\Omega}\\)の正規分布から得られるとする。 \\[ \\begin{pmatrix} u_{1t}\\\\ \\vdots\\\\ u_{5t} \\end{pmatrix} \\sim N(0, \\bf{\\Omega}) \\] 式(5.4)と同様に、\\(\\bf{\\Omega}\\)は以下のように書ける。なお、\\(u_{it}\\)には時間的な相関はない。 \\[ \\bf{Omega} = \\sigma_u^2 \\times \\rm{Matern \\; correlation \\; sites \\; i \\; and\\;j} \\] それでは、\\(w_{it}\\)がどのように決まるか実際にシミュレーションを行ってみよう。 まず、時間的当館が強く、\\(\\phi = 0.9\\)であるとする。 phi &lt;- 0.9 100時点(\\(t = 1,2,3,\\dots,100\\))のデータが5地点(\\(i = 1,2,\\dots,5\\))について収集されたとする。このとき、時点1のデータ\\(w_{i,1}\\)は以下のように得られる(数学的な詳細はここでは省略)。 \\[ \\begin{pmatrix} w_{1,1}\\\\ \\vdots\\\\ w_{5,1} \\end{pmatrix} \\sim N(0, \\frac{\\sigma_u^2}{1-\\phi^2} \\times \\bf{\\Omega}) \\] なお、\\(\\sigma_u^2 = 1\\)であるとし、\\(\\bf{\\Omega}\\)は前節と同じものを使用する。以下で\\(w_{i,1}\\)が得られた。 sigma_u &lt;- 1 cov.w1 &lt;- (sigma_u^2/(1-phi^2))+omega w1 &lt;- mvrnorm(1, mu = rep(0,5), Sigma = cov.w1) よって、\\(t = 2,3,\\dots,100\\)のときの\\(w_{it}\\)っは以下のように得られる。 w &lt;- matrix(nrow = 5, ncol = 100) w[,1] &lt;- w1 colnames(w) &lt;- str_c(&quot;t&quot;, 1:100) for(t in 2:100){ u &lt;- mvrnorm(1, mu = rep(0,5), Sigma = omega) w[, t] &lt;- phi*w[t-1] + u } 以下のように5地点における100時点の\\(w_{it}\\)が得られた。 w %&gt;% data.frame() %&gt;% rownames_to_column(var = &quot;place&quot;) %&gt;% mutate_if(is.numeric, ~round(.,3)) %&gt;% datatable(options = list(scrollX = 20), filter = &quot;top&quot;) これを図示すると以下のようになる。場所が近い地点のデータ(2,4,5)はそれ以外のデータよりもより類似している傾向があることが分かる。 w %&gt;% data.frame() %&gt;% rownames_to_column(var = &quot;place&quot;) %&gt;% pivot_longer(2:101, names_to = &quot;time&quot;, values_to = &quot;w&quot;) %&gt;% mutate(time = as.numeric(str_replace(time, &quot;t&quot;,&quot;&quot;))) %&gt;% ggplot(aes(x = time, y = w))+ geom_line(aes(linetype = place, linewidth = place %in% c(&quot;2&quot;,&quot;4&quot;,&quot;5&quot;)))+ scale_linewidth_manual(values = c(0.6,1.2))+ theme_bw()+ theme(aspect.ratio = 0.8)+ labs(linewidth = &quot;if place is 2, 4, or 5&quot;) 実際の分析では、\\(w_{it}\\)を得るためのパラメータ(\\(\\phi, \\sigma_u, \\kappa, \\nu\\)は与えられるものではなく、データから推定することになる。データの推定は非常に複雑なので、ベイズ推定が必要になってくる。次章ではベイズ統計について学ぶ。 References "],["Chapter7.html", "6 Introduction to Bayesian statistics 6.1 Why go Bayesian? 6.2 General probability rules 6.3 The mean of a distribution 6.4 Bayes theorem again 6.5 Conjugate priors 6.6 Markov chain Monte Carlo simulation 6.7 Integrated nested Laplace approximation 6.8 Examples using R-INLA 6.9 追記", " 6 Introduction to Bayesian statistics 本章では、ベイズ統計とマルコフ連鎖モンテカルロ法(MCMC)、integrated nested Laplace approximations(INLA)について解説を行う。 6.1 Why go Bayesian? ベイズ統計を使うモチベーションとしてはいくつかある。 事前に持っている知識を分析に取り入れるため。 後に見るように、ベイズ統計では事前分布という形であらかじめ持っている知識を分析に組み込むことができる。 頻度論的な統計学に対する批判から 頻度論的な統計学とは、いわゆる帰無仮説検定(p値)に基づく統計学を指すが、p値や信頼区間などをめぐってはその解釈のしにくさや論理的な問題点に対してたびたび批判的な意見も投げかけられている(e.g., 岡田 and 大久保 2012; 松浦 2016)。 複雑なモデルを使用するため 時空間相関を考慮したGLMやGLMMなどの複雑なモデルは、通常の頻度論的な枠組みでは扱えないことが多い。ベイズ統計はこうした複雑なモデルを柔軟にモデリングすることを可能にする。 頻度論ではパラメータはある1つの真値を持つと考えられる一方で、ベイズ統計ではパラメータはある確率的な分布に従っているとされる(Kruschke 2014; 松浦 2016, ; 馬場 2019; McElreath 2020)。ベイズ統計を用いた分析では、データが得られた時のパラメータの分布(= 事後分布)を最終的に得る(\\(P(\\beta|D)\\))。一方で、頻度論的な統計学ではパラ、エータがある値のときにデータが得られる確率(\\(P(D|\\beta)\\))を計算する(= 尤度)。 6.2 General probability rules まず確立の基本から確認していく。\\(P(A)\\)と\\(P(B)\\)をそれぞれ事象Aが生じる確率、事象Bが生じる確率とする。また、\\(P(A \\cap B)\\)をAかつBである確率、\\(P(A \\cup B)\\)をAまたはBである確率とする。このとき、 \\[ P(A \\cap B) = P(B \\cap A) \\] である。また、AとBが独立であるときは以下のように書ける。 \\[ P(A \\cap B) = P(A) \\times P(B) \\] 一方、AとBが独立でないとき以下のように書ける。なお、\\(P(A|B)\\)は条件付き確率を表し、事象Bが生じたときに事象Aが生じる確率を表す。 \\[ \\begin{aligned} P(A \\cap B) &amp;= P(A|B) \\times P(B)\\\\ P(A \\cap B) &amp;= P(B|A) \\times P(A) \\end{aligned} \\tag{6.1} \\] よって、以下の式が導かれる。これを、ベイズの定理という。 \\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\tag{6.2} \\] 6.3 The mean of a distribution ある変数\\(Y\\)がパラメータ\\(\\mu\\)のポワソン分布から得られるとき、\\(Y\\)の期待値は\\(\\mu\\)である。このことは以下のように書ける。 \\[ \\begin{aligned} &amp;Y \\sim Poisson(\\mu)\\\\ &amp;E(Y) = \\mu \\end{aligned} \\] \\(Y\\)が離散的な値のとき、その期待値は以下のように書ける。なお、\\(y\\)は\\(Y\\)がとりうる全ての値を表す。よって、離散的な変数に関する確率分布(ポワソン分布、ベルヌーイ分布、二項分布、負の二項分布など)の期待値は以下の式で求められる。 \\[ E(Y) = \\sum_y y \\times p(y) \\tag{6.3} \\] ポワソン分布は\\(p(y) = \\frac{e^{-\\mu} \\times \\mu^y}{y!}\\)なので、式(6.3)は以下のように書ける。この式を計算すると右辺は\\(\\mu\\)になる。 \\[ E(Y) = \\sum_{y =0} ^\\infty y \\times \\frac{e^{-\\mu} \\times \\mu^y}{y!} \\tag{6.4} \\] もし変数\\(Y\\)が連続的な値の場合、その期待値は\\(\\int\\)を用いて以下のように書ける。よって、連続的な変数に関する確率分布(正規分布、ガンマ分布、β分布など)の期待値は以下の式で求められる。 \\[ E(Y) = \\int _{-\\infty} ^{\\infty} y \\times p(y) dy \\tag{6.5} \\] 6.4 Bayes theorem again ベイズの定理(式(6.2))を用いて、データ(D)が得られたときにパラメータ\\(\\beta\\)がとりうる確率の分布\\(P(\\beta|D)\\)は以下のように書ける。 \\[ P(\\beta|D) = \\frac{P(D|\\beta) \\times P(\\beta)}{P(D)} \\] \\(P(\\beta|D)\\)は、データが得られた時のパラメータ\\(\\beta\\)の事後分布(posterior distribution)という。事後分布こそが、私たちがデータからパラメータを推定するときに求めたいものである。 \\(P(D|\\beta)\\)はあるパラメータ\\(\\beta\\)が与えられたときにデータが得られる確率であり、いわゆる尤度(likelihood)である。\\(P(\\beta)\\)はデータが与えられていない状態でのパラメータ\\(\\beta\\)が得られる確率分布で事前分布(prior distribution)と呼ばれる。 最後に、\\(P(D)\\)はデータが得られる確率で、事後分布の合計を1にするための役割を果たす。これは周辺尤度と言われ、通常計算することが難しいので省略されることが多い。このとき、式(6.2)は以下のように書ける。なお、\\(\\propto\\)は左辺が右辺に比例することを表す。 \\[ P(\\beta|D) \\propto P(D|\\beta) \\times P(\\beta) \\tag{6.6} \\] この式は、事後分布は尤度と事前分布の積に比例していることを示している。また、事後分布の期待値は式(6.5)から以下のように書ける。 \\[ E(\\beta|D) = \\int_{-\\infty} ^\\infty \\beta \\times P(\\beta|D) d\\beta \\] 次節以降では、事後分布とその期待値をどのように推定するかをみていく。 6.5 Conjugate priors 第2章で調べたように、ミサゴの卵の厚さが殺虫剤の崩壊産物(DDD)によって変わるかを検討するとする(Steidl et al. 1991)。第2と同様に以下のモデルを考える。 \\[ \\begin{aligned} &amp;\\mu_i = \\beta_1 + DDD_i \\times \\beta_2 \\\\ &amp;Thickness_i \\sim N(\\mu_i,\\sigma^2) \\end{aligned} \\tag{6.7} \\] ここで、切片\\(\\beta_1\\)と\\(\\sigma\\)は分かっていると仮定し、事後分布\\(P(\\beta_2|D)\\)を推定するとしよう。これを求めるには、式(6.6)で触れたように尤度\\(P(D|\\beta_2)\\)と事前分布\\(P(\\beta_2)\\)が必要である。 6.5.1 Likelihood function \\(P(D|\\beta_2)\\)はパラメータ\\(\\beta_2\\)が与えられたときにデータDが得られる確率、すなわち尤度である。卵の殻の厚さは連続変数なので、ここではモデル式にあるようにデータが正規分布から得られていると仮定する。 このとき、尤度は式(6.7)より以下のように書ける1。 \\[ P(D|\\beta_2) = \\prod_i ^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp\\Bigl(-\\frac{(Thickness_i - \\beta_1 - DDD_i \\times \\beta_2)^2}{2\\sigma^2}\\Bigl) \\tag{6.8} \\] 頻度論的な統計学では、この尤度が最大になるようにパラメータ\\(\\beta_2\\)を決定する。これは最尤推定法(maximum likelihood estimation)と呼ばれ、Rではglm関数などで実装されている。 6.5.2 Priors 続いて、事前分布\\(P(\\beta_2)\\)について考える。これには、先行研究などの結果や生物学的知識などから予想される分布を適用することができる。事前分布としては、例えば以下のように正規分布を仮定することができる。 \\[ \\beta_2 \\sim N(\\beta_2^0, \\sigma_0^2) \\] このとき、事前分布の確率密度関数は以下のように書ける。 \\[ P(\\beta_2) = \\frac{1}{\\sqrt{2 \\pi \\sigma_0^2}} exp\\Bigl(-\\frac{(\\beta_2 - \\beta_2^0)^2}{2\\sigma_0^2}\\Bigl) \\tag{6.9} \\] 6.5.3 Posterior distribution 式(6.8)の尤度と式(6.9)の事前分布から、事後分布は以下のように書ける。 \\[ \\begin{aligned} P(\\beta_2|D) &amp;\\propto P(D|\\beta_2) \\times P(\\beta_2) \\\\ &amp;= \\left[\\prod_i ^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp\\Bigl(-\\frac{(Thickness_i - \\beta_1 - DDD_i \\times \\beta_2)^2}{2\\sigma^2}\\Bigl) \\right] \\times \\left[ \\frac{1}{\\sqrt{2 \\pi \\sigma_0^2}} exp\\Bigl(-\\frac{(\\beta_2 - \\beta_2^0)^2}{2\\sigma_0^2}\\Bigl) \\right] \\end{aligned} \\] これは複雑な計算になるが、正規分布同士を掛け合わせているので事後分布も正規分布になる。このように、事前分布と事後分布の分布の関数形が同じになるようなとき、ベイズ統計ではこれらを共役分布という。このような分布の組み合わせはいくつかある(こちらを参照)。 これを計算すれば、事後分布やその期待値などを計算で求めることができる。なお、今回の場合は以下のような形になる。\\(\\hat{\\beta_2}\\)は\\(\\beta_2\\)の最尤推定値である。 \\[ \\begin{aligned} &amp;w = \\frac{\\sigma_0^2 \\times \\rm{something}}{\\sigma_0^2 \\times \\rm{something} + \\sigma^2}\\\\ &amp;E(\\beta_2|D) = \\hat{\\beta_2} \\times w + (w-1) \\times \\beta_2^0 + \\rm{Ugly \\; stuff} \\\\ &amp;var(\\beta_2|D) = \\sigma^2 \\times \\frac{w}{\\rm{Ugly \\; stuff}} \\end{aligned} \\tag{6.10} \\] 6.5.4 Diffuse prior 多くの場合、私たちは事前分布に関する知識を持たない。そのとき、以下のように非常に広い分布を事前分布として指定することが多い。 \\[ \\beta_2 \\sim N(0, 100) \\Leftrightarrow \\beta_2^0 = 0 \\; and \\; \\sigma_0 = 100 \\] このとき、\\(\\beta_2\\)はだいたい-200から200の間の値をとりうるということになる。このように広い範囲をもつ事前分布を無情報事前分布という。 無情報事前分布のとき(= \\(\\sigma_0\\)が大きいとき)、式(6.10)の\\(w\\)は1に近づく。よって、\\(P(\\beta_2|D)\\)の期待値は\\(\\hat{\\beta_2}\\)に近づき、頻度論的な統計学と同様に最尤推定値となる。 \\[ P(\\beta_2|D) \\approx \\hat{\\beta_2} \\] 実際に分布を書いてみるとこのことがよくわかる。図6.1は無情報事前分布のときの事前分布、尤度関数、事後分布を図示したものである。なお、\\(\\beta_1 = 51.7, \\sigma = 5.17\\)としている。無情報事前分布の場合、尤度関数と事後分布の形がほとんど同じになっていることが分かる。その結果、尤度関数における最尤推定値が事後分布の期待値とほぼ一致するのである。 beta2 &lt;- seq(-20, 10, length.out = 100) beta1 &lt;- 51.7 sigma &lt;- 5.17 ## 尤度 likelihood &lt;- vector() for(i in 1:100){ likelihood[i] &lt;- prod(dnorm(osp$THICK, mean = beta1 + beta2[i]*osp$DDD, sd = sigma)) } ## prior prior &lt;- dnorm(beta2, mean = 0, sd = 100) ## 図示 data.frame(beta2 = beta2, likelihood = likelihood, prior = prior) %&gt;% mutate(posterior = prior*likelihood) %&gt;% pivot_longer(2:4, names_to = &quot;type&quot;, values_to = &quot;probability&quot;) %&gt;% mutate(type = fct_relevel(type, &quot;prior&quot;,&quot;likelihood&quot;,&quot;posterior&quot;)) %&gt;% ggplot(aes(x = beta2))+ geom_line(aes(y = probability), linewidth = 1)+ facet_rep_wrap(~type, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(size = 13)) 図6.1: Prior, likelihood, and posterior distribution. 6.5.5 Informative prior 一方で、パラメータ\\(\\beta_2\\)に関してあらかじめ知識がある場合(e.g., 生態学的に考えて、ある範囲しか取り得ないなど)には、より狭い分布を持つ情報事前分布を用いることもできる。 例えば、以下のように非常に狭い事前分布を指定することもできる。 \\[ \\beta_2 \\sim N(-18, 1) \\Leftrightarrow \\beta_2^0 = -18 \\; and \\; \\sigma_0 = 1 \\] このとき、式(6.10)の\\(w\\)は0に近づいていく。その結果、事後分布の期待値は事前分布の期待値\\(\\beta_2^0\\)に近づいていく。 \\[ P(\\beta_2|D) \\approx \\beta_2^0 \\] これも図示してみるとよくわかる。図6.2は情報事前分布のときの事前分布、尤度関数、事後分布を図示したものである。このとき事後分布と事前分布の分布の形がほとんど同じになっていることが分かる。その結果、事後分布の期待値が事前分布の期待値とほとんど同じになるのである。 beta2 &lt;- seq(-23, 10, length.out = 100) beta1 &lt;- 51.7 sigma &lt;- 5.17 ## 尤度 likelihood &lt;- vector() for(i in 1:100){ likelihood[i] &lt;- prod(dnorm(osp$THICK, mean = beta1 + beta2[i]*osp$DDD, sd = sigma)) } ## prior prior &lt;- dnorm(beta2, mean = -18, sd = 1) ## 図示 data.frame(beta2 = beta2, likelihood = likelihood, prior = prior) %&gt;% mutate(posterior = prior*likelihood) %&gt;% pivot_longer(2:4, names_to = &quot;type&quot;, values_to = &quot;probability&quot;) %&gt;% mutate(type = fct_relevel(type, &quot;prior&quot;,&quot;likelihood&quot;,&quot;posterior&quot;)) %&gt;% ggplot(aes(x = beta2))+ geom_line(aes(y = probability), linewidth = 1)+ facet_rep_wrap(~type, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(size = 13)) 図6.2: Prior, likelihood, and posterior distribution. 以上のように、事前分布が情報を持たないほど(= 幅が広いほど)事後分布の期待値は最尤推定値に近づき、情報を持つほど(= 幅が狭いほど)事後分布の期待値は事前分布の期待値に近づく。 今回は\\(\\beta_2\\)についてのみ事前分布を設定したが、実際の分析では全てのパラメータについて事前分布を設定する必要がある。回帰係数の事前分布としては、正規分布やt分布などが用いられることが多い。一方で、標準偏差\\(\\sigma\\)は必ず0より大きい値をとるので、こうした分布は事前分布として不適切なことが多い。事前分布の選択については、こちらを参照。 Ntzoufras (2011) は、線形モデルの場合回帰係数\\(\\beta\\)の事前分布が正規分布、\\(\\sigma\\)の事前分布として逆ガンマ関数を用いると事前分布と事後分布が共役な分布になるとしている。\\(\\sigma^2\\)の事前分布として逆ガンマ関数を用いるのは、\\(\\tau = 1/\\sigma^2\\)の事前分布としてガンマ関数を用いるのと同じである。このとき、\\(\\tau\\)はprecision(精度)と呼ばれる。 本節では事後分布が手動で計算できるように共役な事前分布を用いた。しかし、これから見るような複雑なモデルでは手動で事後分布を求めることは困難になっていく。そこで用いられるのが次節で解説するMCMC法である。 6.6 Markov chain Monte Carlo simulation 6.6.1 underlying idea マルコフ連鎖モンテカルロ(MCMC)法は、手動ではなくシミュレーションによって事後分布を推測する方法である。MCMCでは、全てのパラメータについて同時にこれを行う。例えば、卵の殻の厚さに関する分析(式(6.7))では、3つのパラメータ\\(\\bf{\\theta} = (\\beta_1, \\beta_2, \\sigma)\\)について事後分布を同時に求める。 マルコフ連鎖とは、\\(\\bf{\\theta}\\)についてシミュレーションを行ったベクトル\\(\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\dots, \\theta^{(T)}\\)を指し、\\(\\theta^{(t+1)}\\)は\\(\\theta^{(t)}\\)のみに依存する。数学的には以下のように書ける。 \\[ f(\\theta^{(t+1)}|\\theta^{(t)}, \\dots, \\theta^{(1)}) = f(\\theta^{(t+1)}|\\theta^{(t)}) \\] MCMCでは各パラメータについて多くの(通常10000回以上)のシミュレーション値が得られる。これのシミュレーション値をヒストグラムにすると、それぞれのパラメータの事後分布に近似させることができることが数学的にわかっている。数学的な説明については、 Kruschke (2014) や McElreath (2020) などを参照。 6.6.2 Simple example of MCMC algorithm ここでは、MCMCがどのように分布を推定できるのかを見るため、MCMC法の一種であるメトロポリスアルゴリズム(Metropolis algorithm)の特殊例について簡単に見ていく(McElreath 2020)。 10の島からなる諸島があるとする。それぞれの島は2つの島に隣接しており、全体で円になっている。各島は面積が異なり、それに比例して人口も異なる。面積と人口は1つめの島から順に2倍、3倍、…10倍になっている(つまり、1つめの島の大きさと人口が1だとすれば、10個目の島はそれぞれ10である)。さて、この諸島の王様は1週間ごとに島々を訪れるが、その際には隣接している島にしか移動できない。王様は各島を人口比率に応じて訪れたいが、訪問計画を長期的に策定するのは面倒である。そこで、彼の側近は以下の方法で島を訪れることを提案した。この方法に従えば、各島に訪れる頻度が人口比率に一致する。 毎週王様はその島にとどまるか、隣接するいずれかの島に移動するかをコインを投げて決める。 もしコインが表なら、王様は時計回りに隣の島に移動することを考える。一方コインが裏なら、反時計回りに移動することを考える。ここで、提案された島をproposal islandとする。 王様はporposal islandの大きさだけ(7つめの島にいるなら7個)貝殻を集める。また、現在いる島の大きさだけ同様に石を集める。 もし貝殻の数が石よりも多ければ、王様はproposal islandへ移動する。一方で石の数の方が多い場合、王様は集めた石から貝殻と同数の石を捨てる(例えば石が6つ、貝殻が4つなら、手元には\\(6-4=2\\)個の石が残る)。その後、残された石と貝殻をカバンに入れ、王様はランダムにそのうちの一つを引く。もしそれが貝殻ならばproposal islandに移動し、石ならば今いる島に留まる。 この方法は一見奇妙だが、長期間繰り返していくと非常にうまくいく。以下でシミュレーションしてみよう。 set.seed(9) num_weeks &lt;- 1e6 positions &lt;- rep(0, num_weeks) current &lt;- 10 ## アルゴリズムの記述 for(i in 1:num_weeks){ ## 最初は島10からスタート positions[i] &lt;- current proposal &lt;- current + sample(c(-1,1), size=1) if(proposal &lt;1) proposal &lt;- 10 if(proposal &gt;10) proposal &lt;- 1 prob_move &lt;- proposal/current current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current) } 国王の動きを可視化してみる。 tibble(week = 1:1e6, island = positions) %&gt;% ggplot(aes(x=week, y = island))+ geom_line(linewidth = 1/3)+ geom_point()+ coord_cartesian(xlim = c(0,500))+ scale_y_continuous(breaks = seq(1,10,1))+ theme_bw()+ theme(aspect.ratio= 0.8) 各島を訪れた回数を見てみると以下のようになり、人口に応じて訪れていることが分かる。 tibble(week = 1:1e6, island = positions) %&gt;% mutate(island = factor(island)) %&gt;% ggplot(aes(x=island))+ geom_bar()+ theme_bw()+ theme(aspect.ratio = 0.9)+ scale_y_continuous(breaks = seq(0,180000, 20000)) 島を訪れている比率(prop)はおよそ人口通りになる。このアルゴリズムは、隣の島だけでなく全ての島への移動が可能であっても同様に機能する。 tibble(week = 1:1e6, island = positions) %&gt;% count(island) %&gt;% mutate(prop = n/n[1]) %&gt;% gt() %&gt;% fmt_number(&quot;prop&quot;,decimals=2) %&gt;% tab_options(table.align=&#39;left&#39;) #wqlbootwvl table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #wqlbootwvl thead, #wqlbootwvl tbody, #wqlbootwvl tfoot, #wqlbootwvl tr, #wqlbootwvl td, #wqlbootwvl th { border-style: none; } #wqlbootwvl p { margin: 0; padding: 0; } #wqlbootwvl .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: 0; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wqlbootwvl .gt_caption { padding-top: 4px; padding-bottom: 4px; } #wqlbootwvl .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wqlbootwvl .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #wqlbootwvl .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wqlbootwvl .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wqlbootwvl .gt_column_spanner_outer:first-child { padding-left: 0; } #wqlbootwvl .gt_column_spanner_outer:last-child { padding-right: 0; } #wqlbootwvl .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wqlbootwvl .gt_spanner_row { border-bottom-style: hidden; } #wqlbootwvl .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #wqlbootwvl .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wqlbootwvl .gt_from_md > :first-child { margin-top: 0; } #wqlbootwvl .gt_from_md > :last-child { margin-bottom: 0; } #wqlbootwvl .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wqlbootwvl .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #wqlbootwvl .gt_row_group_first td { border-top-width: 2px; } #wqlbootwvl .gt_row_group_first th { border-top-width: 2px; } #wqlbootwvl .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #wqlbootwvl .gt_first_summary_row.thick { border-top-width: 2px; } #wqlbootwvl .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wqlbootwvl .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wqlbootwvl .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wqlbootwvl .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wqlbootwvl .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wqlbootwvl .gt_left { text-align: left; } #wqlbootwvl .gt_center { text-align: center; } #wqlbootwvl .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wqlbootwvl .gt_font_normal { font-weight: normal; } #wqlbootwvl .gt_font_bold { font-weight: bold; } #wqlbootwvl .gt_font_italic { font-style: italic; } #wqlbootwvl .gt_super { font-size: 65%; } #wqlbootwvl .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #wqlbootwvl .gt_asterisk { font-size: 100%; vertical-align: 0; } #wqlbootwvl .gt_indent_1 { text-indent: 5px; } #wqlbootwvl .gt_indent_2 { text-indent: 10px; } #wqlbootwvl .gt_indent_3 { text-indent: 15px; } #wqlbootwvl .gt_indent_4 { text-indent: 20px; } #wqlbootwvl .gt_indent_5 { text-indent: 25px; } island n prop 1 18142 1.00 2 36232 2.00 3 54787 3.02 4 72686 4.01 5 90272 4.98 6 108747 5.99 7 127527 7.03 8 145756 8.03 9 163703 9.02 10 182148 10.04 6.6.3 Methods in MCMC MCMCにも様々なアルゴリズムがあり、それぞれの方法を実装するためのソフトウェアが開発されている。例えば、ギブスサンプリングと呼ばれる方法(Kruschke 2014; McElreath 2020)を実装するソフトウェアとしてJAGSやWinBUGSがある。また、ハミルトニアン・モンテカルロ法という方法を用いるソフトウェアとしては(Stan)[https://mc-stan.org/]がある(松浦 2016; 馬場 2019)。いずれもR上で実行することができる。 いずれを用いてもMCMCによるベイズ推定を行えるが、現在はStanが用いられることが多くなっている(松浦 2016)。この理由としては、WinBUGSやJAGSが使いにくい点や、開発があまり継続的には行われておらず、マニュアルや用例が充実していない点が挙げられる。また、Stanで用いられるハミルトニアン・モンテカルロ法はギブスサンプリングよりも複雑なモデルを扱え、またサンプリングも効率的に行える。そこで、本稿では以下Stanを用いてモデリングを行う2。RでStanを動かすには、rstanパッケージが必要である。`Stanのインストール方法や使用方法などは 松浦 (2016) や 馬場 (2019) を参照。 6.6.4 Flowchart for running a model in Stan 以下、Stanを用いてMCMCによって事後分布を推定する。分析には、第3で用いたデータを用いる。以下の線形モデルを考える。ひとまず、データの疑似反復については気にしない。 \\[ \\begin{aligned} pH_i &amp;\\sim N(0,\\sigma^2)\\\\ \\mu_i &amp;= \\beta_1 + \\beta_2 \\times SDI_i\\\\ \\end{aligned} \\tag{6.11} \\] 6.6.4.1 Preparing the data for Stan Stanで分析を行うためには、まずデータをlist形式で準備する必要がある。なお、説明変数\\(SDI\\)はモデルの収束をよくするために標準化する。 iph %&gt;% mutate(SDI.std = scale(SDI)) -&gt; iph2 X &lt;- model.matrix(~ 1 + SDI.std, data = iph2) data_iph &lt;- list(Y = iph2$pH, X = X, ##回帰係数の数 K = ncol(X), ##データ数 N = nrow(iph2)) 6.6.4.2 Decide model formulation and priors パラメータの事前分布などを含めたモデルの詳細を決める。モデル式は式(6.11)の通りである。 パラメータ\\(\\beta\\)の事前分布としては、以下の正規分布の無情報事前分布を用いることにする。 \\[ \\beta_1 \\sim N(0,100^2) \\;\\; and \\;\\; \\beta_2 \\sim N(0,100^2) \\] \\(\\sigma\\)の事前分布としては、0から20までの一様分布を用いる。 \\[ \\sigma \\sim uniform(0,20) \\] 6.6.4.3 Preparing stan file 最後に、ここまでのモデルの情報を記した以下のようなStanファイルを用意する。dataセクションにはデータの情報を、parameterセクションにはパラメータの情報を、modelセクションにはモデル式や事前分布に関する情報を入れる。 ## // データ ## data { ## int N; ## int K; ## vector[N] Y; ## matrix[N, K] X; ## } ## ## // パラメータ ## parameters { ## vector[K] beta; ## real&lt;lower=0&gt; sigma; ## } ## ## // モデル式、事前分布 ## model { ## vector[N] mu = X*beta; ## Y ~ normal(mu, sigma); ## ## //βの事前分布 ## for(i in 1:K){ ## beta[i] ~ normal(0, 100); ## } ## ## //σの事前分布 ## sigma ~ uniform(0,20); ## } 6.6.4.4 Initial values パラメータのMCMCの初期値を定める場合には、指定することができる。今回は、\\(\\beta_1, \\beta_2\\)の初期値については平均0、標準偏差10の正規分布から、\\(\\sigma\\)の初期値は0から20までの一様分布から得られるとした。 K &lt;- ncol(X) inits &lt;- function() { list(beta = rnorm(K, 0, 10), sigma = runif(1, 0,20)) } 6.6.5 Running model in Stan それでは、実際にStanでモデルを回してみよう。 まず、rstanパッケージを読み込む。バックエンドとして、cmdstanrパッケージを用いる。 library(rstan) library(cmdstanr) library(posterior) 以下のオプションを実行すると、実行時間が短くなる。 rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) MCMCによるパラメータの推定は以下のように行う。 file: stanファイル data: リスト化したデータ init: 初期値 chains: 何セットの乱数生成(MCMC)を行うか iter_warmup: チューニングを行う回数。切り捨てる。 iter_sampling: warmup期間を含む各chainの乱数生成回数。 thin: 何回に一回の乱数を用いるか 今回の場合、4つのchainで繰り返し数(iter_sampling)が50000、間引き期間(thin)が10なので、\\((50000)/10 \\times 4 = 20000\\)個の乱数がパラメータごとに得られる。 mod &lt;- cmdstan_model(&quot;stanfile/lm-iph.stan&quot;) m7_1 &lt;- mod$sample(data = data_iph, init = inits, seed = 1234, ## 何回に一回のデータを使うか thin = 10, ## 最初の何回を捨てるか iter_warmup = 5000, ## 乱数生成の繰り返し数(warmupを除く) iter_sampling = 50000, ## chainの数 chains = 4) 6.6.6 Assess mixing 結果を見る前に、まず信頼できるMCMCサンプルが得られたかを確認する必要がある。 得られたMCMCサンプルは以下のように取り出せる。 draw_m7_1 &lt;- m7_1$draws(format = &quot;df&quot;) datatable(draw_m7_1) まずは、MCMCが収束しているかを確認する。視覚的には、横軸に繰り返し(iteration)数をとり、chainごとにその遷移を確認する。全てのchainがまじりあっていれば問題がない。図を見る限りは問題がなさそう。 mcmc_trace(draw_m7_1) また、収束をチェックするための指標としては、\\(\\hat{R}\\)と有向サンプルサイズ数がある。前者は1.1未満であれば、後者は100くらいあれば問題ないとされている(松浦 2016)。今回は問題なさそう(rhatとess_bulkをチェックする)。 m7_1$summary(NULL, c(&quot;Rhat&quot;, &quot;ess_bulk&quot;)) いよいよ、結果を確認する。まずは、事後分布の代表値なども一緒にチェックする。以下には、事後分布の平均(mean)、中央値(median)、標準偏差(sd)、中央値絶対偏差(mad)、2.5パーセンタイル(q2.5)、97.5パーセンタイル(q97.5)を示した。2.5パーセンタイルと97.5パーセンタイルの間の範囲を95%確信区間(credible interval)という。これらは全てMCMCで生成された乱数から計算されている。 \\(\\beta_2\\)の95%確信区間は\\([-0.463, -0.361]\\)で0を含まない。これは、\\(\\beta_2\\)が95%の確率でこの区間の値をとるということを表す。このことから、SDIはpHと強く関連しているといえそうだ。 m7_1$summary(variables = NULL, c(&quot;mean&quot;, &quot;median&quot;,&quot;sd&quot;, &quot;mad&quot;), quantiles = ~posterior::quantile2(., probs = c(.0275, .975))) -&gt; result7_1 result7_1 最後に、事後分布を実際に図示する。 mcmc_hist(draw_m7_1, pars = c(&quot;beta[1]&quot;,&quot;beta[2]&quot;, &quot;sigma&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Frequencies&quot;) 6.7 Integrated nested Laplace approximation Stanでは、前節と同様にして様々なモデルを実装することができる。しかし、時空間相関を考慮するなど複雑なモデルになると、MCMCでは時間がかかりすぎる場合やモデルが収束しない場合が出てくる。本節では、MCMCによらず事後分布を近似させる手法である integrated nested Laplace approximation(INLA)について学ぶ。INLAはMCMCよりもはるかに拘束に、かつ精度高く事後分布を推定することができる。しかし、以下の数学的説明はかなり高度なので、全てを理解する必要はない。 6.7.1 Joint posterior distribution ここまでと同様に、ミサゴの卵の厚さが殺虫剤の崩壊産物(DDD)によって変わるかを検討するとする(Steidl et al. 1991)。同様に以下のモデルを考える。 \\[ \\begin{aligned} &amp;\\mu_i = \\beta_1 + DDD_i \\times \\beta_2 \\\\ &amp;Thickness_i \\sim N(\\mu_i,\\sigma^2) \\end{aligned} \\tag{6.12} \\] 式(6.12)には3つのパラメータ(\\(\\beta_1, \\beta_2, \\sigma\\))があるが、\\(\\sigma\\)のようなパラメータはハイパーパラメータと呼ばれる。ハイパーパラメータには、負の二項分布モデルなどの分散パラメータや、ランダム効果(混合)モデルのランダム切片の分散パラメータ、時空間相関を考慮したモデルにおけるパラメータ(\\(\\phi, \\kappa\\)など)がある。 ベイズの定理から、以下の式が導ける。 \\[ \\begin{aligned} P(\\beta_1, \\beta_2, \\sigma|D) &amp;= \\frac{P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2, \\sigma)}{P(D)}\\\\ &amp;\\propto P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2, \\sigma) \\end{aligned} \\tag{6.13} \\] \\(P(\\beta_1, \\beta_2, \\sigma|D)\\)はデータ(D)が与えられた時のパラメータの同時分布である。\\(P(D|\\beta_1, \\beta_2, \\sigma)\\)はデータの尤度、\\(P(\\beta_1, \\beta_2, \\sigma))\\)はパラメータの事前分布である。\\(pH\\)が正の連続値であると考えると、正規分布かガンマ分布を用いて書くことができるだろう。\\(\\beta_1, \\beta_2\\)は全ての値が取れるのに対して\\(\\sigma\\)は0より大きい値しか取れないので、これらにすべて同じ事前分布を仮定することはできない。そのため、事前分布は\\(\\beta_1, \\beta_2\\)のためのものと、\\(\\sigma\\)のためのものの2種類を含むように書き直す必要がある。 式(6.1)より、式(6.13)は\\(P(\\beta_1, \\beta_2, \\sigma))\\)を変形して以下のように書き直せる。これにより、事前分布を2つの要素に分けることができた。 \\[ \\begin{aligned} P(\\beta_1, \\beta_2, \\sigma)|D) &amp;\\propto P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2, \\sigma) \\\\ &amp;= P(D|\\beta_1, \\beta_2, \\sigma) \\times P(\\beta_1, \\beta_2| \\sigma) \\times P(\\sigma) \\end{aligned} \\tag{6.14} \\] \\(\\beta_s\\)の事前分布\\(P(\\beta_1, \\beta_2| \\sigma)\\)は少しトリッキーだが、互いに独立に多変量正規分布から得られていると仮定すればうまくいくことが多い。 6.7.2 Marginal distributions MCMCでは各パラメータの事後分布\\(P(\\beta_1|D), P(\\beta_2|D), P(\\sigma|D)\\)が得られた。これらは周辺分布(marginal distribution)といい、同時事後確率\\(P(\\beta_1, \\beta_2, \\sigma)|D)\\)を得たわけではなかった。 同時分布と周辺分布の違いを説明するため、ミヤコドリ(Haematopus palliates)を対象とした研究のデータを用いる。この研究では、3か所で12月から1月にミヤコドリによって食べられた二枚貝の長さが記録されている。ミヤコドリは、採食技術によってhammererまたはstabberに分類された。リサーチクエスチョンは、採食技術のタイプによって貝の長さが変わるかである。 oc &lt;- read_delim(&quot;data/Oystercatcher.txt&quot;) datatable(oc, options = list(scrollX = 20), filter = &quot;top&quot;) 下表(表6.1)は、hammererによって割られた二枚貝のサイズ(Large or Small)を場所ごとにまとめたものである。 oc %&gt;% filter(FeedingType == &quot;Hammerers&quot;) %&gt;% mutate(shell_size = ifelse(ShellLength &gt;= 2, &quot;Large&quot;,&quot;Small&quot;)) %&gt;% group_by(shell_size, FeedingPlot) %&gt;% summarise(N = n()) %&gt;% rename(&quot;Shell size&quot; = 1, &quot;Feeding site&quot; = 2) %&gt;% pivot_wider(names_from = &quot;Feeding site&quot;, values_from = N) %&gt;% ungroup() %&gt;% mutate(Total = A + B + C) -&gt; sum_oc sum_oc %&gt;% bind_rows(summarise(., across(where(is.numeric), sum), across(where(is.character), ~&#39;Total&#39;))) %&gt;% kable(booktabs = TRUE, align = c(&quot;l&quot;, rep(&quot;c&quot;,5)), caption = &quot;Number of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site.&quot;) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;Feed place&quot; = 4)) %&gt;% kable_styling(full_width = FALSE) 表6.1: Number of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site. Feed place Shell size A B C Total Large 45 29 36 110 Small 15 16 24 55 Total 60 45 60 165 これを割合データに直したのが表6.2である。 sum_oc %&gt;% bind_rows(summarise(., across(where(is.numeric), sum), across(where(is.character), ~&#39;Total&#39;))) %&gt;% mutate_if(is.numeric, .funs = ~./165) %&gt;% mutate_if(is.numeric, ~sprintf(&quot;%.3f&quot;, .)) %&gt;% kable(booktabs = TRUE, align = c(&quot;l&quot;, rep(&quot;c&quot;,5)), caption = &quot;Proportions of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site.&quot;) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;Feed place&quot; = 4)) %&gt;% kable_styling(full_width = FALSE) 表6.2: Proportions of clams eaten by hammering oystercatchers per shell size (small versus large) and feeding site. Feed place Shell size A B C Total Large 0.273 0.176 0.218 0.667 Small 0.091 0.097 0.145 0.333 Total 0.364 0.273 0.364 1.000 このとき、\\(P(\\rm{shell \\; size} \\; \\mathbf{and} \\rm{\\;Feed \\; place})\\)が同時確率であり、中の6つのセルの値である。 一方、\\(P(\\rm{Feed \\;place})\\)と\\(P(\\rm{Shell \\; size})\\)が周辺確率である。これらは、それぞれ一番下の行と一番右の列の値である。 \\[ \\begin{aligned} &amp;P(\\rm{Feed \\;place} = A) = 0.273 + 0.091 = 0.364 \\\\ &amp;P(\\rm{Feed \\;place} = B) = 0.176 + 0.097 = 0.273 \\\\ &amp;P(\\rm{Feed \\;place} = C) = 0.218 + 0.145 = 0.364 \\\\ \\\\ &amp;P(\\rm{Shell \\; size = Large}) = 0.273 + 0.16 + 0.218 = 0.667 \\\\ &amp;P(\\rm{Shell \\; size = Small}) = 0.091 + 0.097 + 0.145 = 0.333 \\end{aligned} \\] より一般的に、変数が離散的なとき周辺確率は以下のように書ける。 \\[ P(X = x) = \\sum_y P(X = x \\; \\rm{and} \\; Y = y) \\] 変数が連続的なとき、以下のように書ける。 \\[ P(X = x) = \\int_y P(X = x \\; \\rm{and} \\; Y = y) dy \\tag{6.15} \\] このように、複数の確率変数の同時分布(確率)から周辺分布(確率)を計算することを周辺化という(馬場 2019)。周辺事後分布\\(P(\\beta_1|D), P(\\beta_2|D), P(\\sigma|D)\\)を求めるときも、同じように積分を用いて周辺化を行う。 6.7.3 Back to high school それでは、積分とは何だろうか。例えば、図6.3Aの塗りつぶされた場所の面積を求めたいとする(なお、曲線は\\(f(x) = -2x^2 + 8\\))。いうまでもなく\\(\\int_0 ^1 f(x) dx\\)という積分計算を行えばこれを求めることができるが、積分を用いずにこれを近似することはできるだろうか? よく用いられるのは、面積を求めたいエリアの\\(x\\)軸(その範囲を\\(x_0\\)とする)をN等分したのち、面積を求めたいエリアを幅\\(x_0/N\\)、高さ\\(f(x)\\)の長方形N個で埋め尽くし、その面積の合計を近似値として求める方法である。例えば、図6.3Bは面積を求めたいエリアを5等分した場合である。Nを大きくすればするほど近似値は実際の面積に近づいていく(図6.3C)。これを区分求積法という。INLAでも、積分計算に区分求積法のような方法を用いることで近似を行う。 X &lt;- seq(-0.5, 2, length = 100) Y &lt;- -2*X^2 + 8 data.frame(X = X, Y = Y) %&gt;% ggplot(aes(x = X, y = Y))+ geom_area(aes(x = ifelse(X&gt;=0 &amp; X &lt;= 1 , X, 0)), fill = &quot;lightblue&quot;)+ geom_line(linewidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0.35,8))+ labs(title = &quot;A&quot;) -&gt; p1 int &lt;- data.frame(X = seq(0,0.8,0.2)) %&gt;% mutate(Y = -2*X^2 + 8) data.frame(X = X, Y = Y) %&gt;% ggplot(aes(x = X, y = Y))+ geom_area(aes(x = ifelse(X&gt;=0 &amp; X &lt;= 1 , X, 0)), fill = &quot;lightblue&quot;)+ geom_line(linewidth = 1)+ geom_col(data = int, color = &quot;black&quot;, alpha = 0, linewidth = 0.3, width = 0.2, position = position_nudge(x = 0.1)) + theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0.35,8))+ labs(title = &quot;B&quot;)-&gt; p2 int2 &lt;- data.frame(X = seq(0,0.9,0.1)) %&gt;% mutate(Y = -2*X^2 + 8) data.frame(X = X, Y = Y) %&gt;% ggplot(aes(x = X, y = Y))+ geom_area(aes(x = ifelse(X&gt;=0 &amp; X &lt;= 1 , X, 0)), fill = &quot;lightblue&quot;)+ geom_line(linewidth = 1)+ geom_col(data = int2, color = &quot;black&quot;, alpha = 0, linewidth = 0.2, width = 0.1, position = position_nudge(x = 0.05)) + theme_bw()+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0.35,8))+ labs(title = &quot;C&quot;)-&gt; p3 p1 + p2 + p3 図6.3: How integrals work. 実際の分析ではより複雑な関数を積分しなくてはいけないので、実際には積分を行うことが非常に難しいこともある。INLAではラプラス近似(テイラー展開を用いて関数を近似する方法)を用いて\\(f(x)\\)を近似することで、複雑な積分計算を可能にする。もう少し詳しい説明については、こちらなどを参照。 6.7.4 INLA 式(6.15)より、\\(\\beta_1, \\beta_2\\)の事後分布は以下のように書ける。 \\[ \\begin{aligned} &amp;P(\\beta_1|D) = \\int P(\\beta_1, \\sigma|D)d\\sigma \\\\ &amp;P(\\beta_2|D) = \\int P(\\beta_2, \\sigma|D)d\\sigma \\end{aligned} \\tag{6.16} \\] 混合モデルなど、ハイパーパラメータが2つあるときには、これらの事後分布を以下のように求める。 \\[ P(\\sigma_1|D) = \\int(\\sigma_1, \\sigma_2|D)d\\sigma_1 \\\\ P(\\sigma_2|D) = \\int(\\sigma_1, \\sigma_2|D)d\\sigma_2 \\] ひとまず、今回はハイパーパラメータが$$1つの場合を考える。このとき、式(6.16)は条件付き確率の書き換えルール(式(6.1))を用いて以下のように書き換えられる3。 \\[ \\begin{aligned} &amp;P(\\beta_1|D) = \\int P(\\beta_1|\\sigma,D) \\times P(\\sigma|D) d\\sigma \\\\ &amp;P(\\beta_2|D) = \\int P(\\beta_2|\\sigma,D) \\times P(\\sigma|D) d\\sigma \\end{aligned} \\] よって、事後分布を求めるには2つの要素を計算できれば良い。\\(P(\\sigma|D)\\)はハイパーパラメータが1つなので簡単に求められる。もし、ハイパーパラメータが2つ以上のときはこれをさらに簡単な要素に分解する。\\(P(\\beta_1|\\sigma,D)\\)の計算にはいくつかの方法があるが、INLAではラプラス近似を用いてこれを求める。 6.8 Examples using R-INLA 以下では、INLAパッケージを用いて式(6.12)の線形モデルを実行する。INLAのコードは非常にシンプルで、他の関数(lm、glm)と同じようにできる。 m7_2 &lt;- inla(pH ~ SDI.std, data = iph2, family = &quot;gaussian&quot;) 違う点は、分布をfamily =で必ず指定しなければいけない点である。INLAでは非常に多くの分布を扱える。 names(inla.models()$likelihood) ## [1] &quot;poisson&quot; &quot;xpoisson&quot; ## [3] &quot;cenpoisson&quot; &quot;cenpoisson2&quot; ## [5] &quot;gpoisson&quot; &quot;poisson.special1&quot; ## [7] &quot;0poisson&quot; &quot;0poissonS&quot; ## [9] &quot;bell&quot; &quot;0binomial&quot; ## [11] &quot;0binomialS&quot; &quot;binomial&quot; ## [13] &quot;xbinomial&quot; &quot;pom&quot; ## [15] &quot;bgev&quot; &quot;gamma&quot; ## [17] &quot;gammasurv&quot; &quot;gammajw&quot; ## [19] &quot;gammajwsurv&quot; &quot;gammacount&quot; ## [21] &quot;qkumar&quot; &quot;qloglogistic&quot; ## [23] &quot;qloglogisticsurv&quot; &quot;beta&quot; ## [25] &quot;betabinomial&quot; &quot;betabinomialna&quot; ## [27] &quot;cbinomial&quot; &quot;nbinomial&quot; ## [29] &quot;nbinomial2&quot; &quot;cennbinomial2&quot; ## [31] &quot;simplex&quot; &quot;gaussian&quot; ## [33] &quot;gaussianjw&quot; &quot;agaussian&quot; ## [35] &quot;circularnormal&quot; &quot;wrappedcauchy&quot; ## [37] &quot;iidgamma&quot; &quot;iidlogitbeta&quot; ## [39] &quot;loggammafrailty&quot; &quot;logistic&quot; ## [41] &quot;sn&quot; &quot;gev&quot; ## [43] &quot;lognormal&quot; &quot;lognormalsurv&quot; ## [45] &quot;exponential&quot; &quot;exponentialsurv&quot; ## [47] &quot;coxph&quot; &quot;weibull&quot; ## [49] &quot;weibullsurv&quot; &quot;loglogistic&quot; ## [51] &quot;loglogisticsurv&quot; &quot;stochvol&quot; ## [53] &quot;stochvolsn&quot; &quot;stochvolt&quot; ## [55] &quot;stochvolnig&quot; &quot;zeroinflatedpoisson0&quot; ## [57] &quot;zeroinflatedpoisson1&quot; &quot;zeroinflatedpoisson2&quot; ## [59] &quot;zeroinflatedcenpoisson0&quot; &quot;zeroinflatedcenpoisson1&quot; ## [61] &quot;zeroinflatedbetabinomial0&quot; &quot;zeroinflatedbetabinomial1&quot; ## [63] &quot;zeroinflatedbinomial0&quot; &quot;zeroinflatedbinomial1&quot; ## [65] &quot;zeroinflatedbinomial2&quot; &quot;zeroninflatedbinomial2&quot; ## [67] &quot;zeroninflatedbinomial3&quot; &quot;zeroinflatedbetabinomial2&quot; ## [69] &quot;zeroinflatednbinomial0&quot; &quot;zeroinflatednbinomial1&quot; ## [71] &quot;zeroinflatednbinomial1strata2&quot; &quot;zeroinflatednbinomial1strata3&quot; ## [73] &quot;zeroinflatednbinomial2&quot; &quot;t&quot; ## [75] &quot;tstrata&quot; &quot;nmix&quot; ## [77] &quot;nmixnb&quot; &quot;gp&quot; ## [79] &quot;dgp&quot; &quot;logperiodogram&quot; ## [81] &quot;tweedie&quot; &quot;fmri&quot; ## [83] &quot;fmrisurv&quot; &quot;gompertz&quot; ## [85] &quot;gompertzsurv&quot; 6.8.1 Posterior summary 推定された事後分布の要約は以下の通り。事後分布の平均、sd、パーセンタイル値などの情報が出る。結果はほぼMCMCのときと変わらない。 summary(m7_2) ## ## Call: ## c(&quot;inla.core(formula = formula, family = family, contrasts = contrasts, ## &quot;, &quot; data = data, quantiles = quantiles, E = E, offset = offset, &quot;, &quot; ## scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, ## &quot;, &quot; lp.scale = lp.scale, link.covariates = link.covariates, verbose = ## verbose, &quot;, &quot; lincomb = lincomb, selection = selection, control.compute ## = control.compute, &quot;, &quot; control.predictor = control.predictor, ## control.family = control.family, &quot;, &quot; control.inla = control.inla, ## control.fixed = control.fixed, &quot;, &quot; control.mode = control.mode, ## control.expert = control.expert, &quot;, &quot; control.hazard = control.hazard, ## control.lincomb = control.lincomb, &quot;, &quot; control.update = ## control.update, control.lp.scale = control.lp.scale, &quot;, &quot; ## control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, ## &quot;, &quot; inla.call = inla.call, inla.arg = inla.arg, num.threads = ## num.threads, &quot;, &quot; blas.num.threads = blas.num.threads, keep = keep, ## working.directory = working.directory, &quot;, &quot; silent = silent, inla.mode ## = inla.mode, safe = FALSE, debug = debug, &quot;, &quot; .parent.frame = ## .parent.frame)&quot;) ## Time used: ## Pre = 0.738, Running = 0.435, Post = 0.0589, Total = 1.23 ## Fixed effects: ## mean sd 0.025quant 0.5quant 0.975quant mode kld ## (Intercept) 7.432 0.026 7.381 7.432 7.484 7.432 0 ## SDI.std -0.414 0.026 -0.465 -0.414 -0.362 -0.414 0 ## ## Model hyperparameters: ## mean sd 0.025quant 0.5quant ## Precision for the Gaussian observations 6.97 0.681 5.71 6.95 ## 0.975quant mode ## Precision for the Gaussian observations 8.37 6.91 ## ## Marginal log-Likelihood: -113.24 ## is computed ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also &#39;control.compute=list(return.marginals.predictor=TRUE)&#39;) ハイパーパラメータ以外の結果を知りたい場合は以下のようにしてみることができる。 m7_2$summary.fixed %&gt;% select(mean, sd, &quot;0.025quant&quot;, &quot;0.975quant&quot;) 事後分布の平均を用いた予測値や残差は以下のように計算できる。 X &lt;- model.matrix(~ 1 + SDI.std, data = iph2) beta &lt;- m7_2$summary.fixed %&gt;% select(&quot;mean&quot;) %&gt;% .[,1] fit7_2 &lt;- X %*% beta e7_2 &lt;- iph$pH - fit7_2 自分で計算しなくても、INLAでcontrol.predictorオプションを加えれば自動で計算を行ってくれる。95%確信区間の計算も行ってくれるようだ。 m7_2 &lt;- inla(pH ~ SDI.std, data = iph2, family = &quot;gaussian&quot;, control.predictor = list(compute = TRUE), control.compute = list(config = TRUE)) fit7_2 &lt;- m7_2$summary.fitted.values datatable(fit7_2) ハイパーパラメータは以下のように求めることができる。INLAパッケージでは標準偏差ではなくprecision(\\(\\tau = 1/\\sigma^2\\)が推定される。 m7_2$summary.hyperpar 6.8.2 Posterior marginal distributions ある特定のパラメータに関する事後分布は事後周辺分布(posterior marginal distribution)と呼ばれる4。以後、これを事後分布と呼ぶ(先ほどの節の結果で示されたのも事後周辺分布の要約である)。先ほど推定したモデルでは3つのパラメータ(\\(\\beta_1, \\beta_2, 1 / \\sigma^2\\))があった。これらの事後分布は以下のように抽出できる。 pmbeta1 &lt;- m7_2$marginals.fixed$`(Intercept)` pmbeta2 &lt;- m7_2$marginals.fixed$SDI.std pmtau &lt;- m7_2$marginals.hyperpar$`Precision for the Gaussian observations` INLAには事後周辺分布の確信区間などの要約統計量を算出するための関数が装備されている。例えば、95%確信区間と中央値は以下のように求められる。 inla.qmarginal(p = c(0.025, 0.5, 0.975), pmbeta1) ## [1] 7.380707 7.432135 7.483562 inla.zmarginalでは、自動的に要約統計量を算出してくれる。 inla.zmarginal(pmbeta2) ## Mean -0.413666 ## Stdev 0.0262696 ## Quantile 0.025 -0.465272 ## Quantile 0.25 -0.431393 ## Quantile 0.5 -0.413722 ## Quantile 0.75 -0.39605 ## Quantile 0.975 -0.362171 また、最高密度区間(highest posterior density)5は以下のように求められる。 inla.hpdmarginal(0.95, pmbeta2) ## low high ## level:0.95 -0.4652722 -0.3621714 precision\\(\\tau\\)は容易に\\(\\sigma\\)に変換できる。 pm.sigma &lt;- inla.tmarginal(function(x) sqrt(1/x), pmtau) 事後分布はこれらを用いて容易に作図できる。 ## beta1 pmbeta1 %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(beta[1]), y = expression(paste(&quot;P( &quot;, beta[1] ,&quot; | Data)&quot;))) -&gt; p1 ## beta2 pmbeta2 %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(beta[2]), y = expression(paste(&quot;P( &quot;, beta[2] ,&quot; | Data)&quot;))) -&gt; p2 ## tau pmtau %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(tau), y = expression(paste(&quot;P( &quot;, tau ,&quot; | Data)&quot;))) -&gt; p3 ## sigma pmtau %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(sigma), y = expression(paste(&quot;P( &quot;, sigma ,&quot; | Data)&quot;))) -&gt; p4 p1 + p2 + p3 + p4 + plot_layout(ncol = 2) 6.9 追記 INLAの詳しい使い方やそれを用いたモデリングについての詳しい解説は、以下の本が役に立つ。いずれも無料でオンラインで閲覧可能である。 Bayesian inference with INLA Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA Dynamic Time Series Models using R-INLA: An Applied Perspective References "],["Chapter8.html", "7 Multiple linear regression in R-INLA 7.1 Introduction 7.2 Data exploration 7.3 Linear regression result 7.4 Model validation 7.5 Model selection 7.6 Visualizing the model", " 7 Multiple linear regression in R-INLA 本章では、時空間相関を持つモデルを実行する方法について学ぶ前に、よりシンプルなモデル(重回帰分析)をINLAパッケージで実行する方法やそこから予測値や残差を抽出したり、モデル診断やモデル選択を行う方法を学ぶ。 7.1 Introduction 本章では、チンパンジーの道具使用を調べた Hopkins et al. (2015) のデータを用いる。リサーチクエスチョンは、アリ釣りの技術が性別、年齢、生育環境で変わるのかである。 データでは、アリ釣りの技術は1回成功するまでの時間(潜時: Latency)で測定されている。計243個体の平均潜時を標準化した値がデータとして用いられている。また、説明変数は年齢Age、性別Sex、生育環境(rear; 1: 母親に育てられた、2: 人間に育てられた、3: 野生由来)、事件が実施された研究施設(Colony; 1か2)である。データは以下の通り。 chimp &lt;- read_delim(&quot;data/Chimps.txt&quot;) datatable(chimp, options = list(scrollX = 20), filter = &quot;top&quot;) 7.2 Data exploration まずデータの確認を行う。図7.1は全ての変数のdotplot(Zuur 2012)を示したものである。平均潜時が大きい個体が2頭いる点に注意が必要である。 Hopkins et al. (2015) ではこれらは取り除かれたが、本章では入れて分析を行う。年齢は均等にばらついているように見える。 chimp %&gt;% select(Sex, Age, Z_Latency, Colony, rear) %&gt;% mutate(N = 1:n()) %&gt;% pivot_longer(1:5) %&gt;% ggplot(aes(x = value, y = N))+ geom_point()+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1) 図7.1: Cleveland dotplots of all the variables. このデータには疑似反復はないように思える。各個体のデータは1つずつしかないし、時間的・空間的な相関が生じる要素もない。遺伝的な関連を考慮する必要があるかもしれないがここではひとまず扱わない。モデルに遺伝的な相関を取り入れる方法については、 Ga and Fox などを参照。 ##Model formulation 以下のモデルを考える。なお、rearは3水準あるので2つの回帰係数のパラメータが推定される点は注意。 \\[ \\begin{aligned} &amp;Latency_i \\sim N(\\mu_i, \\sigma^2)\\\\ &amp;E(Latency_i) = \\mu_i \\; \\rm{and} \\; var(Latency_i) = \\sigma^2 \\\\ &amp;\\mu_i = \\beta_1 + \\beta_2 \\times Age_i + \\beta_3 \\times Sex_i + \\beta_4 \\times Colony_i + \\beta_5(\\rm{and \\; \\beta_6}) \\times rear_i \\end{aligned} \\] 7.3 Linear regression result 7.3.1 Executing the model in R=INLA まず、Sex、Colony、rearについては変数を因子型にする。 chimp &lt;- chimp %&gt;% mutate(fSex = factor(Sex), fColony = factor(Colony), frear = factor(rear)) 次に、INLAでモデリングを行う。 m8_1 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975))) 7.3.2 Output for betas 7.3.2.1 Numerical output for the betas \\(\\sigma\\)以外のパラメータの事後分布の情報は以下のとおりである。年齢の95%確信区間は0を含まないので、年齢は平均潜時に影響を与えているといえそう。そのほかの切片以外のパラメータは全て95%確信区間に0を含んでいる。 m8_1$summary.fixed 7.3.2.2 Graphical output for the betas \\(\\beta_2\\)の事後分布は以下のように図示できる。 beta2 &lt;- m8_1$marginals.fixed$Age beta2 %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(beta[2]), y = expression(paste(&quot;P( &quot;, beta[2] ,&quot; | Data)&quot;))) 7.3.3 Output for hyperparameters 7.3.3.1 Numerical output for hyper parameters ハイパーパラメータ\\(\\tau = 1/\\sigma^2\\)の事後分布の要約統計量は以下のように出せる。 m8_1$summary.hyperpar しかしこれらは\\(\\tau\\)についてのものであって、私たちが知りたいのは\\(\\sigma = 1/\\sqrt\\tau\\)の事後分布である。\\(\\tau\\)の期待値は以下のように書ける(第6.3節参照)。 \\[ E(\\tau) = \\int_{-\\infty}^{\\infty} \\tau \\times p(\\tau) d\\tau \\tag{7.1} \\] 一方で、$= h() = 1/ \\(とするとき、\\)$の期待値は以下のようになる。 \\[ E(\\sigma) = \\int_{-\\infty}^{\\infty} h(\\tau) \\times p(\\tau) d\\tau = \\int_{0}^{\\infty} \\frac{1}{\\sqrt{\\tau}} \\times p(\\tau) d\\tau \\tag{7.2} \\] これは、単純に\\(\\tau\\)の事後分布の期待値を\\(1/\\sqrt{\\tau}\\)で変換しても、それは\\(\\sigma\\)の期待値ではないことを示している。幸いなことに、INLAではこれを計算してくれる関数が用意されている。 tau &lt;- m8_1$marginals.hyperpar$`Precision for the Gaussian observations` sigma &lt;- inla.emarginal(function(x) 1/sqrt(x), tau) sigma ## [1] 0.9767155 確かにこの値は単純に\\(\\tau\\)の事後分布の期待値を\\(1/\\sqrt{E(\\tau)}\\)で変換したものとは違う。 etau &lt;- m8_1$summary.hyperpar[,&quot;mean&quot;] 1/sqrt(etau) ## [1] 0.9736711 他の要約統計量が知りたい場合は、inla.tmarginalを用いればよい。 pmtau &lt;- m8_1$marginals.hyperpar$`Precision for the Gaussian observations` pm.sigma &lt;- inla.tmarginal(function(x) sqrt(1/x), pmtau) inla.zmarginal(pm.sigma) ## Mean 0.9767 ## Stdev 0.0445711 ## Quantile 0.025 0.8939 ## Quantile 0.25 0.945629 ## Quantile 0.5 0.974946 ## Quantile 0.75 1.00581 ## Quantile 0.975 1.06894 7.3.3.2 Graphical output for the hyperparameters \\(\\tau\\)の事後分布は以下のように図示できる(図7.2のA)。ただし、これにはわずかに45ポイントのデータしか使用されていないので、少しカクカクしている。inla.smarginal関数を用いると、スプライン回帰によってよりスムーズにしてくれる(図7.2のB)。 pmtau %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(tau), y = expression(paste(&quot;P( &quot;, tau ,&quot; | Data)&quot;)))+ labs(title = &quot;A&quot;) -&gt; p1 tau.smooth &lt;- inla.smarginal(pmtau) tau.smooth %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(tau), y = expression(paste(&quot;P( &quot;, tau ,&quot; | Data)&quot;)))+ labs(title = &quot;B&quot;) -&gt; p2 p1 + p2 図7.2: Pusterior distribution of tau 7.3.4 Fitted model 推定されたパラメータの事後分布から、モデル式は以下のように書ける。 \\[ \\begin{aligned} &amp;Latency_i \\sim N(\\mu_i, 0.97^2)\\\\ &amp;E(Latency_i) = \\mu_i \\; \\rm{and} \\; var(Latency_i) = 0.97^2 \\\\ \\\\ &amp;\\rm{for \\; chimpanzee \\; of \\; sex = 1, colony = 1, and \\; rear = 1}\\\\ &amp;\\mu_i = -0.45 + 0.02 \\times Age_i\\\\ \\\\ &amp;\\rm{for \\; chimpanzee \\; of \\; sex = 2, colony = 2, and \\; rear = 2}\\\\ &amp;\\mu_i = -0.45 + 0.02 \\times Age_i -0.22 +0.09 + 0.05\\\\ &amp; \\;\\;\\; = -0.52 + 0.02 \\times Age_i \\end{aligned} \\] 7.4 Model validation 前章で計算したように事後平均を用いた\\(\\mu_i\\)の予測値を手動で計算することもできるが(6.8.1)、以下のように求めることもできる。fit8_1には予測値の95%確信区間も入っている。 fit8_1 &lt;- m8_1$summary.fitted.values resid &lt;- chimp$Z_Latency - fit8_1$mean 予測値と残差の関係を示したのが図7.3である。明らかに残差が大きい点が2つある。 data.frame(fitted = fit8_1$mean, resid = resid) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;) 図7.3: Fitted vs residuals 予測値と実測値の関係を見ても、あまり当てはまりがよいように見えない。 data.frame(Latency = chimp$Z_Latency, fitted = fit8_1$mean) %&gt;% ggplot(aes(x = fitted, y = Latency))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Latency&quot;) 図7.4: Fitted vs residuals 予測値を手動で計算する方法は、リンク関数が恒等関数のときのみ正確な値になる。なぜなら、もしリンク関数で線形予測子を変換した後の期待値は線形予測子の期待値を変換するものと一致しないからである(式(7.1)と式(7.2)も参照)。 \\[ E(h(x)) \\neq h(E(x)) \\] 7.5 Model selection 7.5.1 What should we do? ベイズ統計でモデル選択を行うとき、話は通常の頻度論的な場合よりも複雑になる。以下では、ベイズモデリング(特にINLA)で用いることのできるモデル選択方法について議論する。 7.5.2 Usind the DIC AIC(赤池情報量規準)はモデル選択の際に最も一般的な指標である。なお、\\(L\\)はパラメータが与えられたときのデータの尤度(e.g., \\(P(D|\\beta_1, \\beta_2, \\sigma)\\))、\\(k\\)はパラメータ数である。\\(log(L)\\)は対数尤度、\\(-2 \\times log(L)\\)は逸脱度(deviance)といわれる。共変量をたくさん入れればモデルの当てはまりはよくなるが(\\(Lが高くなる\\))、パラメータ数が増える(\\(p\\)が大きくなる)という関係が成り立っている。AICが低いほど「良い」モデルということになる。 \\[ AIC = -2 \\times log(L) + 2\\times p \\] もし事前分布が無情報なのであればパラメータ数は知ることができるが、事前分布が情報を持っている場合、回帰係数がとりうる範囲は限定されるので、モデルの自由度やパラメータ数は変わってくる。すなわち、このような場合にはAICは適していない。 このようなときに使えるのがDICである。DICは\\(\\theta\\)を全てのパラメータを含むベクトル、\\(f(y|\\theta)\\)を尤度、\\(D(\\bar{\\theta}) = -2 \\times p(y|\\bar{\\theta})\\)をパラメータの期待値6が与えられた時の逸脱度とするとき、以下のように定義される。 \\[ DIC = D(\\bar{\\theta}) + 2 \\times p_D \\] なお、\\(p_D\\)は有効パラメータ数と呼ばれるもので、事前分布が無情報に近づくとパラメータ数\\(p\\)と一致する。また、事後分布が無情報に近づくほど頻度論での最尤推定値がベイズ統計の事後分布の期待値と一致する。よって、事前分布が無情報であればAICとDICはほとんど一致する。 これを実際にRで確かめよう。 まず、AICは以下のようになる。 m8_2 &lt;- lm(Z_Latency ~ Age + fSex + fColony + frear, data = chimp) ## 対数尤度 logLik(m8_2) ## &#39;log Lik.&#39; -336.2983 (df=7) ## AIC AIC(m8_2) ## [1] 686.5965 続いて、INLAでDICも求める。control.computeオプションで、dic = TRUEとすればよい。INLAはデフォルトでは無情報事前分布が用いられている。 m8_1 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1$dic$dic ## [1] 686.6328 AICとDICはほとんど一致する。 7.5.2.1 Effective number of parameters 有効パラメータ数の求め方には2つある。1つ目は以下の通り。なお、\\(\\bar{D}\\)は逸脱度の平均を表す。 \\[ p_D = \\bar{D} - D(\\bar{\\theta}) \\] このとき、DICは以下のように書き直せる。 \\[ \\begin{aligned} DIC &amp;= D(\\bar{\\theta}) + 2 \\times p_D \\\\ &amp;= D(\\bar{\\theta}) + 2 \\times (\\bar{D} - D(\\bar{\\theta}))\\\\ &amp;= \\bar{D} + \\bar{D} -D(\\bar{\\theta})\\\\ &amp;= \\bar{D} + p_D \\end{aligned} \\] 7.5.2.2 DIC related output DICは実際のINLAの出力から計算することができる。 pD = m8_1$dic$mean.deviance - m8_1$dic$deviance.mean DIC &lt;- m8_1$dic$mean.deviance + pD DIC ## [1] 686.6328 7.5.2.3 Model selection using DIC それでは、実際にDICを比較してみる。先ほどのモデルから年齢以外の説明変数を1つずつ除いた以下のモデルを比較する。 m8_1b &lt;- inla(Z_Latency ~ fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1c &lt;- inla(Z_Latency ~ Age + fSex + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1d &lt;- inla(Z_Latency ~ Age + fSex + fColony, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) DICの結果、frearがないモデルが最もDICが低いことが分かった。 c(m8_1$dic$dic, m8_1b$dic$dic, m8_1c$dic$dic, m8_1d$dic$dic) ## [1] 686.6328 692.3986 685.0378 682.7590 ここからは、さらにm8_1dから1つずつ説明変数を除いたモデルを作成し、DICが減少しなくなるまで同様の比較を続ける。 m8_1e &lt;- m8_1 &lt;- inla(Z_Latency ~ Age + fColony, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1f &lt;- m8_1 &lt;- inla(Z_Latency ~ Age + fSex, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) m8_1dより、そこからfColonyを除いたモデルのDICの方が低い。 c(m8_1d$dic$dic, m8_1e$dic$dic, m8_1f$dic$dic) ## [1] 682.7590 683.7640 681.4553 さらにm8_1fからfSexを除いたモデルと比較する。 m8_1g &lt;- m8_1 &lt;- inla(Z_Latency ~ Age, family = &quot;gaussian&quot;, data = chimp, control.compute = list(dic = TRUE)) 最終的に、m8_1fが最もDICが低いことが分かった。 c(m8_1f$dic$dic, m8_1g$dic$dic) ## [1] 681.4553 682.0625 7.5.3 WAIC DICのほかには、WAIC(widely applicable information criterion)を使うこともできる。WAICはDICをより発展させたものととらえられる。WAICの解説については、 McElreath (2020) も参照。 INLAでは以下のようにして計算できる。 m8_1 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(waic = TRUE)) m8_1$waic$waic ## [1] 696.295 7.5.4 Out of sample prediction 最後に、DICやWAICのような情報量規準ではなく、交差検証(cross validation)と呼ばれる方法を用いることもできる。この方法では、例えばデータをらなダムに2つ(\\(D_{fit}\\)と\\(D_{pred}\\))に分ける。その後\\(D_{fit}\\)に対してあるモデルを当てはめ、その結果をもとに\\(D_{fit}\\)の予測を行う。以上を何度も繰り返し、それらを総合してそのモデルの精度を評価する。これを複数のモデルに対して行い、そのモデルが最も良いかを調べるのが交差検証である。 INLAでも交差検証を行う。INLAでは、\\(D_{fit}\\)を1つだけの観測値を除いたデータとし、これを全ての観測値に対して行う交差検証を行う。これは”leave one out” 交差検証と呼ばれる。INLAは交差検証によってCPO(conditional predictive ordinate)やPIT(probability integral transform)と呼ばれる値を算出する。 CPOは、除かれた1つの観測値が、その他の観測値が与えられたときに得られる確率として定義される。\\(CPO_i\\)が高いほど他のデータを用いて推定されたモデルに従うことを示す。 \\[ CPO_i = Pr(除かれた観測値_i|そのほかの観測値) \\] PITはCPOの代替的な指標である。説明はこちらや Blangiardo and Cameletti (2015) に詳しい。 INLAでは\\(CPO_i\\)を以下のように算出できる。 m8_3 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.compute = list(cpo = TRUE)) 以下のm8_3$cpoには3つのリストが含まれる。m8_3$cpo$cpoは\\(CPO_i\\)が、m8_3$cpo$pitは\\(PIT_i\\)がデータ数だけ含まれる。3つめのm3_8$cpo$failureはもし1であればその観測値のCPOやPITが信頼できないことを表す。 m8_3$cpo %&gt;% data.frame() %&gt;% datatable() CPOのdotplotを図示すると以下のようになる。それも低い値をとっており、モデルの当てはまりがよくないことが分かる。 m8_3$cpo %&gt;% data.frame() %&gt;% mutate(n = 1:n()) %&gt;% ggplot(aes(x = cpo, y = n))+ geom_point()+ coord_cartesian(xlim = c(0,1))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;CPO&quot;, y = &quot;Observation number&quot;) モデル選択では、様々なモデルに対して同様にCPOを算出し、どのモデルがよりよく当てはまっているかを比べる。しかし実際にこれを基に判断するのは難しい。他の方法としては、モデルごとに\\(CPO_i\\)を1つの値にまとめ、それをモデル間で比較するというものである。例えば、\\(log(CPO_i)\\)の合計をそのモデルの当てはまりの良さとして使用することができる。 sum(log(m8_3$cpo$cpo)) ## [1] -347.8294 7.5.5 Posterior predictive check モデルの当てはまりをチェックする方法としては、モデルから事後予測分布を算出するというものである。事後予測分布は、モデルから推定された事後分布をもとに新たにデータを生成したときに、新たに得られるデータの予測分布のことである。INLAでは以下のようにして容易に事後予測分布を計算できる。 m8_4 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp, control.predictor = list(compute = TRUE), control.compute = list(return.marginals.predictor=TRUE)) 例えば、1頭目のチンパンジーの平均潜時の事後予測分布は以下のようになる。実測値を黒い点で示した。 m8_4$marginals.fitted.values[[1]] %&gt;% data.frame() %&gt;% ggplot(aes(x = x, y = y))+ geom_area(fill = &quot;lightblue&quot;)+ geom_line()+ geom_point(data = chimp %&gt;% .[1,], aes(x = Z_Latency, y = 0), size = 4.5)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Latency scores of chimp 1&quot;, y = &quot;Density&quot;) 全観測値について95%予測区間(事後予測分布の95%区間)と観測値の関係を示したのが以下の図である。実測値が95%予測区間に入ってないものがかなり多くあることが分かる。このことは、このモデルから実際のデータが得られたとは言いにくいということを示している。 postpre8_4 &lt;- m8_4$marginals.fitted.values postpre_all &lt;- data.frame() for(i in 1:nrow(chimp)){ summary_i &lt;- inla.qmarginal(c(0.025, 0.5, 0.975), postpre8_4[[i]]) %&gt;% data.frame() %&gt;% rename(value = 1) %&gt;% mutate(col = c(&quot;q2.5&quot;,&quot;q50&quot;, &quot;q97.5&quot;)) %&gt;% pivot_wider(names_from = col, values_from = value) %&gt;% mutate(id = i) postpre_all &lt;- bind_rows(postpre_all, summary_i) } postpre_all %&gt;% mutate(id2 = c(rep(&quot;1~61&quot;,61),rep(&quot;62~122&quot;,61), rep(&quot;123~183&quot;,61), rep(&quot;184~243&quot;,60))) %&gt;% ggplot(aes(x = id))+ geom_errorbar(aes(ymin = q2.5, ymax = q97.5))+ geom_point(data = chimp %&gt;% mutate(id = 1:n(), id2 = c(rep(&quot;1~61&quot;,61),rep(&quot;62~122&quot;,61), rep(&quot;123~183&quot;,61), rep(&quot;184~243&quot;,60))), aes(x = id, y = Z_Latency), size = 1)+ theme(aspect.ratio = 0.5)+ facet_rep_wrap(~id2, repeat.tick.labels = TRUE, scales = &quot;free&quot;) 事後予測分布をもとにモデルの当てはまりを評価するために、事後予測p値という値が考えられているようだ。これは、事後予測分布が実測値よりも小さい値をとる確率\\(Pr(Latency_i^* \\le Latency_i|D)\\)で定義される。なお、\\(Latency_i^*\\)は事後予測分布の値である。事後予測p値が0や1に近い値が多いならば、このモデルの当てはまりは悪いということになる。 では、実際に算出してみる。図示すると、やはり0や1に近い値が多くてモデルの当てはまりが悪いことが分かる。 pval &lt;- rep(NA, nrow(chimp)) for(i in 1:nrow(chimp)){ pval[i] &lt;- inla.pmarginal(q = chimp$Z_Latency[[i]], marginal = postpre8_4[[i]]) } data.frame(pval = pval) %&gt;% ggplot()+ geom_histogram(aes(x = pval), bins = 20, alpha = 0, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(0,1,0.1)) 7.6 Visualizing the model 最後に、モデルの予測値とその95%確信区間をデータ上に可視化する。 lm関数を用いた重回帰分析ではこれがかなり簡単に行える。例えば、fColony = 1、frear = 1のときの予測値とその95%信頼区間は以下のように描ける。 fit8_2 &lt;- ggpredict(m8_2, terms = c(&quot;Age[4:50,by = 0.1]&quot;,&quot;fSex&quot;), condition = c(fColony = &quot;1&quot;, frear = &quot;1&quot;)) fit8_2 %&gt;% data.frame() %&gt;% rename(Age = x, fSex = group) %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)) %&gt;% ggplot(aes(x = Age, y = predicted))+ geom_line()+ geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.4)+ geom_point(data = chimp %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)), aes(y = Z_Latency), shape = 1)+ facet_rep_wrap(~fSex)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Latency&quot;) INLAで同様のグラフを95%確信区間で書く方法は2つある。そのうち1つをここで紹介する(もう一つは第??章で紹介する)。 この方法は少しトリッキーだがうまくいく。まず、予測値を求めたい範囲のデータを格納し、かつZ_Latency = NAのデータフレームを作成する。 newdata &lt;- crossing(Z_Latency = NA, Age = seq(4,50,length = 100), fSex = c(&quot;1&quot;,&quot;2&quot;), fColony = &quot;1&quot;, frear = &quot;1&quot;) これをもとのデータにくっつけてモデルを実行すると、パラメータの推定自体に影響はないが、先ほどnewdataで指定した範囲についても予測値を算出することができる。 chimp2 &lt;- bind_rows(chimp, newdata) m8_5 &lt;- inla(Z_Latency ~ Age + fSex + fColony + frear, family = &quot;gaussian&quot;, data = chimp2, control.predictor = list(compute = TRUE), control.compute = list(return.marginals.predictor=TRUE)) 確信区間等を算出し、244番目以降のデータについて抽出すればnewdataで指定したデータについての予測値と95%確信区間が得られる。図示した結果は頻度論の結果とほぼ変わらない。 fit8_5 &lt;- m8_5$summary.fitted.values[244:443,] %&gt;% bind_cols(newdata) fit8_5 %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)) %&gt;% ggplot(aes(x = Age, y = mean))+ geom_line()+ geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), alpha = 0.4)+ geom_point(data = chimp %&gt;% mutate(fSex = str_c(&quot;fSex = &quot;,fSex)), aes(y = Z_Latency), shape = 1)+ facet_rep_wrap(~fSex)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Latency&quot;) References "],["Chapter9.html", "8 Mixed effects modelling in R-INLA to analysis otolith data 8.1 Otoliths in plaice 8.2 Model formulation 8.3 Dependency 8.4 Data exploration 8.5 Running the model in R-INLA 8.6 Model validation 8.7 Model selection 8.8 Model interpretation 8.9 Multiple random effects 8.10 Changin prior of fixed parameters 8.11 Changing priors of hyperparameters", " 8 Mixed effects modelling in R-INLA to analysis otolith data 本章では、INLAで線形混合モデルを実行する方法を学ぶ。 8.1 Otoliths in plaice 平衡石(otholith)は魚類の96%にある耳内の器官で、海水から炭化カルシウムを生成して作られている。よって、平衡石の組成を調べればその魚がどこの海域にいたかを推定できる可能性がある。しかし、それを知るためには環境要因と生理的要因がそれぞれどのように平衡石の組成に影響しているかを調べなければならない。 本章では Sturrock et al. (2015) による実験研究のデータを用いる。25個体が7から12ヶ月自然環境に近い状況でタンクに入れて飼育され、生理学的変数(全長、体重、フルトンのcondition factor7、成長率、血漿中のタンパク質、元素濃度)と環境的変数(塩分濃度、温度、海水の元素濃度)が少なくとも1ヶ月ごとに測定された。 \\(^7Li, ^{26}Mg, ^{41}K,^{48}Ca, ^{88}Sr, ^{138}Ba\\)などの元素濃度が海水中、血漿中、そして平衡石中で測定された。また、性別や魚が生息していた海域、産卵を促すために特定のホルモン(GnRH)を与えられていたかなども測定された。 oto &lt;- read_csv(&quot;data/OTODATA.csv&quot;) datatable(oto, options = list(scrollX = 80), filter = &quot;top&quot;) 8.2 Model formulation Sturrock et al. (2015) では様々な元素濃度を用いたモデリングを行っているが、本章ではそのうちの一つであるSr(ストロンチウム)/Ca(カルシウム)比を応答変数とするモデルの解説を行う。 モデルの共変量としては、性別とGnRHの有無、生息していた海域、環境的変数(塩分濃度、気温、水中のSr濃度、水中のSr/Ca比)と生理学的変数(年齢、全長、体重、condition factor、成長率、血漿中タンパク質、血中Sr濃度、血中Sr/Ca比)が用いられた。交互作用は考えないものとする。 8.3 Dependency 分析するのに十分な平衡石の成長が見られたのは25頭中19頭だけだった。各個体について複数時点のデータがあるため、データは独立ではない(図8.1)。 oto %&gt;% mutate(Date = as.Date(Date, format = &quot;%d/%m/%Y&quot;)) %&gt;% group_by(Fish) %&gt;% mutate(date_num = Date - min(Date) + 1) %&gt;% ungroup() -&gt; oto oto %&gt;% ggplot(aes(x = Date, y = O.Sr.Ca))+ geom_point()+ scale_x_date(labels = date_format(&quot;%m&quot;), date_breaks = &quot;2 months&quot;) + facet_rep_wrap(~Fish, repeat.tick.labels = TRUE)+ labs(y = &quot;Sr / Ca ratio (mmmol / mol)&quot;, x = &quot;Time (months)&quot;)+ theme_bw()+ theme(aspect.ratio = 0.8) 図8.1: Plot of the Sr / Ca ratio versus time for each fish. ランダム切片に個体IDを入れることでこれについてはある程度対処できる(第4章参照)。この場合、同じ魚からのデータは全て相関\\(\\phi\\)であり、異なる魚の相関は0であると仮定される。ただし、時系列相関は考慮されない。モデル式は大まかに以下のように書ける。本章では分析をシンプルにするため、応答変数が正規分布から得られているとして分析を行う。 \\[ \\begin{aligned} \\rm{Sr/Ca \\; ratio} = &amp; \\rm{Intercept + Sex + GnRH + Origin} + \\\\ &amp;+ \\rm{lots \\; of \\; environmental \\; variables} \\\\ &amp;+ \\rm{lots \\; of \\; ephysiological \\; variables} \\\\ &amp;+ \\rm{random \\; intercept} + noise \\end{aligned} \\] 8.4 Data exploration 各変数のdotplotを以下に示した(図8.2)。平衡石の成長率(Otolithgrowthrate)のみすこし外れ値があるようだが、他は問題ないようだ。ひとまずはこのまま進む。 oto %&gt;% select(Age, Opacity, Growthrate, Otolithgrowthrate, B.Sr, B.Sr.Ca, Plasmaprotein,Condition, Totallength, O.Sr.Ca, Temp, Sal, SW.Sr, SW.Sr.Ca) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% mutate(n = 1:n()) %&gt;% ungroup() %&gt;% ggplot(aes(x = value, y = n))+ geom_point(size = 0.4)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 0.8) 図8.2: Cleveland dotplots of each variable. 現在説明変数がデータ数に対してかなり多い。一般的に、1パラメータ当たり15データが必要だといわれている。そこで、変数の多重共線性を調べて相関の高い変数がないかをVIF(分散拡大係数)で確認する。 library(car) m9_vif &lt;- lm(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + B.Sr.Ca + Plasmaprotein + Condition + Totallength+ Temp + Sal + SW.Sr + SW.Sr.Ca, data = oto) vif(m9_vif) %&gt;% data.frame() %&gt;% rename(vif=1) %&gt;% arrange(vif) いくつかVIFの高い変数があることが分かる。ここでは保守的にVIFが3以上の変数は用いないこととする(通常は閾値は5か10で構わない)。海水中のSr濃度(SW.Sr)が最も高いVIF(13.31)を示している。各変数間の相関を調べてみると(図8.3)、気温(Temp)や塩分濃度(Sal)、海中Sr/Ca比(SW.Sr.Ca)と強く相関していることが分かる。よって、これらのどれかを除くとVIFは小さくなりそう。本章では、SW.Srを除くことにする。また、これ以外にVIFが高かった全長(Totallength)も除くことにする。 ggpairs(oto %&gt;% select(Age, Opacity, Growthrate, Otolithgrowthrate, B.Sr, B.Sr.Ca, Plasmaprotein,Condition, Totallength, Temp, Sal, SW.Sr, SW.Sr.Ca)) 図8.3: Relationship between covariates. 改めてVIFを調べると、まだVIFが3を超えるものが3つだけあることが分かる。血中Sr濃度と血中Sr/Ca比も中程度の相関があるようなので、血中Sr/Ca比を除くことにする。 m9_vif2 &lt;- lm(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + B.Sr.Ca + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca, data = oto) vif(m9_vif2) %&gt;% data.frame() %&gt;% rename(vif=1) %&gt;% arrange(vif) 最終的に全てのVIFが3以下になった。 m9_vif3 &lt;- lm(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca, data = oto) vif(m9_vif3) %&gt;% data.frame() %&gt;% rename(vif=1) %&gt;% arrange(vif) 8.5 Running the model in R-INLA 最終的に選ばれた変数から、以下のようなモデルを実行する。 \\[ \\begin{aligned} &amp;SrCa_{ij} = \\rm{Intercept + Covariates} + a_i + \\epsilon_{ij}\\\\ &amp;a_i \\sim N(0, \\sigma_{Fish}^2)\\\\ &amp;\\epsilon_{ij} \\sim N(0, \\sigma^2) \\end{aligned} \\] モデルの収束をよくするため、連続値の説明変数は標準化する。Opacityは3つの値(0, 0.5, 1)しか取らないので標準化しなかった。 oto %&gt;% select(Fish, O.Sr.Ca, Sex, GnRH, Age, Origin, Growthrate, Otolithgrowthrate, B.Sr, Plasmaprotein, Condition, Temp, Sal, SW.Sr.Ca) %&gt;% mutate_if(is.numeric, ~scale(.)[,1]) %&gt;% mutate(Opacity = oto$Opacity) %&gt;% mutate(Date = oto$Date, date_num = oto$date_num) %&gt;% drop_na() -&gt; oto2 モデルは以下の通り。ランダム切片はf(Fish, model = \"iid)のように指定する。iidはindependent and identical distributed を表す。すなわち、同じ分布から独立に得られたと仮定するということである。 m9_1 &lt;- inla(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca + f(Fish, model = &quot;iid&quot;), control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975)), control.compute = list(dic = TRUE), data = oto2) 固定効果の結果は以下の通り。血中Sr濃度(B.Sr)、血漿中タンパク(Plasmaprotein)、気温(Temp)、塩分濃度Salinityは95%確信区間に0を含んでおらず、これらの変数は影響があるといえそう。 m9_1$summary.fixed %&gt;% select(1,2,3,5) ハイパーパラメータの結果は以下の通り。しかし、前章で見たようにこれらは\\(\\tau = 1/\\sigma^2\\)の事後推定値である。 m9_1$summary.hyperpar %&gt;% select(1,2,3,5) \\(\\sigma\\)と\\(\\sigma_{Fish}\\)の事後平均値は以下のように求められる。 tau &lt;- m9_1$marginals.hyperpar$`Precision for the Gaussian observations` tau_fish &lt;- m9_1$marginals.hyperpar$`Precision for Fish` sigma &lt;- inla.emarginal(function(x) 1/sqrt(x), tau) sigma_fish &lt;- inla.emarginal(function(x) 1/sqrt(x), tau_fish) c(sigma, sigma_fish) ## [1] 0.6628616 0.4673066 級内相関係数は以下の通り。すなわち、同じ個体のデータの相関は0.33くらいであると推定された。 sigma_fish^2/(sigma^2 + sigma_fish^2) ## [1] 0.3319982 8.6 Model validation モデルの予測値と残差は以下のように計算できる。 fit9_1 &lt;- m9_1$summary.fitted.values fit9_1 %&gt;% bind_cols(oto2) %&gt;% mutate(resid = O.Sr.Ca - mean) -&gt; fit9_1b 残差と予測値にはパターンはなく、等分散性の仮定は満たされていそう。 fit9_1b %&gt;% ggplot(aes(x = mean, y = resid))+ geom_point()+ theme_bw()+ theme(aspect.ratio = 1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) 残差と説明変数の関係をプロットしても明確なパターンはなさそう? fit9_1b %&gt;% select(resid, Sex:Opacity) %&gt;% select(-Sex, -Origin, -GnRH) %&gt;% pivot_longer(2:11) %&gt;% ggplot(aes(x = value, y = resid))+ geom_point(shape = 1)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1) fit9_1b %&gt;% select(resid, Sex, Origin, GnRH) %&gt;% pivot_longer(2:4) %&gt;% ggplot(aes(x = value, y = resid))+ geom_boxplot(shape = 1)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free&quot;)+ theme_bw()+ theme(aspect.ratio = 1) QQプロットを見ても問題はなさそう。残差の正規性も問題ない。 qqPlot(fit9_1b$resid, ylab = &quot;Sample quantiles&quot;) ## [1] 120 187 最後に、残差の時系列相関があるかを確認する。図を見ると明確に時間的に近いポイントで残差が類似した値をとっていることが見て取れる。すなわち、残差は独立ではなく時系列相関が存在すると考えられる。 fit9_1b %&gt;% ggplot(aes(x = Date, y = resid))+ geom_point(shape = 1)+ scale_x_date(labels = date_format(&quot;%m&quot;), date_breaks = &quot;2 months&quot;)+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 0.8)+ facet_rep_wrap(~Fish, repeat.tick.labels = TRUE) 本来はここで時系列相関を考慮したモデルを作るべきだが、ひとまずここではこのまま解説を続ける。続いて、ランダム効果の前提が満たされているかも確認する。 各個体の\\(a_i\\)の事後分布の要約統計量は以下のように確認できる。 a &lt;- m9_1$summary.random a$Fish 19個しかないのでその正規性をきちんと検討することはできないが、QQプロットを見る限りそこまで大きな問題はなさそう? qqPlot(a$Fish$mean, ylab = &quot;a&quot;) ## [1] 5 7 8.7 Model selection 前章でやったように、DICやWAICでモデル選択をすることはできる。ここではやらない。 8.8 Model interpretation モデルを解釈する際には、結果を可視化することが重要だ。ある説明変数と応答変数の関係についてみる場合には、それ以外の説明変数を固定する必要がある。通常は連続変数であれば平均を(今回は標準化しているので全て0)、離散変数であれば特定の水準に固定することが多い。これを行う方法は2つあるが、そのうち一つは前章(7.6)で解説したので、本節ではもう一つの方法も解説する。 8.8.1 Option 1 for prediction: Adding extra data まずは前章でも見た一つ目の方法で行う。以下では、血漿中タンパク質とSr/Ca比の関連についてプロットする。ここでは、ランダム効果を含まない予測値を図示したいので、Fish = NAとする。また、連続変数は血漿中タンパク質以外は0(Opacityだけ標準化されていないので平均をとる)、離散変数についてはOrigin‘はEC(English channel)、GnRHはNon-treated、SexはF`に固定する。 newdata &lt;- data.frame(O.Sr.Ca = rep(NA, 25),# Fish = factor(NA, levels =levels(oto2$Fish)), Sex = factor(&quot;F&quot;, levels = c(&quot;F&quot;, &quot;M&quot;)), Origin = factor(&quot;EC&quot;, levels = c(&quot;EC&quot;, &quot;IS&quot;)), GnRH = factor(&quot;Non-treated&quot;, levels = c(&quot;Non-treated&quot;,&quot;Treated&quot;)), Temp = 0, Sal = 0, SW.Sr.Ca = 0, B.Sr = 0, Plasmaprotein = seq(from = min(oto2$Plasmaprotein), to =max(oto2$Plasmaprotein), length = 100), Condition = 0, Age = 0, Opacity = mean(oto2$Opacity), Growthrate = 0, Otolithgrowthrate = 0 ) oto3 &lt;- bind_rows(oto2, newdata) %&gt;% select(-Date, -date_num) それでは、実際にモデルを回して予測値と95%確信区間を得る。 m9_2 &lt;- inla(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca + f(Fish, model = &quot;iid&quot;), control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975)), control.compute = list(dic = TRUE), data = oto3) 以下に結果を図示する。事後平均を用いた平均の予測値と、その95%確信区間である。 fit9_2 &lt;- m9_2$summary.fitted.values[210:309,] %&gt;% bind_cols(newdata) %&gt;% ## 血漿中タンパク質は元のスケールに戻す mutate(Plasmaprotein = Plasmaprotein*sd(oto2$Plasmaprotein) + mean(oto2$Plasmaprotein)) fit9_2 %&gt;% ggplot(aes(x = Plasmaprotein))+ geom_line(aes(y = mean))+ geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), alpha = 0.3)+ geom_point(data = oto2, aes(y = O.Sr.Ca), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1) 8.8.2 Option 2 for prediction: Using the inla.make.lincombs 続いて、もう一つの方法を解説する。ここでは、inla.make.limcombsを使用する。先ほどと全く同じではないが似た結果が得られる。 まず、1つ目の方法と同様に予測値が欲しい範囲の変数を格納したデータフレームを作る。ただし、このときランダム効果と応答変数は含めなくていい。 newdata2 &lt;- data.frame(Sex = factor(&quot;F&quot;, levels = c(&quot;F&quot;, &quot;M&quot;)), Origin = factor(&quot;EC&quot;, levels = c(&quot;EC&quot;, &quot;IS&quot;)), GnRH = factor(&quot;Non-treated&quot;, levels = c(&quot;Non-treated&quot;,&quot;Treated&quot;)), Temp = 0, Sal = 0, SW.Sr.Ca = 0, B.Sr = 0, Plasmaprotein = seq(from = min(oto2$Plasmaprotein), to =max(oto2$Plasmaprotein), length = 100), Condition = 0, Age = 0, Opacity = mean(oto2$Opacity), Growthrate = 0, Otolithgrowthrate = 0 ) 次に、これらを切片を含むマトリックスにする。 Xmat &lt;- model.matrix(~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca, data = newdata2) 最後にこれをデータフレームにする。 Xmat &lt;- as.data.frame(Xmat) それでは、inlaでモデルを実行する。このとき、あらかじめXmatを変換する必要がある。その後、inlaでlimcomb =(linear combinationの意)で作成したオブジェクトを指定する。 lcb &lt;- inla.make.lincombs(Xmat) m9_3 &lt;- inla(O.Sr.Ca ~ Sex + GnRH + Age+ Origin + Opacity + Growthrate+ Otolithgrowthrate + B.Sr + Plasmaprotein + Condition + Temp + Sal + SW.Sr.Ca + f(Fish, model = &quot;iid&quot;), lincomb = lcb, family = &quot;gaussian&quot;, control.predictor = list(compute = TRUE, quantiles = c(0.025, 0.975)), data = oto2) m9_3$summary.lincomb.derivedに予測値と確信区間が格納されているので、これをnewdata2と結合する。 fit9_3 &lt;- m9_3$summary.lincomb.derived %&gt;% bind_cols(newdata2) %&gt;% mutate(Plasmaprotein = Plasmaprotein*sd(oto2$Plasmaprotein) + mean(oto2$Plasmaprotein)) 最後にこれを図示する。 fit9_3 %&gt;% ggplot(aes(x = Plasmaprotein))+ geom_line(aes(y = mean))+ geom_ribbon(aes(ymin = `0.025quant`, ymax = `0.975quant`), alpha = 0.3)+ geom_point(data = oto2, aes(y = O.Sr.Ca), shape = 1)+ theme_bw()+ theme(aspect.ratio = 1) 8.9 Multiple random effects INLAでも2つ以上のランダム切片を追加することはできる。 8.10 Changin prior of fixed parameters 本稿では、ここまで事前分布にINLAのデフォルトを使用してきた。しかし、今回のように1湯のランダム切片しか持たないときは問題ないが、ランダム効果を2つ以上持つ場合や、それらに時空間的相関を仮定するときには、事前分布の影響を確認した方がよい。 INLAでは固定効果のパラメータのデフォルトの事前分布は平均0で精度$\\(0.001の正規分布になっている。\\)\\(を\\)\\(に直すと、\\)= 31.62$である。 \\[ \\beta_i \\sim N(0, 31.6^2) \\] 正規分布では\\(±3 \\times \\sigma\\)の範囲に99%の値が入るので、この事前分布はパラメータがおよそ-95.8から94.8の値をとることを贈呈していることになる。これは十分に広い。なお、切片のパラメータの精度は0にされている。 以下では、事前分布を変えたときに結果がどのように変化するかを見ていく。話を単純にするため、先ほどの結果で影響があった4つの変数のみをモデルに含める。また、変数変換は行わないものとする。 まず、デフォルトの事前分布でモデリングを行う。 m9_4a &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;), family = &quot;gaussian&quot;, data = oto) 得られたハイパーパラメータ以外の事後分布の要約統計量は以下の通り。 m9_4a$summary.fixed %&gt;% select(1,2,3,5) それでは、次に情報事前分布を用いてモデルを回す。ここでは、例えば先行研究などの結果からPlasmaproteinの回帰係数\\(\\beta_{Plasma}\\)が以下の事前分布を持つとする。 \\[ \\beta_{Plasma} \\sim N(-0.22, 0.01^2) \\] \\(\\sigma = 0.01\\)のとき\\(\\tau = 10000\\)である。一方で、その他のパラメータはデフォルトと同様に平均0で精度0.001の無情報事前分布を事前分布に定める。また、切片のパラメータの事前分布もデフォルトと同様である。inlaでは、control.fixedオプションで事前分布を指定できる。 m9_4b &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;), control.fixed = list(mean = list(Plasmaprotein = -0.22, Temp = 0, Sal = 0, B.Sr = 0), prec = list(Temp = 0.001, Sal = 0.001, B.Sr = 0.001, Plasmaprotein = 10000), mean.intercept = 0, prec.intercept = 0), data = oto) 血漿中タンパクの回帰係数の推定値がかなり変わっている。 結果が明らかにおかしい。何らかのバグ？おそらく事前分布の平均が反映されていない。 m9_4b$summary.fixed %&gt;% select(1,2,3,5) 8.11 Changing priors of hyperparameters 先ほどのモデルにはハイパーパラメータが2つあった(\\(\\sigma\\)と\\(\\sigma_{Fish}\\))。しかし、INLAでは精度(\\(\\tau = 1/\\sigma^2, \\tau_{Fish} = 1/\\sigma_{Fish}^2\\)が推定される。これらのデフォルトの事前分布は以下の通り。これは、\\(\\tau\\)と\\(\\tau_{Fish}\\)がガンマ分布を事前分布に持つのと同じことである。 \\[ \\begin{aligned} &amp;log(\\tau) \\sim LogGamma(1, 0.00005)\\\\ &amp;log(\\tau_{Fish}) \\sim LogGamma(1, 0.00005)\\\\ \\end{aligned} \\] ガンマ分布は2つのパラメータshapeとscaleを持っており、それぞれ\\(a\\)とと\\(b\\)で示されることが多い。ただし、INLAでは\\(b\\)をscaleパラメータの逆数に用いているためややこしい。以下では、INLAと同様にscaleパラメータの逆数(rateパラメータという)を\\(b\\)で示す。このとき、ガンマ分布の平均は\\(a/b\\)で分散は\\(a/b^2\\)となる。 INLAでは、\\(\\tau\\)と\\(\\tau_{Fish}\\)の事前分布に\\(Gamma(a = 1, b = 0.00001)\\)をしている。これは、ほぼ一様分布のようになる(図8.4のA)。一方で、 Carroll et al. (2015) は、INLAではポワソンGLMMのときには\\(Gamma(1, 0.5)\\)の方がデフォルトよりもうまく分析できることを示している。この時のガンマ分布は図8.4のBのようになる。 x &lt;- seq(0, 20, length = 1000) data.frame(x = x, y = dgamma(x, shape =1, rate = 0.00001)) %&gt;% ggplot()+ geom_line(aes(x = x, y = y))+ coord_cartesian(ylim = c(0,0.00001))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;A: shape =, rate = 0.00001&quot;)-&gt; p1 data.frame(x = x, y = dgamma(x, shape =1, rate = 0.5)) %&gt;% ggplot()+ geom_line(aes(x = x, y = y))+ coord_cartesian(ylim = c(0,0.5))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(title = &quot;B: shape = 1, rate = 0.5&quot;)-&gt; p2 p1 + p2 図8.4: Gamma distribution with shape = 1 and rate = 0.00001. では、\\(\\tau\\)が\\(Gamma(1,0.5)\\)に従うとき、\\(\\sigma\\)はどのような値をとるだろうか。シミュレーションによってこの分布から\\(\\tau\\)をランダムに抽出したときの\\(\\sigma\\)の値の分布を示したのが図8.5である。ここから、この事前分布では\\(\\sigma\\)はおおよそ0から5までの間の値をとることが多いことが分かる。 set.seed(123) tau &lt;- rgamma(n = 1000, shape = 1, rate = 0.5) data.frame(sigma = 1/sqrt(tau)) %&gt;% ggplot(aes(x = sigma))+ geom_histogram(binwidth = 1, alpha = 0, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1) 図8.5: 1000 simulated values of sigmas when sampling tau from Gamma(1, 0.5) ただし、 Carroll et al. (2015) はポワソン分布の場合の話であり、リンク関数にログ関数を用いていることは注意が必要である。私たちが現在使っているのは正規分布のモデルでリンク関数は恒等関数である。 さて、それではハイパーパラメータの事前分布を変えたときに結果がどのように変わるかを見てみる。\\(\\sigma\\)の事前分布はcontrol.familyオプションで、\\(\\sigma_{Fish}\\)の事前分布は式のf(Fish, model = \"iid\", ...)の中で指定できる。まずは、デフォルト(\\(\\sigma, \\sigma_{Fish} \\sim Gamma(1,0.00001)\\)のモデルを回す。 m9_5a &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;), data = oto) 続いて、事前分布に\\(\\sigma, \\sigma_{Fish} \\sim Gamma(1,0.5)\\)を用いてみる。 m9_5b &lt;- inla(O.Sr.Ca ~ B.Sr + Plasmaprotein + Temp + Sal + f(Fish, model = &quot;iid&quot;, hyper = list(prec = list(prior = &quot;loggamma&quot;, param = c(1,0.5)))), control.family = list(hyper = list(prec = list( prior = &quot;loggamma&quot;, param = c(1, 0.5)))), data = oto) 固定効果の推定値や95%確信区間などはほとんど変わらなかった。 m9_5a$summary.fixed %&gt;% select(1,2,3,5) %&gt;% mutate(model = &quot;m9_5a&quot;) %&gt;% rownames_to_column(var = &quot;Parameter&quot;) %&gt;% bind_rows(m9_5b$summary.fixed %&gt;% select(1,2,3,5) %&gt;% mutate(model = &quot;m9_5b&quot;) %&gt;% rownames_to_column(var = &quot;Parameter&quot;)) 一方で、推定されたハイパーパラメータの事後分布を示すと、特に\\(\\sigma_{Fish}\\)はかなり違うことが分かる。 tau5a &lt;- m9_5a$marginals.hyperpar$`Precision for the Gaussian observations` tau5b &lt;- m9_5b$marginals.hyperpar$`Precision for the Gaussian observations` tau_fish5a &lt;- m9_5a$marginals.hyperpar$`Precision for Fish` tau_fish5b &lt;- m9_5b$marginals.hyperpar$`Precision for Fish` ## sigmaにする myfun &lt;- function(x) 1/sqrt(x) sigma5a &lt;- inla.tmarginal(myfun, tau5a) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5a&quot;) sigma5b &lt;- inla.tmarginal(myfun, tau5b) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5b&quot;) sigma_fish5a &lt;- inla.tmarginal(myfun, tau_fish5a) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5a&quot;) sigma_fish5b &lt;- inla.tmarginal(myfun, tau_fish5b) %&gt;% data.frame() %&gt;% mutate(model = &quot;m9_5b&quot;) ## 図示 sigma5a %&gt;% bind_rows(sigma5b) %&gt;% ggplot(aes(x = x, y = y))+ geom_line(aes(color = model))+ scale_color_manual(values = c(&quot;red&quot;,&quot;blue&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ guides(color = &quot;none&quot;)+ labs(x = expression(sigma), y = expression(paste(&quot;Pr(&quot;, sigma, &quot;|D)&quot;))) -&gt; p1 sigma_fish5a %&gt;% bind_rows(sigma_fish5b) %&gt;% ggplot(aes(x = x, y = y))+ geom_line(aes(color = model))+ scale_color_manual(values = c(&quot;red&quot;,&quot;blue&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = expression(sigma[Fish]), y = expression(paste(&quot;Pr(&quot;, sigma[Fish], &quot;|D)&quot;)))-&gt; p2 p1 + p2 References "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] parallel stats graphics grDevices utils datasets methods ## [8] base ## ## other attached packages: ## [1] car_3.1-2 carData_3.0-5 posterior_1.4.1 ## [4] fields_15.2 viridisLite_0.4.2 spam_2.9-1 ## [7] lemon_0.4.6 ggsci_2.9 kableExtra_1.3.4 ## [10] DT_0.27 patchwork_1.1.2 ggrepel_0.9.2 ## [13] GGally_2.1.2 ggnewscale_0.4.9 geoR_1.9-2 ## [16] gt_0.9.0 bayesplot_1.10.0 ggeffects_1.1.4 ## [19] cmdstanr_0.5.3 rstan_2.26.23 StanHeaders_2.26.28 ## [22] brms_2.18.0 Rcpp_1.0.11 gstat_2.1-1 ## [25] gamm4_0.2-6 lme4_1.1-34 mgcv_1.8-41 ## [28] nlme_3.1-160 INLA_23.04.24 foreach_1.5.2 ## [31] Matrix_1.6-1 NipponMap_0.2 sf_1.0-14 ## [34] sp_1.5-1 fontregisterer_0.3 systemfonts_1.0.4 ## [37] extrafont_0.18 data.table_1.14.6 see_0.7.5.5 ## [40] report_0.5.7.4 parameters_0.20.3 performance_0.10.3 ## [43] modelbased_0.8.6.3 insight_0.19.1.4 effectsize_0.8.3.6 ## [46] datawizard_0.7.1.1 correlation_0.8.4 bayestestR_0.13.1 ## [49] easystats_0.6.0.8 scales_1.2.1 lubridate_1.9.2 ## [52] forcats_1.0.0 stringr_1.5.0 dplyr_1.1.2 ## [55] purrr_1.0.2 readr_2.1.4 tidyr_1.3.0 ## [58] tibble_3.2.1 ggplot2_3.4.3 tidyverse_2.0.0 ## [61] MASS_7.3-58.1 knitr_1.44 ## ## loaded via a namespace (and not attached): ## [1] utf8_1.2.2 tidyselect_1.2.0 htmlwidgets_1.6.2 ## [4] grid_4.2.2 munsell_0.5.0 codetools_0.2-18 ## [7] units_0.8-1 miniUI_0.1.1.1 withr_2.5.0 ## [10] Brobdingnag_1.2-9 colorspace_2.0-3 rstudioapi_0.15.0 ## [13] stats4_4.2.2 Rttf2pt1_1.3.12 labeling_0.4.3 ## [16] emmeans_1.8.8 splancs_2.01-44 farver_2.1.1 ## [19] bridgesampling_1.1-2 coda_0.19-4 vctrs_0.6.3 ## [22] generics_0.1.3 TH.data_1.1-2 xfun_0.39 ## [25] timechange_0.1.1 R6_2.5.1 markdown_1.8 ## [28] reshape_0.8.9 cachem_1.0.6 promises_1.2.0.1 ## [31] multcomp_1.4-25 gtable_0.3.4 processx_3.8.0 ## [34] sandwich_3.0-2 MatrixModels_0.5-2 rlang_1.1.1 ## [37] splines_4.2.2 extrafontdb_1.0 checkmate_2.1.0 ## [40] inline_0.3.19 yaml_2.3.7 reshape2_1.4.4 ## [43] abind_1.4-5 threejs_0.3.3 crosstalk_1.2.0 ## [46] backports_1.4.1 httpuv_1.6.7 tensorA_0.36.2 ## [49] tools_4.2.2 tcltk_4.2.2 bookdown_0.35 ## [52] ellipsis_0.3.2 RColorBrewer_1.1-3 jquerylib_0.1.4 ## [55] proxy_0.4-27 plyr_1.8.8 base64enc_0.1-3 ## [58] classInt_0.4-8 ps_1.7.2 prettyunits_1.1.1 ## [61] zoo_1.8-11 magrittr_2.0.3 spacetime_1.3-0 ## [64] colourpicker_1.3.0 mvtnorm_1.1-3 matrixStats_0.63.0 ## [67] hms_1.1.3 shinyjs_2.1.0 mime_0.12 ## [70] evaluate_0.21 xtable_1.8-4 shinystan_2.6.0 ## [73] gridExtra_2.3 rstantools_2.3.1.1 compiler_4.2.2 ## [76] maps_3.4.1 KernSmooth_2.23-20 crayon_1.5.2 ## [79] minqa_1.2.5 htmltools_0.5.4 later_1.3.0 ## [82] tzdb_0.3.0 RcppParallel_5.1.6 DBI_1.1.3 ## [85] boot_1.3-28 cli_3.6.1 dotCall64_1.0-2 ## [88] igraph_1.3.5 pkgconfig_2.0.3 xml2_1.3.5 ## [91] svglite_2.1.1 dygraphs_1.1.1.6 QuickJSR_1.0.5 ## [94] bslib_0.5.1 webshot_0.5.5 estimability_1.4.1 ## [97] rvest_1.0.3 distributional_0.3.2 callr_3.7.3 ## [100] digest_0.6.31 rmarkdown_2.24 intervals_0.15.4 ## [103] Deriv_4.1.3 shiny_1.7.5 gtools_3.9.4 ## [106] nloptr_2.0.3 lifecycle_1.0.3 jsonlite_1.8.4 ## [109] fansi_1.0.3 pillar_1.9.0 lattice_0.20-45 ## [112] loo_2.6.0 httr_1.4.7 fastmap_1.1.1 ## [115] pkgbuild_1.4.2 survival_3.5-5 glue_1.6.2 ## [118] xts_0.12.2 FNN_1.1.3.2 shinythemes_1.2.0 ## [121] iterators_1.0.14 class_7.3-20 stringi_1.7.12 ## [124] sass_0.4.5 e1071_1.7-12 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
