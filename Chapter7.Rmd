# Introduction to Bayesian statistics  
本章では、ベイズ統計とマルコフ連鎖モンテカルロ法(MCMC)、integrated nested Laplace approximations(INLA)について解説を行う。   

## Why go Bayesian?  
ベイズ統計を使うモチベーションとしてはいくつかある。  

1. 事前に持っている知識を分析に取り入れるため。  
後に見るように、ベイズ統計では事前分布という形であらかじめ持っている知識を分析に組み込むことができる。  

2. 頻度論的な統計学に対する批判から  
頻度論的な統計学とは、いわゆる帰無仮説検定(p値)に基づく統計学を指すが、p値や信頼区間などをめぐってはその解釈のしにくさや論理的な問題点に対してたびたび批判的な意見も投げかけられている[e.g., @Ohkubo2012; @Matsuura2016]。  

3. 複雑なモデルを使用するため  
時空間相関を考慮したGLMやGLMMなどの複雑なモデルは、通常の頻度論的な枠組みでは扱えないことが多い。ベイズ統計はこうした複雑なモデルを柔軟にモデリングすることを可能にする。  

頻度論ではパラメータはある1つの真値を持つと考えられる一方で、ベイズ統計ではパラメータはある確率的な分布に従っているとされる[@Kruschke2014; @Baba2019; @Matsuura2016; @Matsuura2016; @McElreath2020]。ベイズ統計を用いた分析では、データが得られた時のパラメータの分布(= 事後分布)を最終的に得る($P(\beta|D)$)。一方で、頻度論的な統計学ではパラ、エータがある値のときにデータが得られる確率($P(D|\beta)$)を計算する(= 尤度)。  

## General probability rules  
まず確立の基本から確認していく。$P(A)$と$P(B)$をそれぞれ事象Aが生じる確率、事象Bが生じる確率とする。また、$P(A \cap B)$をAかつBである確率、$P(A \cup B)$をAまたはBである確率とする。このとき、  

$$
P(A \cap B) = P(B \cap A)
$$

である。また、AとBが独立であるときは以下のように書ける。  
$$
P(A \cap B) = P(A) \times P(B)
$$

一方、AとBが独立でないとき以下のように書ける。なお、$P(A|B)$は条件付確率を表し、事象Bが生じたときに事象Aが生じる確率を表す。  
$$
\begin{aligned}
P(A \cap B) &= P(A|B) \times P(B)\\
P(A \cap B) &= P(B|A) \times P(A)
\end{aligned}
$$

よって、以下の式が導かれる。これを、**ベイズの定理**という。  
$$
P(A|B) = \frac{P(B|A) \times P(A)}{P(B)} (\#eq:bayes)
$$

## The mean of a distribution  
ある変数$Y$がパラメータ$\mu$のポワソン分布から得られるとき、$Y$の期待値は$\mu$である。このことは以下のように書ける。  
$$
\begin{aligned}
&Y \sim Poisson(\mu)\\
&E(Y) = \mu
\end{aligned}
$$

$Y$が**離散的な値**のとき、その期待値は以下のように書ける。なお、$y$は$Y$がとりうる全ての値を表す。よって、離散的な変数に関する確率分布(ポワソン分布、ベルヌーイ分布、二項分布、負の二項分布など)の期待値は以下の式で求められる。  

$$
E(Y) = \sum_y y \times p(y) (\#eq:exp-disc)
$$

ポワソン分布は$p(y) = \frac{e^{-\mu} \times \mu^y}{y!}$なので、式\@ref(eq:exp-disc)は以下のように書ける。この式を計算すると右辺は$\mu$になる。    
$$
E(Y) = \sum_{y =0} ^\infty y \times \frac{e^{-\mu} \times \mu^y}{y!} (\#eq:exp-poisson)
$$

もし変数$Y$が**連続的な値**の場合、その期待値は$\int$を用いて以下のように書ける。よって、連続的な変数に関する確率分布(正規分布、ガンマ分布、β分布など)の期待値は以下の式で求められる。    
$$
E(Y) = \int _{-\infty} ^{\infty} y \times p(y) dy (\#eq:exp-con)
$$

## Bayes theorem again  
ベイズの定理(式\@ref(eq:bayes))を用いて、データ(D)が得られたときにパラメータ$\beta$がとりうる確率の分布$P(\beta|D)$は以下のように書ける。  

$$
P(\beta|D) = \frac{P(D|\beta) \times P(\beta)}{P(D)}
$$

$P(\beta|D)$は、データが得られた時のパラメータ$\beta$の**事後分布(posterior distribution)**という。事後分布こそが、<u>私たちがデータからパラメータを推定するときに求めたいものである</u>。  

$P(D|\beta)$はあるパラメータ$\beta$が与えられたときにデータが得られる確率であり、いわゆる**尤度(likelihood)**である。$P(\beta)$はデータが与えられていない状態でのパラメータ$\beta$が得られる確率分布で**事前分布(prior distribution)**と呼ばれる。  

最後に、$P(D)$はデータが得られる確率で、事後分布の合計を1にするための役割を果たす。これは**周辺尤度**と言われ、通常計算することが難しいので省略されることが多い。このとき、式\@ref(eq:bayes)は以下のように書ける。なお、$\propto$は左辺が右辺に比例することを表す。    

$$
P(\beta|D) \propto P(D|\beta) \times P(\beta) (\#eq:bayes2)
$$

この式は、事後分布は尤度と事前分布の積に比例していることを示している。また、事後分布の期待値は式\@ref(eq:exp-con)から以下のように書ける。  

$$
E(\beta|D) = \int_{-\infty} ^\infty \beta \times P(\beta_|D) d\beta
$$

次節以降では、事後分布とその期待値をどのように推定するかをみていく。  

## Conjugate priors  

